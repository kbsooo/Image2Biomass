{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e36542",
   "metadata": {},
   "source": [
    "# üöÄ Improved DINOv3 Inference Pipeline v2\n",
    "\n",
    "**Model**: CSIROModelV2 (14_improved_train.pyÏôÄ ÎèôÏùº Íµ¨Ï°∞)\n",
    "**TTA**: Original + HFlip + VFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a3702",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.v2 as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22789bd3",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9537b4bc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    WEIGHTS_PATH = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large\")\n",
    "    MODELS_DIR = Path(\"/kaggle/input/csiro-improved-models\")  # ÌïôÏäµÎêú Î™®Îç∏\n",
    "\n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb.lvd1689m\"\n",
    "    img_size = (512, 512)  # patch16 Î™®Îç∏\n",
    "\n",
    "    # Must match training config\n",
    "    head_hidden_dim = 128\n",
    "    dropout = 0.1\n",
    "    use_zero_inflated_clover = True\n",
    "\n",
    "    batch_size = 16\n",
    "    num_workers = 0  # Avoid multiprocessing errors\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9680ba",
   "metadata": {},
   "source": [
    "## Model Definition (Same as training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536a365",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, context):\n",
    "        out = self.mlp(context)\n",
    "        gamma, beta = torch.chunk(out, 2, dim=1)\n",
    "        return gamma, beta\n",
    "\n",
    "\n",
    "class ZeroInflatedHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        prob = torch.sigmoid(self.classifier(x))\n",
    "        amount = self.regressor(x)\n",
    "        return prob * amount\n",
    "\n",
    "\n",
    "class CSIROModelV2(nn.Module):\n",
    "    def __init__(self, cfg, load_backbone=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if load_backbone:\n",
    "            self.backbone = timm.create_model(\n",
    "                cfg.model_name, pretrained=False, num_classes=0, global_pool='avg'\n",
    "            )\n",
    "        else:\n",
    "            self.backbone = timm.create_model(\n",
    "                cfg.model_name, pretrained=False, num_classes=0, global_pool='avg'\n",
    "            )\n",
    "\n",
    "        feat_dim = self.backbone.num_features\n",
    "        combined_dim = feat_dim * 2\n",
    "        hidden_dim = cfg.head_hidden_dim\n",
    "        dropout = cfg.dropout\n",
    "\n",
    "        self.film = FiLM(feat_dim)\n",
    "\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(combined_dim, hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_dim, 1),\n",
    "                nn.Softplus()\n",
    "            )\n",
    "\n",
    "        self.head_green = make_head()\n",
    "        self.head_dead = make_head()\n",
    "\n",
    "        if cfg.use_zero_inflated_clover:\n",
    "            self.head_clover = ZeroInflatedHead(combined_dim, hidden_dim, dropout)\n",
    "        else:\n",
    "            self.head_clover = make_head()\n",
    "\n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "\n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "\n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "\n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "\n",
    "        green = self.head_green(combined)\n",
    "        clover = self.head_clover(combined)\n",
    "        dead = self.head_dead(combined)\n",
    "\n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "\n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ba12bb",
   "metadata": {},
   "source": [
    "## Dataset & TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a65ba0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, cfg, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img = Image.open(self.cfg.DATA_PATH / row['image_path']).convert('RGB')\n",
    "        w, h = img.size\n",
    "        mid = w // 2\n",
    "\n",
    "        left = img.crop((0, 0, mid, h))\n",
    "        right = img.crop((mid, 0, w, h))\n",
    "\n",
    "        if self.transform:\n",
    "            left = self.transform(left)\n",
    "            right = self.transform(right)\n",
    "\n",
    "        return left, right, row['sample_id_prefix']\n",
    "\n",
    "\n",
    "def get_tta_loaders(df, cfg):\n",
    "    \"\"\"3x TTA: Original, HFlip, VFlip\"\"\"\n",
    "    transforms = [\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.RandomHorizontalFlip(p=1.0),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.RandomVerticalFlip(p=1.0),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    ]\n",
    "\n",
    "    loaders = []\n",
    "    for t in transforms:\n",
    "        ds = TestDataset(df, cfg, t)\n",
    "        loader = DataLoader(ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "                          num_workers=cfg.num_workers, pin_memory=True)\n",
    "        loaders.append(loader)\n",
    "\n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600c86e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e69a2c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    ids = []\n",
    "\n",
    "    for left, right, sample_ids in tqdm(loader, desc=\"Predicting\"):\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "\n",
    "        out = model(left, right)\n",
    "        outputs.append(out.cpu().numpy())\n",
    "        ids.extend(sample_ids)\n",
    "\n",
    "    return np.concatenate(outputs), ids\n",
    "\n",
    "\n",
    "def predict_with_tta(model, loaders, device):\n",
    "    \"\"\"TTA: average across augmentations\"\"\"\n",
    "    all_preds = []\n",
    "    final_ids = None\n",
    "\n",
    "    for loader in loaders:\n",
    "        preds, ids = predict(model, loader, device)\n",
    "        all_preds.append(preds)\n",
    "        if final_ids is None:\n",
    "            final_ids = ids\n",
    "\n",
    "    return np.mean(all_preds, axis=0), final_ids\n",
    "\n",
    "\n",
    "def predict_ensemble(models_dir, loaders, cfg):\n",
    "    \"\"\"Ensemble: N folds √ó 3 TTA\"\"\"\n",
    "    model_files = sorted(Path(models_dir).glob(\"model_fold*.pth\"))\n",
    "    print(f\"Found {len(model_files)} models\")\n",
    "\n",
    "    all_preds = []\n",
    "    final_ids = None\n",
    "\n",
    "    for mf in model_files:\n",
    "        print(f\"\\nLoading {mf.name}...\")\n",
    "\n",
    "        model = CSIROModelV2(cfg, load_backbone=False).to(cfg.device)\n",
    "        model.load_state_dict(torch.load(mf, map_location=cfg.device))\n",
    "\n",
    "        preds, ids = predict_with_tta(model, loaders, cfg.device)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "        if final_ids is None:\n",
    "            final_ids = ids\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return np.mean(all_preds, axis=0), final_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699ac44",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f29e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "test_df['sample_id_prefix'] = test_df['sample_id'].str.split('__').str[0]\n",
    "test_wide = test_df.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Test samples: {len(test_wide)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA loaders\n",
    "loaders = get_tta_loaders(test_wide, cfg)\n",
    "\n",
    "# Predict\n",
    "preds, sample_ids = predict_ensemble(cfg.MODELS_DIR, loaders, cfg)\n",
    "print(f\"Predictions: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "pred_df = pd.DataFrame(preds, columns=TARGET_ORDER)\n",
    "pred_df['sample_id_prefix'] = sample_ids\n",
    "\n",
    "sub_df = pred_df.melt(\n",
    "    id_vars=['sample_id_prefix'],\n",
    "    value_vars=TARGET_ORDER,\n",
    "    var_name='target_name',\n",
    "    value_name='target'\n",
    ")\n",
    "sub_df['sample_id'] = sub_df['sample_id_prefix'] + '__' + sub_df['target_name']\n",
    "\n",
    "submission = sub_df[['sample_id', 'target']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úì Submission: {len(submission)} rows\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify\n",
    "sample_sub = pd.read_csv(cfg.DATA_PATH / \"sample_submission.csv\")\n",
    "assert len(submission) == len(sample_sub), \"Row count mismatch!\"\n",
    "print(\"‚úì Format verified!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
