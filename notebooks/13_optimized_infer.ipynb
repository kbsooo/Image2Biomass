{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a566119b",
   "metadata": {},
   "source": [
    "# üöÄ Optimized DINOv3 Inference Pipeline\n",
    "\n",
    "**Model**: CSIROModelV2 (trained with 13_optimized_train.py)\n",
    "**Features**: TTA (Test Time Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ab983",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb53a8",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c047a32",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    MODELS_DIR = Path(\"/kaggle/input/csiro-optimized-models\")  # ÌïôÏäµÎêú Î™®Îç∏ Í≤ΩÎ°ú\n",
    "    WEIGHTS_PATH = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large\")\n",
    "    \n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb.lvd1689m\"  # DINOv3 Large\n",
    "    img_size = (512, 512)  # patch16 Î™®Îç∏\n",
    "    dropout = 0.3\n",
    "    \n",
    "    use_tta = True\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e96cd40",
   "metadata": {},
   "source": [
    "## Model Definition (Same as training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d93ff",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        return torch.chunk(gamma_beta, 2, dim=1)\n",
    "\n",
    "class ZeroInflatedHead(nn.Module):\n",
    "    def __init__(self, in_features, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        prob = torch.sigmoid(self.classifier(x))\n",
    "        amount = self.regressor(x)\n",
    "        return prob * amount\n",
    "\n",
    "class CSIROModelV2(nn.Module):\n",
    "    def __init__(self, model_name, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, pretrained=False, num_classes=0, global_pool='avg'\n",
    "        )\n",
    "        \n",
    "        feat_dim = self.backbone.num_features\n",
    "        self.film = FiLM(feat_dim)\n",
    "        \n",
    "        def make_head(in_dim, dropout):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_dim, 512),\n",
    "                nn.LayerNorm(512),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout * 0.5),\n",
    "                nn.Linear(128, 1),\n",
    "                nn.Softplus()\n",
    "            )\n",
    "        \n",
    "        combined_dim = feat_dim * 2\n",
    "        self.head_green = make_head(combined_dim, dropout)\n",
    "        self.head_dead = make_head(combined_dim, dropout)\n",
    "        self.head_clover = ZeroInflatedHead(combined_dim, dropout)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "        \n",
    "        green = self.head_green(combined)\n",
    "        clover = self.head_clover(combined)\n",
    "        dead = self.head_dead(combined)\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e66fd4",
   "metadata": {},
   "source": [
    "## TTA Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd4848",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_tta_transforms(cfg):\n",
    "    \"\"\"Test Time Augmentation: original + hflip + vflip\"\"\"\n",
    "    base = T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    hflip = T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.RandomHorizontalFlip(p=1.0),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    vflip = T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.RandomVerticalFlip(p=1.0),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return [base, hflip, vflip]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99dccff",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eca6bf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_single(model, img_path, transforms, cfg):\n",
    "    \"\"\"Single image prediction with TTA\"\"\"\n",
    "    img = Image.open(cfg.DATA_PATH / img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    mid_point = width // 2\n",
    "    \n",
    "    left_img = img.crop((0, 0, mid_point, height))\n",
    "    right_img = img.crop((mid_point, 0, width, height))\n",
    "    \n",
    "    all_preds = []\n",
    "    for transform in transforms:\n",
    "        left_t = transform(left_img).unsqueeze(0).to(cfg.device)\n",
    "        right_t = transform(right_img).unsqueeze(0).to(cfg.device)\n",
    "        \n",
    "        outputs = model(left_t, right_t)\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "    \n",
    "    return np.mean(all_preds, axis=0)\n",
    "\n",
    "def predict_all_folds(test_df, cfg):\n",
    "    \"\"\"Ensemble prediction across all folds\"\"\"\n",
    "    transforms = get_tta_transforms(cfg) if cfg.use_tta else [get_tta_transforms(cfg)[0]]\n",
    "    \n",
    "    all_fold_preds = []\n",
    "    \n",
    "    for model_path in sorted(cfg.MODELS_DIR.glob(\"model_fold*.pth\")):\n",
    "        print(f\"Loading {model_path.name}...\")\n",
    "        \n",
    "        model = CSIROModelV2(cfg.model_name, cfg.dropout)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=cfg.device))\n",
    "        model = model.to(cfg.device)\n",
    "        model.eval()\n",
    "        \n",
    "        fold_preds = []\n",
    "        for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "            pred = predict_single(model, row['image_path'], transforms, cfg)\n",
    "            fold_preds.append(pred)\n",
    "        \n",
    "        all_fold_preds.append(np.concatenate(fold_preds))\n",
    "    \n",
    "    # Average across folds\n",
    "    return np.mean(all_fold_preds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52fd1b8",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "    test_df['target'] = 0.0\n",
    "    test_df[['sample_id_prefix', 'sample_id_suffix']] = test_df.sample_id.str.split('__', expand=True)\n",
    "    \n",
    "    test_data = test_df.groupby(['sample_id_prefix', 'image_path']).apply(\n",
    "        lambda df: df.set_index('target_name').target\n",
    "    ).reset_index()\n",
    "    test_data.columns.name = None\n",
    "    \n",
    "    print(f\"Test samples: {len(test_data)}\")\n",
    "    \n",
    "    # Predict\n",
    "    preds = predict_all_folds(test_data, cfg)\n",
    "    \n",
    "    # Format predictions\n",
    "    test_data[['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']] = preds\n",
    "    \n",
    "    # Create submission\n",
    "    cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "    sub_df = test_data.set_index('sample_id_prefix')[cols].stack().reset_index()\n",
    "    sub_df.columns = ['sample_id_prefix', 'target_name', 'target']\n",
    "    sub_df['sample_id'] = sub_df.sample_id_prefix + '__' + sub_df.target_name\n",
    "    \n",
    "    sub_df[['sample_id', 'target']].to_csv('submission.csv', index=False)\n",
    "    print(\"\\n‚úì submission.csv created!\")\n",
    "    print(sub_df[['sample_id', 'target']].head(10))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
