{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ed8109",
   "metadata": {},
   "source": [
    "# ðŸ† DINOv3 ViT-Large Training Pipeline\n",
    "\n",
    "**ëª©í‘œ**: LB 0.70+ ë‹¬ì„± (Phase 1)\n",
    "\n",
    "**í•µì‹¬ ì „ëžµ** (070.py ì°¸ê³ ):\n",
    "1. DINOv3 ViT-Large backbone (`vit_large_patch16_dinov3_qkvb`)\n",
    "2. Left/Right ì´ë¯¸ì§€ ë¶„í•  (70Ã—30cm quadrat)\n",
    "3. FiLM fusion (Feature-wise Linear Modulation)\n",
    "4. 5-Fold Cross Validation\n",
    "5. í•™ìŠµ/ì¶”ë¡  ë¶„ë¦¬ (ê°€ì¤‘ì¹˜ ì €ìž¥ â†’ ë³„ë„ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164216c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import timm\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de743163",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f335f0d",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61776f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === Paths ===\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    OUTPUT_DIR = Path(\"/kaggle/working\")\n",
    "    WEIGHTS_PATH = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large\")\n",
    "    \n",
    "    # === Model ===\n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb\"\n",
    "    backbone_dim = 1024  # ViT-Large output dimension\n",
    "    img_size = (512, 512)\n",
    "    \n",
    "    # === Training ===\n",
    "    n_folds = 5\n",
    "    epochs = 15\n",
    "    batch_size = 16  # T4 x 2 = 32GB VRAM, batch 16 ê°€ëŠ¥\n",
    "    lr = 1e-4\n",
    "    use_multi_gpu = True  # DataParallel ì‚¬ìš©\n",
    "    backbone_lr_mult = 0.1  # backboneì€ ë‚®ì€ lr\n",
    "    weight_decay = 1e-4\n",
    "    dropout = 0.1\n",
    "    \n",
    "    # === Other ===\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()\n",
    "cfg.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"Model: {cfg.model_name}\")\n",
    "print(f\"Folds: {cfg.n_folds}, Epochs: {cfg.epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc1bce6",
   "metadata": {},
   "source": [
    "## Competition Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36915be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "TARGET_WEIGHTS = {\n",
    "    'Dry_Green_g': 0.1, 'Dry_Dead_g': 0.1, 'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2, 'Dry_Total_g': 0.5,\n",
    "}\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "def competition_metric(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Weighted RÂ² score.\"\"\"\n",
    "    total_weight = 0.0\n",
    "    weighted_r2 = 0.0\n",
    "    \n",
    "    for i, target in enumerate(TARGET_ORDER):\n",
    "        weight = TARGET_WEIGHTS[target]\n",
    "        ss_res = np.sum((y_true[:, i] - y_pred[:, i]) ** 2)\n",
    "        ss_tot = np.sum((y_true[:, i] - np.mean(y_true[:, i])) ** 2)\n",
    "        r2 = 1 - ss_res / (ss_tot + 1e-8)\n",
    "        weighted_r2 += weight * r2\n",
    "        total_weight += weight\n",
    "    \n",
    "    return weighted_r2 / total_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a306012",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977b01d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Pivot long format to wide format.\"\"\"\n",
    "    pivot = df.pivot_table(\n",
    "        index=['image_path', 'State', 'Species', 'Sampling_Date', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "        columns='target_name',\n",
    "        values='target',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    pivot.columns.name = None\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55950f1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(cfg.DATA_PATH / \"train.csv\")\n",
    "train_wide = prepare_data(train_df)\n",
    "train_wide['image_id'] = train_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "# Stratified Group KFold (by State, grouped by image)\n",
    "sgkf = StratifiedGroupKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "train_wide['fold'] = -1\n",
    "for fold, (_, val_idx) in enumerate(sgkf.split(\n",
    "    train_wide, \n",
    "    train_wide['State'],\n",
    "    groups=train_wide['image_id']\n",
    ")):\n",
    "    train_wide.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "print(f\"Train data shape: {train_wide.shape}\")\n",
    "print(f\"Fold distribution:\\n{train_wide['fold'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51182ec8",
   "metadata": {},
   "source": [
    "## Dataset with Left/Right Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c846cac",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    í•µì‹¬: ì´ë¯¸ì§€ë¥¼ Left/Rightë¡œ ë¶„í• í•˜ì—¬ ë°˜í™˜\n",
    "    - 70cm Ã— 30cm quadrat â†’ ê°€ë¡œë¡œ ê¸´ ì´ë¯¸ì§€\n",
    "    - ê° ì˜ì—­ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ í›„ fusion\n",
    "    \"\"\"\n",
    "    def __init__(self, df, cfg, transform=None, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img = Image.open(self.cfg.DATA_PATH / row['image_path']).convert('RGB')\n",
    "        width, height = img.size\n",
    "        mid_point = width // 2\n",
    "        \n",
    "        # Split into left and right halves\n",
    "        left_img = img.crop((0, 0, mid_point, height))\n",
    "        right_img = img.crop((mid_point, 0, width, height))\n",
    "        \n",
    "        if self.transform:\n",
    "            left_img = self.transform(left_img)\n",
    "            right_img = self.transform(right_img)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            # ë…ë¦½ íƒ€ê²Ÿ 3ê°œë§Œ (GDM, Totalì€ ê³„ì‚°ìœ¼ë¡œ ìœ ë„)\n",
    "            targets = torch.tensor([\n",
    "                row['Dry_Green_g'],\n",
    "                row['Dry_Clover_g'],\n",
    "                row['Dry_Dead_g']\n",
    "            ], dtype=torch.float32)\n",
    "            return left_img, right_img, targets\n",
    "        else:\n",
    "            return left_img, right_img, row['image_id']\n",
    "\n",
    "def get_train_transforms(cfg):\n",
    "    return T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_transforms(cfg):\n",
    "    return T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5ff64",
   "metadata": {},
   "source": [
    "## Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9622ba7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    \"\"\"\n",
    "    Feature-wise Linear Modulation\n",
    "    - Left/Right ì˜ì—­ì˜ í‰ê·  featureë¥¼ contextë¡œ ì‚¬ìš©\n",
    "    - Î³ (scale)ì™€ Î² (shift)ë¥¼ í•™ìŠµí•˜ì—¬ cross-region interaction êµ¬í˜„\n",
    "    \"\"\"\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)\n",
    "        return gamma, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1869c6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CSIROModel(nn.Module):\n",
    "    \"\"\"\n",
    "    DINOv3 ViT-Large + FiLM + Physics-constrained Heads\n",
    "    \n",
    "    Architecture:\n",
    "    1. Left/Right ì´ë¯¸ì§€ â†’ DINOv3 backbone â†’ ê°ê° 1024-dim feature\n",
    "    2. Context = (left + right) / 2\n",
    "    3. FiLMìœ¼ë¡œ feature modulation\n",
    "    4. Concatenate â†’ 3ê°œ Head (Green, Clover, Dead)\n",
    "    5. Physics layer: GDM = G + C, Total = GDM + D\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, pretrained=True, weights_path=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # DINOv3 ViT-Large backbone\n",
    "        if pretrained and weights_path and Path(weights_path).exists():\n",
    "            print(f\"Loading backbone from: {weights_path}\")\n",
    "            self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0, global_pool='avg')\n",
    "            state_dict = torch.load(weights_path, map_location='cpu', weights_only=True)\n",
    "            self.backbone.load_state_dict(state_dict, strict=False)\n",
    "            print(\"âœ“ Backbone loaded from local weights\")\n",
    "        else:\n",
    "            print(\"Loading backbone from timm (online)\")\n",
    "            self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool='avg')\n",
    "        \n",
    "        feat_dim = self.backbone.num_features  # 1024 for ViT-Large\n",
    "        print(f\"Backbone feature dim: {feat_dim}\")\n",
    "        \n",
    "        # FiLM for cross-region modulation\n",
    "        self.film = FiLM(feat_dim)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Independent heads for each target\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(feat_dim * 2, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(256, 1)\n",
    "            )\n",
    "        \n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        \n",
    "        # Softplus for non-negative outputs\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        # Extract features from both halves\n",
    "        left_feat = self.backbone(left_img)   # (B, 1024)\n",
    "        right_feat = self.backbone(right_img) # (B, 1024)\n",
    "        \n",
    "        # Compute context as average of both views\n",
    "        context = (left_feat + right_feat) / 2\n",
    "        \n",
    "        # Generate modulation parameters\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        # Modulate features\n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        # Concatenate modulated features\n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)  # (B, 2048)\n",
    "        combined = self.dropout(combined)\n",
    "        \n",
    "        # Predict independent targets\n",
    "        green = self.softplus(self.head_green(combined))\n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined))\n",
    "        \n",
    "        # Physics constraints\n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        # Return: [Green, Dead, Clover, GDM, Total] (competition order)\n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e01c0b",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb732fde",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, scheduler, device, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for left, right, targets in pbar:\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(left, right)\n",
    "            # Loss on Green, Clover, Dead (indices 0, 2, 1 in output)\n",
    "            pred = outputs[:, [0, 2, 1]]  # Reorder to [Green, Clover, Dead]\n",
    "            loss = F.mse_loss(pred, targets)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for left, right, targets in tqdm(loader, desc=\"Validating\"):\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        \n",
    "        outputs = model(left, right)\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_targets.append(targets.numpy())\n",
    "    \n",
    "    preds = np.concatenate(all_preds)\n",
    "    targets = np.concatenate(all_targets)\n",
    "    \n",
    "    # Compute full targets for metric\n",
    "    full_targets = np.zeros((len(targets), 5))\n",
    "    full_targets[:, 0] = targets[:, 0]  # Green\n",
    "    full_targets[:, 1] = targets[:, 2]  # Dead\n",
    "    full_targets[:, 2] = targets[:, 1]  # Clover\n",
    "    full_targets[:, 3] = targets[:, 0] + targets[:, 1]  # GDM = Green + Clover\n",
    "    full_targets[:, 4] = full_targets[:, 3] + targets[:, 2]  # Total = GDM + Dead\n",
    "    \n",
    "    score = competition_metric(full_targets, preds)\n",
    "    return score, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435ef0d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_fold(fold, train_df, cfg):\n",
    "    \"\"\"Train single fold\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "    \n",
    "    # Datasets & Loaders\n",
    "    train_ds = BiomassDataset(train_data, cfg, get_train_transforms(cfg), 'train')\n",
    "    val_ds = BiomassDataset(val_data, cfg, get_val_transforms(cfg), 'train')\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, \n",
    "                              shuffle=True, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size * 2,\n",
    "                            shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    \n",
    "    # Model\n",
    "    weights_path = cfg.WEIGHTS_PATH / \"dinov3_vitl16_qkvb.pth\"\n",
    "    model = CSIROModel(\n",
    "        cfg.model_name, \n",
    "        pretrained=True, \n",
    "        weights_path=weights_path,\n",
    "        dropout=cfg.dropout\n",
    "    )\n",
    "    \n",
    "    # Multi-GPU support\n",
    "    if cfg.use_multi_gpu and torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(cfg.device)\n",
    "    \n",
    "    # Optimizer with layer-wise learning rate decay\n",
    "    # Handle DataParallel wrapper\n",
    "    base_model = model.module if hasattr(model, 'module') else model\n",
    "    backbone_params = list(base_model.backbone.parameters())\n",
    "    head_params = (list(base_model.head_green.parameters()) + \n",
    "                   list(base_model.head_clover.parameters()) + \n",
    "                   list(base_model.head_dead.parameters()) + \n",
    "                   list(base_model.film.parameters()))\n",
    "    \n",
    "    optimizer = AdamW([\n",
    "        {'params': backbone_params, 'lr': cfg.lr * cfg.backbone_lr_mult},\n",
    "        {'params': head_params, 'lr': cfg.lr}\n",
    "    ], weight_decay=cfg.weight_decay)\n",
    "    \n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=len(train_loader),\n",
    "        num_training_steps=len(train_loader) * cfg.epochs\n",
    "    )\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Training loop\n",
    "    best_score = -float('inf')\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{cfg.epochs}\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, cfg.device, scaler)\n",
    "        val_score, _ = validate(model, val_loader, cfg.device)\n",
    "        \n",
    "        print(f\"Loss: {train_loss:.4f} | CV: {val_score:.4f}\")\n",
    "        \n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_epoch = epoch + 1\n",
    "            # Save model (handle DataParallel wrapper)\n",
    "            state_dict = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n",
    "            torch.save(state_dict, cfg.OUTPUT_DIR / f'model_fold{fold}.pth')\n",
    "            print(f\"  âœ“ New best! Saved.\")\n",
    "    \n",
    "    print(f\"\\nFold {fold} Best: {best_score:.4f} (epoch {best_epoch})\")\n",
    "    \n",
    "    flush()\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5fc5f",
   "metadata": {},
   "source": [
    "## Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold in range(cfg.n_folds):\n",
    "        score = train_fold(fold, train_wide, cfg)\n",
    "        fold_scores.append(score)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Fold scores: {fold_scores}\")\n",
    "    print(f\"Mean CV: {np.mean(fold_scores):.4f} Â± {np.std(fold_scores):.4f}\")\n",
    "    \n",
    "    # List saved models\n",
    "    print(\"\\nSaved models:\")\n",
    "    for f in sorted(cfg.OUTPUT_DIR.glob(\"model_fold*.pth\")):\n",
    "        print(f\"  {f.name}: {f.stat().st_size / 1e6:.1f} MB\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
