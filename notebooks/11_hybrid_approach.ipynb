{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "716fa5f6",
   "metadata": {},
   "source": [
    "# üß† Hybrid Approach: DINOv2 + Knowledge Distillation\n",
    "\n",
    "**Ï†ÑÎûµ**:\n",
    "1. Phase 1: Teacher Model ÌïôÏäµ (Image + Tabular ‚Üí Biomass)\n",
    "2. Phase 2: Soft Targets ÏÉùÏÑ±\n",
    "3. Phase 3: Student Model ÌïôÏäµ (Image only, KD Loss)\n",
    "4. Phase 4: Inference & Submission\n",
    "\n",
    "**Key Features**:\n",
    "- DINOv2 ViT-B/14 backbone (self-supervised, 142M images)\n",
    "- FiLM (Feature-wise Linear Modulation) for fusion\n",
    "- Zero-Inflated Regression for Clover\n",
    "- Physics Constraints (GDM = Green + Clover, Total = GDM + Dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f821474",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25343a3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddfc9d8",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === Paths (Kaggle) ===\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    OUTPUT_DIR = Path(\"/kaggle/working\")\n",
    "    WEIGHTS_PATH = Path(\"/kaggle/input/pretrained-weights-biomass\")\n",
    "    \n",
    "    # === Model ===\n",
    "    backbone = \"dinov2_vitb14\"  # DINOv2 ViT-B/14\n",
    "    backbone_dim = 768  # ViT-B/14 output dim\n",
    "    input_size = 518    # DINOv2 optimal (divisible by 14)\n",
    "    freeze_backbone = True  # Freeze DINOv2, only train heads\n",
    "    \n",
    "    # === Teacher ===\n",
    "    teacher_epochs = 15\n",
    "    teacher_lr = 2e-4\n",
    "    \n",
    "    # === Student ===\n",
    "    student_epochs = 20\n",
    "    student_lr = 1e-4\n",
    "    kd_alpha = 0.5  # Balance hard/soft loss\n",
    "    \n",
    "    # === Training ===\n",
    "    n_folds = 5\n",
    "    batch_size = 8  # DINOv2 is larger\n",
    "    weight_decay = 1e-4\n",
    "    \n",
    "    # === Tabular ===\n",
    "    tabular_cols = ['Pre_GSHH_NDVI', 'Height_Ave_cm']\n",
    "    \n",
    "    # === Misc ===\n",
    "    seed = 42\n",
    "    num_workers = 2\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()\n",
    "cfg.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"Backbone: {cfg.backbone}\")\n",
    "print(f\"Folds: {cfg.n_folds}, Teacher epochs: {cfg.teacher_epochs}, Student epochs: {cfg.student_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3bc11",
   "metadata": {},
   "source": [
    "## Competition Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b8266",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "TARGET_WEIGHTS = {\n",
    "    'Dry_Green_g': 0.1, 'Dry_Dead_g': 0.1, 'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2, 'Dry_Total_g': 0.5,\n",
    "}\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "def competition_metric(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Weighted R¬≤ score.\"\"\"\n",
    "    weights = np.array([TARGET_WEIGHTS[t] for t in TARGET_ORDER])\n",
    "    total_r2 = 0.0\n",
    "    for i in range(5):\n",
    "        ss_res = ((y_true[:, i] - y_pred[:, i]) ** 2).sum()\n",
    "        ss_tot = ((y_true[:, i] - y_true[:, i].mean()) ** 2).sum()\n",
    "        r2 = 1 - ss_res / (ss_tot + 1e-8)\n",
    "        total_r2 += weights[i] * r2\n",
    "    return total_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa99d3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998f79a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame, is_train: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Pivot long format to wide format.\"\"\"\n",
    "    if 'target' in df.columns:\n",
    "        df_wide = pd.pivot_table(\n",
    "            df, values='target',\n",
    "            index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "            columns='target_name', aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        df = df.copy()\n",
    "        cols = ['image_path']\n",
    "        for col in ['Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm']:\n",
    "            if col in df.columns:\n",
    "                cols.append(col)\n",
    "        df_wide = df.drop_duplicates(subset=['image_path'])[cols].reset_index(drop=True)\n",
    "    return df_wide\n",
    "\n",
    "def get_transforms(mode: str = 'train', size: int = 518) -> A.Compose:\n",
    "    if mode == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(size, size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.3, hue=0.05, p=0.7),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(size, size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3bdcb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(cfg.DATA_PATH / \"train.csv\")\n",
    "train_wide = prepare_data(train_df, is_train=True)\n",
    "train_wide['image_id'] = train_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "# Geographic Stratified KFold (by State)\n",
    "skf = StratifiedKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "train_wide['fold'] = -1\n",
    "for fold, (_, val_idx) in enumerate(skf.split(train_wide, train_wide['State'])):\n",
    "    train_wide.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "# Encode categoricals\n",
    "state_encoder = LabelEncoder()\n",
    "species_encoder = LabelEncoder()\n",
    "train_wide['state_encoded'] = state_encoder.fit_transform(train_wide['State'])\n",
    "train_wide['species_encoded'] = species_encoder.fit_transform(train_wide['Species'])\n",
    "\n",
    "# Month from date\n",
    "train_wide['month'] = pd.to_datetime(train_wide['Sampling_Date']).dt.month\n",
    "\n",
    "print(f\"Train data: {len(train_wide)} images\")\n",
    "print(f\"States: {train_wide['State'].nunique()}\")\n",
    "print(f\"Species: {train_wide['Species'].nunique()}\")\n",
    "print(f\"Fold distribution:\\n{train_wide['fold'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56968523",
   "metadata": {},
   "source": [
    "## Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc0ba9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DINOv2Backbone(nn.Module):\n",
    "    \"\"\"DINOv2 ViT-B/14 backbone with offline weight loading.\"\"\"\n",
    "    def __init__(self, model_name: str = \"dinov2_vitb14\", freeze: bool = True, weights_path: Path = None):\n",
    "        super().__init__()\n",
    "        self.feat_dim = 768  # ViT-B/14\n",
    "        \n",
    "        # Try loading from local weights (Kaggle offline)\n",
    "        # Path format: {WEIGHTS_PATH}/dinov2/dinov2_vitb14.pth\n",
    "        weight_file = None\n",
    "        if weights_path and weights_path.exists():\n",
    "            weight_file = weights_path / \"dinov2\" / f\"{model_name}.pth\"\n",
    "        \n",
    "        if weight_file and weight_file.exists():\n",
    "            # Load DINOv2 architecture from timm\n",
    "            self.backbone = timm.create_model('vit_base_patch14_dinov2.lvd142m', pretrained=False, num_classes=0)\n",
    "            state_dict = torch.load(weight_file, map_location='cpu', weights_only=True)\n",
    "            self.backbone.load_state_dict(state_dict, strict=False)\n",
    "            print(f\"‚úì DINOv2 loaded from: {weight_file}\")\n",
    "        else:\n",
    "            # Fallback: won't work offline!\n",
    "            print(f\"‚ö† Local weights not found at {weight_file}, trying online...\")\n",
    "            self.backbone = timm.create_model('vit_base_patch14_dinov2.lvd142m', pretrained=True, num_classes=0)\n",
    "        \n",
    "        print(f\"‚úì DINOv2 backbone: feat_dim={self.feat_dim}\")\n",
    "        \n",
    "        if freeze:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"‚úì DINOv2 backbone frozen\")\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "class TabularEncoder(nn.Module):\n",
    "    \"\"\"Encode tabular features: NDVI, Height, State, Species, Month.\"\"\"\n",
    "    def __init__(self, n_states: int = 4, n_species: int = 30, embed_dim: int = 16, output_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.cont_bn = nn.BatchNorm1d(2)\n",
    "        self.cont_linear = nn.Linear(2, 64)\n",
    "        self.state_embed = nn.Embedding(n_states, embed_dim)\n",
    "        self.species_embed = nn.Embedding(n_species, embed_dim)\n",
    "        self.month_linear = nn.Linear(2, embed_dim)  # sin/cos\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(64 + embed_dim * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, continuous, state, species, month):\n",
    "        cont = self.cont_linear(self.cont_bn(continuous))\n",
    "        state_emb = self.state_embed(state)\n",
    "        species_emb = self.species_embed(species)\n",
    "        \n",
    "        month_rad = (month.float() - 1) / 12 * 2 * math.pi\n",
    "        month_enc = self.month_linear(torch.stack([torch.sin(month_rad), torch.cos(month_rad)], dim=-1))\n",
    "        \n",
    "        all_feat = torch.cat([cont, state_emb, species_emb, month_enc], dim=-1)\n",
    "        return self.fusion(all_feat)\n",
    "\n",
    "\n",
    "class FiLMFusion(nn.Module):\n",
    "    \"\"\"Feature-wise Linear Modulation.\"\"\"\n",
    "    def __init__(self, img_dim: int, tab_dim: int):\n",
    "        super().__init__()\n",
    "        self.gamma_net = nn.Sequential(nn.Linear(tab_dim, img_dim), nn.Tanh())\n",
    "        self.beta_net = nn.Linear(tab_dim, img_dim)\n",
    "    \n",
    "    def forward(self, img_feat, tab_feat):\n",
    "        gamma = self.gamma_net(tab_feat)\n",
    "        beta = self.beta_net(tab_feat)\n",
    "        return img_feat * (1 + gamma) + beta\n",
    "\n",
    "\n",
    "class ZeroInflatedHead(nn.Module):\n",
    "    \"\"\"Two-stage prediction for zero-inflated Clover.\"\"\"\n",
    "    def __init__(self, in_features: int):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 64), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1), nn.Sigmoid()\n",
    "        )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(in_features, 64), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1), nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        p = self.classifier(x)\n",
    "        amount = self.regressor(x)\n",
    "        return p, amount, p * amount\n",
    "\n",
    "\n",
    "class PhysicsHead(nn.Module):\n",
    "    \"\"\"Physics-constrained prediction head.\"\"\"\n",
    "    def __init__(self, in_features: int, use_zero_inflated: bool = True):\n",
    "        super().__init__()\n",
    "        self.use_zero_inflated = use_zero_inflated\n",
    "        \n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(in_features, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128), nn.ReLU(), nn.Dropout(0.3)\n",
    "        )\n",
    "        self.green_head = nn.Sequential(nn.Linear(128, 1), nn.Softplus())\n",
    "        self.dead_head = nn.Sequential(nn.Linear(128, 1), nn.Softplus())\n",
    "        \n",
    "        if use_zero_inflated:\n",
    "            self.clover_head = ZeroInflatedHead(128)\n",
    "        else:\n",
    "            self.clover_head = nn.Sequential(nn.Linear(128, 1), nn.Softplus())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat = self.shared(x)\n",
    "        green = self.green_head(feat)\n",
    "        dead = self.dead_head(feat)\n",
    "        \n",
    "        if self.use_zero_inflated:\n",
    "            clover_p, clover_amt, clover = self.clover_head(feat)\n",
    "        else:\n",
    "            clover = self.clover_head(feat)\n",
    "            clover_p, clover_amt = None, None\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        # [Green, Dead, Clover, GDM, Total]\n",
    "        full = torch.cat([green, dead, clover, gdm, total], dim=1)\n",
    "        independent = torch.cat([green, clover, dead], dim=1)\n",
    "        \n",
    "        return {'full': full, 'independent': independent, 'clover_p': clover_p, 'clover_amt': clover_amt}\n",
    "\n",
    "\n",
    "class TeacherModel(nn.Module):\n",
    "    \"\"\"Teacher: Image + Tabular ‚Üí Biomass\"\"\"\n",
    "    def __init__(self, cfg, n_states, n_species):\n",
    "        super().__init__()\n",
    "        self.backbone = DINOv2Backbone(cfg.backbone, cfg.freeze_backbone, cfg.WEIGHTS_PATH)\n",
    "        self.tabular_encoder = TabularEncoder(n_states, n_species)\n",
    "        self.fusion = FiLMFusion(cfg.backbone_dim, 128)\n",
    "        self.head = PhysicsHead(cfg.backbone_dim)\n",
    "    \n",
    "    def forward(self, image, continuous, state, species, month):\n",
    "        img_feat = self.backbone(image)\n",
    "        tab_feat = self.tabular_encoder(continuous, state, species, month)\n",
    "        fused = self.fusion(img_feat, tab_feat)\n",
    "        return self.head(fused), fused\n",
    "\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    \"\"\"Student: Image only ‚Üí Biomass\"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.backbone = DINOv2Backbone(cfg.backbone, cfg.freeze_backbone, cfg.WEIGHTS_PATH)\n",
    "        self.head = PhysicsHead(cfg.backbone_dim)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        img_feat = self.backbone(image)\n",
    "        return self.head(img_feat), img_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a9cc3",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1442a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TeacherDataset(Dataset):\n",
    "    \"\"\"Dataset for Teacher (Image + Tabular ‚Üí Biomass).\"\"\"\n",
    "    def __init__(self, df, cfg, transforms=None, tabular_scaler=None, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # Scale tabular\n",
    "        tabular = df[cfg.tabular_cols].values.astype(np.float32)\n",
    "        if tabular_scaler is not None:\n",
    "            if mode == 'train':\n",
    "                self.tabular = tabular_scaler.fit_transform(tabular)\n",
    "            else:\n",
    "                self.tabular = tabular_scaler.transform(tabular)\n",
    "        else:\n",
    "            self.tabular = tabular\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        img = cv2.imread(str(self.cfg.DATA_PATH / row['image_path']))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        continuous = torch.tensor(self.tabular[idx], dtype=torch.float32)\n",
    "        state = torch.tensor(row['state_encoded'], dtype=torch.long)\n",
    "        species = torch.tensor(row['species_encoded'], dtype=torch.long)\n",
    "        month = torch.tensor(row['month'], dtype=torch.long)\n",
    "        \n",
    "        targets = torch.tensor([\n",
    "            row['Dry_Green_g'], row['Dry_Clover_g'], row['Dry_Dead_g']\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        full_targets = torch.tensor([\n",
    "            row['Dry_Green_g'], row['Dry_Dead_g'], row['Dry_Clover_g'],\n",
    "            row['GDM_g'], row['Dry_Total_g']\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        return {\n",
    "            'image': img,\n",
    "            'continuous': continuous,\n",
    "            'state': state,\n",
    "            'species': species,\n",
    "            'month': month,\n",
    "            'targets': targets,\n",
    "            'full_targets': full_targets,\n",
    "            'image_id': row['image_id']\n",
    "        }\n",
    "\n",
    "\n",
    "class StudentDataset(Dataset):\n",
    "    \"\"\"Dataset for Student (Image only).\"\"\"\n",
    "    def __init__(self, df, cfg, transforms=None, soft_targets=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transforms = transforms\n",
    "        self.soft_targets = soft_targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        img = cv2.imread(str(self.cfg.DATA_PATH / row['image_path']))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        targets = torch.tensor([\n",
    "            row['Dry_Green_g'], row['Dry_Clover_g'], row['Dry_Dead_g']\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        full_targets = torch.tensor([\n",
    "            row['Dry_Green_g'], row['Dry_Dead_g'], row['Dry_Clover_g'],\n",
    "            row['GDM_g'], row['Dry_Total_g']\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        result = {\n",
    "            'image': img,\n",
    "            'targets': targets,\n",
    "            'full_targets': full_targets,\n",
    "            'image_id': row['image_id']\n",
    "        }\n",
    "        \n",
    "        if self.soft_targets and row['image_id'] in self.soft_targets:\n",
    "            result['soft_target'] = self.soft_targets[row['image_id']]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb655f2",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b28b9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_teacher_fold(fold: int, train_df: pd.DataFrame, cfg, n_states, n_species) -> Tuple[float, Dict]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üéì PHASE 1: Teacher Model - Fold {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "    \n",
    "    tabular_scaler = StandardScaler()\n",
    "    \n",
    "    train_ds = TeacherDataset(train_data, cfg, get_transforms('train', cfg.input_size), tabular_scaler, 'train')\n",
    "    val_ds = TeacherDataset(val_data, cfg, get_transforms('val', cfg.input_size), tabular_scaler, 'val')\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size * 2, shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    \n",
    "    model = TeacherModel(cfg, n_states, n_species)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"üöÄ Using {torch.cuda.device_count()} GPUs\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(cfg.device)\n",
    "    \n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=cfg.teacher_lr, weight_decay=cfg.weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=cfg.teacher_epochs)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_score = -float('inf')\n",
    "    best_state = None\n",
    "    \n",
    "    for epoch in range(cfg.teacher_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f'Teacher E{epoch+1}', leave=False):\n",
    "            imgs = batch['image'].to(cfg.device)\n",
    "            cont = batch['continuous'].to(cfg.device)\n",
    "            state = batch['state'].to(cfg.device)\n",
    "            species = batch['species'].to(cfg.device)\n",
    "            month = batch['month'].to(cfg.device)\n",
    "            targets = batch['targets'].to(cfg.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output, _ = model(imgs, cont, state, species, month)\n",
    "                loss = F.mse_loss(output['independent'], targets)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                imgs = batch['image'].to(cfg.device)\n",
    "                cont = batch['continuous'].to(cfg.device)\n",
    "                state = batch['state'].to(cfg.device)\n",
    "                species = batch['species'].to(cfg.device)\n",
    "                month = batch['month'].to(cfg.device)\n",
    "                full_targets = batch['full_targets']\n",
    "                \n",
    "                output, _ = model(imgs, cont, state, species, month)\n",
    "                all_preds.append(output['full'].cpu().numpy())\n",
    "                all_targets.append(full_targets.numpy())\n",
    "        \n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        cv_score = competition_metric(all_targets, all_preds)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{cfg.teacher_epochs} | Loss: {train_loss:.4f} | CV: {cv_score:.4f}\")\n",
    "        \n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            best_state = {k: v.cpu() for k, v in model_to_save.state_dict().items()}\n",
    "            torch.save({\n",
    "                'model_state_dict': best_state,\n",
    "                'score': best_score,\n",
    "                'tabular_scaler': tabular_scaler,\n",
    "            }, cfg.OUTPUT_DIR / f'teacher_fold{fold}.pt')\n",
    "            print(f\"  ‚úì New best!\")\n",
    "    \n",
    "    flush()\n",
    "    return best_score, tabular_scaler\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_soft_targets(model, loader, cfg):\n",
    "    \"\"\"Generate soft targets from teacher.\"\"\"\n",
    "    model.eval()\n",
    "    soft_targets = {}\n",
    "    \n",
    "    for batch in tqdm(loader, desc='Generating Soft Targets'):\n",
    "        imgs = batch['image'].to(cfg.device)\n",
    "        cont = batch['continuous'].to(cfg.device)\n",
    "        state = batch['state'].to(cfg.device)\n",
    "        species = batch['species'].to(cfg.device)\n",
    "        month = batch['month'].to(cfg.device)\n",
    "        image_ids = batch['image_id']\n",
    "        \n",
    "        output, _ = model(imgs, cont, state, species, month)\n",
    "        \n",
    "        for i, img_id in enumerate(image_ids):\n",
    "            soft_targets[img_id] = output['independent'][i].cpu()\n",
    "    \n",
    "    return soft_targets\n",
    "\n",
    "\n",
    "def train_student_fold(fold: int, train_df: pd.DataFrame, soft_targets: Dict, cfg) -> float:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üéØ PHASE 2: Student Model (KD) - Fold {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "    \n",
    "    train_ds = StudentDataset(train_data, cfg, get_transforms('train', cfg.input_size), soft_targets)\n",
    "    val_ds = StudentDataset(val_data, cfg, get_transforms('val', cfg.input_size))\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size * 2, shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    \n",
    "    model = StudentModel(cfg)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"üöÄ Using {torch.cuda.device_count()} GPUs\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(cfg.device)\n",
    "    \n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=cfg.student_lr, weight_decay=cfg.weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=cfg.student_epochs)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_score = -float('inf')\n",
    "    \n",
    "    for epoch in range(cfg.student_epochs):\n",
    "        model.train()\n",
    "        train_loss, hard_loss_sum, soft_loss_sum = 0, 0, 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f'Student E{epoch+1}', leave=False):\n",
    "            imgs = batch['image'].to(cfg.device)\n",
    "            targets = batch['targets'].to(cfg.device)\n",
    "            \n",
    "            # Get soft targets\n",
    "            soft = torch.stack([batch['soft_target'][i] for i in range(len(batch['image_id']))]).to(cfg.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output, _ = model(imgs)\n",
    "                pred = output['independent']\n",
    "                \n",
    "                hard_loss = F.mse_loss(pred, targets)\n",
    "                soft_loss = F.mse_loss(pred, soft)\n",
    "                loss = cfg.kd_alpha * hard_loss + (1 - cfg.kd_alpha) * soft_loss\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            hard_loss_sum += hard_loss.item()\n",
    "            soft_loss_sum += soft_loss.item()\n",
    "        \n",
    "        n = len(train_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                imgs = batch['image'].to(cfg.device)\n",
    "                full_targets = batch['full_targets']\n",
    "                \n",
    "                output, _ = model(imgs)\n",
    "                all_preds.append(output['full'].cpu().numpy())\n",
    "                all_targets.append(full_targets.numpy())\n",
    "        \n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        cv_score = competition_metric(all_targets, all_preds)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{cfg.student_epochs} | Loss: {train_loss/n:.4f} (H:{hard_loss_sum/n:.4f} S:{soft_loss_sum/n:.4f}) | CV: {cv_score:.4f}\")\n",
    "        \n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            torch.save({\n",
    "                'model_state_dict': {k: v.cpu() for k, v in model_to_save.state_dict().items()},\n",
    "                'score': best_score,\n",
    "            }, cfg.OUTPUT_DIR / f'student_fold{fold}.pt')\n",
    "            print(f\"  ‚úì New best!\")\n",
    "    \n",
    "    flush()\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e58b8c",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14479d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = train_wide['state_encoded'].nunique()\n",
    "n_species = train_wide['species_encoded'].nunique()\n",
    "print(f\"n_states: {n_states}, n_species: {n_species}\")\n",
    "\n",
    "teacher_scores = []\n",
    "student_scores = []\n",
    "all_soft_targets = {}\n",
    "\n",
    "for fold in range(cfg.n_folds):\n",
    "    # Phase 1: Train Teacher\n",
    "    teacher_score, tabular_scaler = train_teacher_fold(fold, train_wide, cfg, n_states, n_species)\n",
    "    teacher_scores.append(teacher_score)\n",
    "    \n",
    "    # Load teacher for soft target generation\n",
    "    ckpt = torch.load(cfg.OUTPUT_DIR / f'teacher_fold{fold}.pt', weights_only=False)\n",
    "    teacher = TeacherModel(cfg, n_states, n_species).to(cfg.device)\n",
    "    teacher.load_state_dict(ckpt['model_state_dict'])\n",
    "    \n",
    "    # Generate soft targets for training data\n",
    "    train_data = train_wide[train_wide['fold'] != fold].reset_index(drop=True)\n",
    "    train_ds = TeacherDataset(train_data, cfg, get_transforms('val', cfg.input_size), tabular_scaler, 'val')\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size * 2, shuffle=False, num_workers=cfg.num_workers)\n",
    "    \n",
    "    fold_soft_targets = generate_soft_targets(teacher, train_loader, cfg)\n",
    "    all_soft_targets.update(fold_soft_targets)\n",
    "    print(f\"Generated {len(fold_soft_targets)} soft targets\")\n",
    "    \n",
    "    del teacher\n",
    "    flush()\n",
    "    \n",
    "    # Phase 2: Train Student with KD\n",
    "    student_score = train_student_fold(fold, train_wide, all_soft_targets, cfg)\n",
    "    student_scores.append(student_score)\n",
    "    \n",
    "    print(f\"Fold {fold} | Teacher CV: {teacher_score:.4f} | Student CV: {student_score:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üìä Overall Results\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Teacher CV: {np.mean(teacher_scores):.4f} ¬± {np.std(teacher_scores):.4f}\")\n",
    "print(f\"Student CV: {np.mean(student_scores):.4f} ¬± {np.std(student_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a39d06",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "test_wide = prepare_data(test_df, is_train=False)\n",
    "test_wide['image_id'] = test_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "print(f\"\\nTest data: {len(test_wide)} images\")\n",
    "\n",
    "# Create test dataset (image only for student)\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, cfg, transforms):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = cv2.imread(str(self.cfg.DATA_PATH / row['image_path']))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        return img, row['image_id']\n",
    "\n",
    "test_ds = TestDataset(test_wide, cfg, get_transforms('val', cfg.input_size))\n",
    "test_loader = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8854c5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load student models and inference\n",
    "models = []\n",
    "for fold in range(cfg.n_folds):\n",
    "    ckpt = torch.load(cfg.OUTPUT_DIR / f'student_fold{fold}.pt', weights_only=False)\n",
    "    model = StudentModel(cfg).to(cfg.device)\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "    print(f\"‚úì Loaded student fold {fold} (CV: {ckpt['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1fd822",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference(models, loader, device):\n",
    "    all_preds = []\n",
    "    all_ids = []\n",
    "    \n",
    "    for imgs, img_ids in tqdm(loader, desc='Inference'):\n",
    "        imgs = imgs.to(device)\n",
    "        batch_preds = []\n",
    "        \n",
    "        for model in models:\n",
    "            output, _ = model(imgs)\n",
    "            batch_preds.append(output['full'].cpu().numpy())\n",
    "        \n",
    "        avg_pred = np.mean(batch_preds, axis=0)\n",
    "        all_preds.append(avg_pred)\n",
    "        all_ids.extend(img_ids)\n",
    "    \n",
    "    return np.concatenate(all_preds), all_ids\n",
    "\n",
    "preds, image_ids = inference(models, test_loader, cfg.device)\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b88704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission_rows = []\n",
    "for i, img_id in enumerate(image_ids):\n",
    "    for j, target in enumerate(TARGET_ORDER):\n",
    "        submission_rows.append({\n",
    "            'sample_id': f\"{img_id}__{target}\",\n",
    "            'target': max(0, preds[i, j])  # Ensure non-negative\n",
    "        })\n",
    "\n",
    "submission = pd.DataFrame(submission_rows)\n",
    "submission.to_csv(cfg.OUTPUT_DIR / 'submission.csv', index=False)\n",
    "\n",
    "# Verify physics constraints\n",
    "print(f\"\\n‚úì Physics constraint check:\")\n",
    "for i, img_id in enumerate(image_ids):\n",
    "    green, dead, clover, gdm, total = preds[i]\n",
    "    print(f\"  {img_id}: GDM=G+C: {np.isclose(gdm, green+clover)}, Total=GDM+D: {np.isclose(total, gdm+dead)}\")\n",
    "\n",
    "print(f\"\\nüìÑ Submission saved: {len(submission)} rows\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "{'='*60}\n",
    "üèÜ Hybrid Approach Complete!\n",
    "{'='*60}\n",
    "\n",
    "Pipeline:\n",
    "1. Teacher (Image + Tabular) trained with FiLM fusion\n",
    "2. Soft targets generated for Knowledge Distillation\n",
    "3. Student (Image only) trained with KD loss\n",
    "\n",
    "Results:\n",
    "  Teacher CV: {np.mean(teacher_scores):.4f} ¬± {np.std(teacher_scores):.4f}\n",
    "  Student CV: {np.mean(student_scores):.4f} ¬± {np.std(student_scores):.4f}\n",
    "\n",
    "Output: {cfg.OUTPUT_DIR / 'submission.csv'}\n",
    "{'='*60}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
