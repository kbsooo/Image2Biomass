{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1463952c",
   "metadata": {},
   "source": [
    "# v24 Inference with Test-Time Adaptation (TENT)\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**:\n",
    "- Inference ì¤‘ LayerNorm íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ Test ë¶„í¬ì— ì ì‘\n",
    "- Regressionì— ë§ê²Œ ë³€í˜•: Prediction Variance Minimization\n",
    "\n",
    "**ê³¼ì •**:\n",
    "1. v20/v23 ëª¨ë¸ ë¡œë“œ\n",
    "2. Test ë°°ì¹˜ë§ˆë‹¤ TENT ì ì‘ (LayerNormë§Œ ì—…ë°ì´íŠ¸)\n",
    "3. ì ì‘ëœ ëª¨ë¸ë¡œ ìµœì¢… ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e089345",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import timm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3d5c5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a4545",
   "metadata": {},
   "source": [
    "## âš™ï¸ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136b15d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    BACKBONE_WEIGHTS = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large/dinov3_vitl16_qkvb.pth\")\n",
    "    \n",
    "    # âš ï¸ ê¸°ì¡´ v20 ë˜ëŠ” v23 ëª¨ë¸ ê²½ë¡œ\n",
    "    MODELS_DIR = Path(\"/kaggle/input/csiro-v20-models\")  # v20 ë˜ëŠ” v23\n",
    "    \n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb.lvd1689m\"\n",
    "    img_size = (512, 512)\n",
    "    \n",
    "    # Model êµ¬ì¡°\n",
    "    hidden_dim = 512\n",
    "    num_layers = 3\n",
    "    dropout = 0.1\n",
    "    use_layernorm = True\n",
    "    \n",
    "    batch_size = 8  # TENTëŠ” ì‘ì€ ë°°ì¹˜ ì‚¬ìš©\n",
    "    num_workers = 0\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # === TENT ì„¤ì • ===\n",
    "    tent_lr = 1e-5  # LayerNorm ì—…ë°ì´íŠ¸ lr (ë§¤ìš° ì‘ê²Œ)\n",
    "    tent_steps = 1  # ë°°ì¹˜ë‹¹ ì ì‘ ìŠ¤í… ìˆ˜\n",
    "    tent_augmentations = 4  # variance ê³„ì‚°ìš© augmentation ìˆ˜\n",
    "\n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9977b",
   "metadata": {},
   "source": [
    "## ğŸ“Š Dataset (TENTìš© Augmentation í¬í•¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592d463",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TENTDataset(Dataset):\n",
    "    \"\"\"TENTìš© Dataset: augmentation ì ìš©ëœ ì—¬ëŸ¬ ë²„ì „ ë°˜í™˜\"\"\"\n",
    "    def __init__(self, df, cfg, base_transform, aug_transform, num_augs=4):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.base_transform = base_transform\n",
    "        self.aug_transform = aug_transform\n",
    "        self.num_augs = num_augs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(self.cfg.DATA_PATH / row['image_path']).convert('RGB')\n",
    "        width, height = img.size\n",
    "        mid = width // 2\n",
    "        \n",
    "        left_pil = img.crop((0, 0, mid, height))\n",
    "        right_pil = img.crop((mid, 0, width, height))\n",
    "        \n",
    "        # ê¸°ë³¸ ë³€í™˜ (ìµœì¢… ì˜ˆì¸¡ìš©)\n",
    "        left_base = self.base_transform(left_pil)\n",
    "        right_base = self.base_transform(right_pil)\n",
    "        \n",
    "        # Augmentation ë²„ì „ë“¤ (TENT ì ì‘ìš©)\n",
    "        left_augs = [self.aug_transform(left_pil) for _ in range(self.num_augs)]\n",
    "        right_augs = [self.aug_transform(right_pil) for _ in range(self.num_augs)]\n",
    "        \n",
    "        return (left_base, right_base, \n",
    "                torch.stack(left_augs), torch.stack(right_augs),\n",
    "                row['sample_id_prefix'])\n",
    "\n",
    "\n",
    "def get_transforms(cfg):\n",
    "    base = T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    aug = T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return base, aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c9473",
   "metadata": {},
   "source": [
    "## ğŸ§  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce504e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        return torch.chunk(self.mlp(context), 2, dim=1)\n",
    "\n",
    "\n",
    "def make_head(in_dim, hidden_dim, num_layers, dropout, use_layernorm):\n",
    "    layers = []\n",
    "    current_dim = in_dim\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        layers.append(nn.Linear(current_dim, hidden_dim))\n",
    "        if i < num_layers - 1:\n",
    "            if use_layernorm:\n",
    "                layers.append(nn.LayerNorm(hidden_dim))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        current_dim = hidden_dim\n",
    "    \n",
    "    layers.append(nn.Linear(hidden_dim, 1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class CSIROModelV20(nn.Module):\n",
    "    \"\"\"v20/v23 í˜¸í™˜ ëª¨ë¸\"\"\"\n",
    "    def __init__(self, cfg, backbone_weights_path=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if backbone_weights_path and Path(backbone_weights_path).exists():\n",
    "            self.backbone = timm.create_model(cfg.model_name, pretrained=False, \n",
    "                                               num_classes=0, global_pool='avg')\n",
    "            state = torch.load(backbone_weights_path, map_location='cpu', weights_only=True)\n",
    "            self.backbone.load_state_dict(state, strict=False)\n",
    "        else:\n",
    "            self.backbone = timm.create_model(cfg.model_name, pretrained=True, \n",
    "                                               num_classes=0, global_pool='avg')\n",
    "        \n",
    "        feat_dim = self.backbone.num_features\n",
    "        combined_dim = feat_dim * 2\n",
    "        \n",
    "        self.film = FiLM(feat_dim)\n",
    "        \n",
    "        self.head_green = make_head(combined_dim, cfg.hidden_dim, cfg.num_layers, \n",
    "                                    cfg.dropout, cfg.use_layernorm)\n",
    "        self.head_clover = make_head(combined_dim, cfg.hidden_dim, cfg.num_layers,\n",
    "                                     cfg.dropout, cfg.use_layernorm)\n",
    "        self.head_dead = make_head(combined_dim, cfg.hidden_dim, cfg.num_layers,\n",
    "                                   cfg.dropout, cfg.use_layernorm)\n",
    "        \n",
    "        self.head_height = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.head_ndvi = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "        \n",
    "        green = self.softplus(self.head_green(combined))\n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined))\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c77c2",
   "metadata": {},
   "source": [
    "## ğŸ”§ TENT: Test-Time Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd4293",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def configure_tent(model, cfg):\n",
    "    \"\"\"\n",
    "    TENTë¥¼ ìœ„í•œ ëª¨ë¸ ì„¤ì •\n",
    "    - LayerNorm íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •\n",
    "    - ë‚˜ë¨¸ì§€ëŠ” ê³ ì •\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.requires_grad_(False)\n",
    "    \n",
    "    # LayerNorm íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ\n",
    "    trainable_params = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.LayerNorm):\n",
    "            module.requires_grad_(True)\n",
    "            trainable_params.extend(module.parameters())\n",
    "    \n",
    "    print(f\"TENT: {len(trainable_params)} LayerNorm parameters trainable\")\n",
    "    \n",
    "    if len(trainable_params) == 0:\n",
    "        print(\"Warning: No LayerNorm parameters found, TENT disabled\")\n",
    "        return model, None\n",
    "    \n",
    "    optimizer = torch.optim.Adam(trainable_params, lr=cfg.tent_lr)\n",
    "    \n",
    "    return model, optimizer\n",
    "\n",
    "\n",
    "def tent_adapt_batch(model, optimizer, left_augs, right_augs, cfg):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ ë°°ì¹˜ì— ëŒ€í•´ TENT ì ì‘ ìˆ˜í–‰\n",
    "    \n",
    "    Args:\n",
    "        left_augs: [B, num_augs, C, H, W]\n",
    "        right_augs: [B, num_augs, C, H, W]\n",
    "    \"\"\"\n",
    "    if optimizer is None:\n",
    "        return 0.0  # TENT disabled\n",
    "    \n",
    "    try:\n",
    "        B, N, C, H, W = left_augs.shape\n",
    "        \n",
    "        for step in range(cfg.tent_steps):\n",
    "            all_preds = []\n",
    "            \n",
    "            # ê° augmentationì— ëŒ€í•´ ì˜ˆì¸¡\n",
    "            for i in range(N):\n",
    "                left = left_augs[:, i]  # [B, C, H, W]\n",
    "                right = right_augs[:, i]\n",
    "                \n",
    "                pred = model(left, right)  # [B, 5]\n",
    "                all_preds.append(pred)\n",
    "            \n",
    "            # [N, B, 5] -> variance ê³„ì‚°\n",
    "            preds_stack = torch.stack(all_preds, dim=0)  # [N, B, 5]\n",
    "            \n",
    "            # Prediction varianceë¥¼ lossë¡œ ì‚¬ìš© (varianceê°€ ì‘ì„ìˆ˜ë¡ confident)\n",
    "            variance = torch.var(preds_stack, dim=0).mean()  # scalar\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            variance.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        return variance.item()\n",
    "    except Exception as e:\n",
    "        print(f\"TENT adapt error: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6807f87",
   "metadata": {},
   "source": [
    "## ğŸ”® Inference with TENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6abceb2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def predict_with_tent(model, loader, cfg, device):\n",
    "    \"\"\"TENT ì ì‘ + ì˜ˆì¸¡\"\"\"\n",
    "    model, optimizer = configure_tent(model, cfg)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    all_outputs = []\n",
    "    all_ids = []\n",
    "    all_variances = []\n",
    "    \n",
    "    for left_base, right_base, left_augs, right_augs, ids in tqdm(loader, desc=\"TENT\"):\n",
    "        try:\n",
    "            left_base = left_base.to(device)\n",
    "            right_base = right_base.to(device)\n",
    "            left_augs = left_augs.to(device)\n",
    "            right_augs = right_augs.to(device)\n",
    "            \n",
    "            # 1. TENT ì ì‘ (ì´ ë°°ì¹˜ì˜ ë¶„í¬ì— ë§ê²Œ LayerNorm ì—…ë°ì´íŠ¸)\n",
    "            var = tent_adapt_batch(model, optimizer, left_augs, right_augs, cfg)\n",
    "            all_variances.append(var)\n",
    "            \n",
    "            # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "            del left_augs, right_augs\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # 2. ìµœì¢… ì˜ˆì¸¡ (ê¸°ë³¸ transform ì‚¬ìš©)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(left_base, right_base)\n",
    "            \n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "            all_ids.extend(ids)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Batch error: {e}\")\n",
    "            # ì—ëŸ¬ ì‹œ ê¸°ë³¸ ì˜ˆì¸¡\n",
    "            with torch.no_grad():\n",
    "                outputs = model(left_base.to(device), right_base.to(device))\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "            all_ids.extend(ids)\n",
    "    \n",
    "    print(f\"Average variance: {np.mean(all_variances):.6f}\")\n",
    "    \n",
    "    return np.concatenate(all_outputs), all_ids\n",
    "\n",
    "\n",
    "def predict_ensemble_tent(cfg, test_df):\n",
    "    \"\"\"5-fold ì•™ìƒë¸” + TENT\"\"\"\n",
    "    base_transform, aug_transform = get_transforms(cfg)\n",
    "    \n",
    "    dataset = TENTDataset(test_df, cfg, base_transform, aug_transform, \n",
    "                          num_augs=cfg.tent_augmentations)\n",
    "    loader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=False,\n",
    "                       num_workers=cfg.num_workers, pin_memory=True)\n",
    "    \n",
    "    all_fold_preds = []\n",
    "    model_files = sorted(cfg.MODELS_DIR.glob(\"model_fold*.pth\"))\n",
    "    print(f\"Found {len(model_files)} models\")\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        print(f\"\\n=== {model_file.name} ===\")\n",
    "        \n",
    "        # ë§¤ foldë§ˆë‹¤ ìƒˆ ëª¨ë¸ ë¡œë“œ (TENTê°€ íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í•˜ë¯€ë¡œ)\n",
    "        model = CSIROModelV20(cfg, cfg.BACKBONE_WEIGHTS)\n",
    "        model.load_state_dict(torch.load(model_file, map_location='cpu'))\n",
    "        print(\"âœ“ Loaded\")\n",
    "        \n",
    "        preds, ids = predict_with_tent(model, loader, cfg, cfg.device)\n",
    "        all_fold_preds.append(preds)\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return np.mean(all_fold_preds, axis=0), ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77680028",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "test_df['sample_id_prefix'] = test_df['sample_id'].str.split('__').str[0]\n",
    "test_wide = test_df.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "print(f\"Test samples: {len(test_wide)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a454e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”§ v24: Test-Time Adaptation (TENT)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"TENT lr: {cfg.tent_lr}\")\n",
    "print(f\"TENT steps: {cfg.tent_steps}\")\n",
    "print(f\"TENT augmentations: {cfg.tent_augmentations}\")\n",
    "\n",
    "preds, sample_ids = predict_ensemble_tent(cfg, test_wide)\n",
    "print(f\"\\nPredictions: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee3d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "pred_df = pd.DataFrame(preds, columns=TARGET_ORDER)\n",
    "pred_df['sample_id_prefix'] = sample_ids\n",
    "\n",
    "sub_df = pred_df.melt(\n",
    "    id_vars=['sample_id_prefix'],\n",
    "    value_vars=TARGET_ORDER,\n",
    "    var_name='target_name',\n",
    "    value_name='target'\n",
    ")\n",
    "sub_df['sample_id'] = sub_df['sample_id_prefix'] + '__' + sub_df['target_name']\n",
    "\n",
    "submission = sub_df[['sample_id', 'target']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nâœ… Saved: {len(submission)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c54f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv(cfg.DATA_PATH / \"sample_submission.csv\")\n",
    "assert len(submission) == len(sample_sub)\n",
    "print(\"âœ“ Format verified!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
