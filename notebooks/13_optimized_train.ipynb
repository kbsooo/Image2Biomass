{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9367c92",
   "metadata": {},
   "source": [
    "# üöÄ Optimized DINOv3 Training Pipeline (CV 0.85+ Î™©Ìëú)\n",
    "\n",
    "**ÌïµÏã¨ Í∞úÏÑ†ÏÇ¨Ìï≠**:\n",
    "1. TrivialAugmentWide + Í∞ïÌôîÎêú Augmentation\n",
    "2. Log1p Target Transformation\n",
    "3. C-MixUp for Regression\n",
    "4. Deeper Head Architecture (512 ‚Üí 128 ‚Üí 1)\n",
    "5. Zero-Inflated Clover Head\n",
    "6. Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import timm\n",
    "import torchvision.transforms.v2 as T\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bfc86",
   "metadata": {},
   "source": [
    "## üîê Step 1: Google Drive Mount (Colab Only)\n",
    "**Ï§ëÏöî**: Ïù¥ ÏÖÄÏùÑ Î®ºÏ†Ä Ïã§ÌñâÌïòÏó¨ Drive Í∂åÌïúÏùÑ ÏäπÏù∏ÌïòÏÑ∏Ïöî.\n",
    "ÌõàÎ†® ÏôÑÎ£å ÌõÑ Î™®Îç∏Ïù¥ ÏûêÎèôÏúºÎ°ú DriveÏóê Ï†ÄÏû•Îê©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive Mount (Colab ÌôòÍ≤ΩÏóêÏÑúÎßå Ïã§Ìñâ)\n",
    "GDRIVE_SAVE_PATH = None\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    GDRIVE_SAVE_PATH = Path('/content/drive/MyDrive/kaggle_models/csiro_biomass')\n",
    "    GDRIVE_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úì Google Drive mounted. Models will be saved to: {GDRIVE_SAVE_PATH}\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Colab - Google Drive mount skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ad712",
   "metadata": {},
   "source": [
    "## üîë Step 2: Kaggle Login (Colab Only)\n",
    "**Ï§ëÏöî**: Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥ Î°úÍ∑∏Ïù∏ Ï∞ΩÏù¥ ÎúπÎãàÎã§. Î°úÍ∑∏Ïù∏ ÏôÑÎ£å ÌõÑ Îã§Ïùå ÏÖÄÏùÑ Ïã§ÌñâÌïòÏÑ∏Ïöî."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc980642",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Kaggle ÌôòÍ≤Ω Ï≤¥ÌÅ¨ Î∞è Î°úÍ∑∏Ïù∏\n",
    "import kagglehub\n",
    "\n",
    "IS_KAGGLE = Path(\"/kaggle/input/csiro-biomass\").exists()\n",
    "\n",
    "if not IS_KAGGLE:\n",
    "    print(\"üü¢ Colab ÌôòÍ≤Ω Í∞êÏßÄ - Kaggle Î°úÍ∑∏Ïù∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.\")\n",
    "    print(\"ÏïÑÎûò Ï∞ΩÏóêÏÑú Î°úÍ∑∏Ïù∏ ÌõÑ, Îã§Ïùå ÏÖÄÏùÑ Ïã§ÌñâÌïòÏÑ∏Ïöî.\")\n",
    "    kagglehub.login()\n",
    "else:\n",
    "    print(\"üîµ Kaggle ÌôòÍ≤Ω Í∞êÏßÄ - Î°úÍ∑∏Ïù∏ Î∂àÌïÑÏöî\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731f2f0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b815a6",
   "metadata": {},
   "source": [
    "## Configuration (Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ffd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === Paths (Colab with kagglehub) ===\n",
    "    DATA_PATH = None  # Will be set after kagglehub download\n",
    "    OUTPUT_DIR = Path(\"/kaggle/working\")\n",
    "    WEIGHTS_PATH = None  # Will be set after kagglehub download\n",
    "    \n",
    "    # === Model ===\n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb.lvd1689m\"  # DINOv3 Large\n",
    "    backbone_dim = 1024\n",
    "    img_size = (512, 512)  # patch16 Î™®Îç∏Ïù¥ÎØÄÎ°ú 16Ïùò Î∞∞Ïàò ÌïÑÏöî\n",
    "    \n",
    "    # === Training (Optimized) ===\n",
    "    n_folds = 5\n",
    "    epochs = 25  # 15 ‚Üí 25 (Îçî Í∏¥ ÌïôÏäµ)\n",
    "    batch_size = 8  # 16 ‚Üí 8 (gradient accumulation ÏÇ¨Ïö©)\n",
    "    accumulation_steps = 2  # Ïã§Ìö® batch = 16\n",
    "    lr = 3e-5  # 1e-4 ‚Üí 3e-5 (Îçî ÏïàÏ†ïÏ†Å)\n",
    "    backbone_lr_mult = 0.01  # 0.1 ‚Üí 0.01 (backbone Îçî Î≥¥Ìò∏)\n",
    "    weight_decay = 5e-4  # 1e-4 ‚Üí 5e-4 (Îçî Í∞ïÌïú regularization)\n",
    "    dropout = 0.3  # 0.0 ‚Üí 0.3\n",
    "    warmup_epochs = 2  # 1 ‚Üí 2\n",
    "    \n",
    "    # === Augmentation ===\n",
    "    use_trivial_augment = True\n",
    "    use_cmixup = True\n",
    "    cmixup_alpha = 0.4\n",
    "    cmixup_sigma = 0.5\n",
    "    \n",
    "    # === Target Transform ===\n",
    "    use_log1p = True\n",
    "    \n",
    "    # === Other ===\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af207fe",
   "metadata": {},
   "source": [
    "## üì• Step 3: Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú (ColabÏóêÏÑúÎäî kagglehub ÏÇ¨Ïö©)\n",
    "if IS_KAGGLE:\n",
    "    # Kaggle ÎÖ∏Ìä∏Î∂Å ÌôòÍ≤Ω\n",
    "    cfg.DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    cfg.WEIGHTS_PATH = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large\")\n",
    "    cfg.OUTPUT_DIR = Path(\"/kaggle/working\")\n",
    "else:\n",
    "    # Colab ÌôòÍ≤Ω - kagglehubÎ°ú Îã§Ïö¥Î°úÎìú\n",
    "    print(\"üü¢ Colab ÌôòÍ≤Ω - kagglehubÎ°ú Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú Ï§ë...\")\n",
    "\n",
    "    csiro_biomass_path = kagglehub.competition_download('csiro-biomass')\n",
    "    weights_path = kagglehub.dataset_download('kbsooo/pretrained-weights-biomass')\n",
    "\n",
    "    cfg.DATA_PATH = Path(csiro_biomass_path)\n",
    "    cfg.WEIGHTS_PATH = Path(weights_path) / \"dinov3_large\" / \"dinov3_large\"\n",
    "    cfg.OUTPUT_DIR = Path(\"/content/output\")\n",
    "\n",
    "cfg.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Data path: {cfg.DATA_PATH}\")\n",
    "print(f\"Weights path: {cfg.WEIGHTS_PATH}\")\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"Config: epochs={cfg.epochs}, batch={cfg.batch_size}, lr={cfg.lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbaaa45",
   "metadata": {},
   "source": [
    "## Competition Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426008b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "TARGET_WEIGHTS = {\n",
    "    'Dry_Green_g': 0.1, 'Dry_Dead_g': 0.1, 'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2, 'Dry_Total_g': 0.5,\n",
    "}\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "def competition_metric(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Weighted R¬≤ score.\"\"\"\n",
    "    total_weight = 0.0\n",
    "    weighted_r2 = 0.0\n",
    "    \n",
    "    for i, target in enumerate(TARGET_ORDER):\n",
    "        weight = TARGET_WEIGHTS[target]\n",
    "        ss_res = np.sum((y_true[:, i] - y_pred[:, i]) ** 2)\n",
    "        ss_tot = np.sum((y_true[:, i] - np.mean(y_true[:, i])) ** 2)\n",
    "        r2 = 1 - ss_res / (ss_tot + 1e-8)\n",
    "        weighted_r2 += weight * r2\n",
    "        total_weight += weight\n",
    "    \n",
    "    return weighted_r2 / total_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b7f75",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa1bb5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Pivot long format to wide format.\"\"\"\n",
    "    pivot = df.pivot_table(\n",
    "        index=['image_path', 'State', 'Species', 'Sampling_Date', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "        columns='target_name',\n",
    "        values='target',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    pivot.columns.name = None\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b18b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(cfg.DATA_PATH / \"train.csv\")\n",
    "train_wide = prepare_data(train_df)\n",
    "train_wide['image_id'] = train_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "# Stratified Group KFold\n",
    "sgkf = StratifiedGroupKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "train_wide['fold'] = -1\n",
    "for fold, (_, val_idx) in enumerate(sgkf.split(\n",
    "    train_wide, \n",
    "    train_wide['State'],\n",
    "    groups=train_wide['image_id']\n",
    ")):\n",
    "    train_wide.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "print(f\"Train data shape: {train_wide.shape}\")\n",
    "print(f\"Fold distribution:\\n{train_wide['fold'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f068ac",
   "metadata": {},
   "source": [
    "## Enhanced Dataset with TrivialAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed77f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_transforms(cfg):\n",
    "    \"\"\"TrivialAugmentWide + Enhanced Augmentation\"\"\"\n",
    "    transforms_list = [\n",
    "        T.Resize(cfg.img_size),\n",
    "    ]\n",
    "    \n",
    "    if cfg.use_trivial_augment:\n",
    "        transforms_list.append(T.TrivialAugmentWide())\n",
    "    \n",
    "    transforms_list.extend([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.RandomRotation(degrees=15),\n",
    "        T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "        T.RandomPerspective(distortion_scale=0.15, p=0.3),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        T.RandomErasing(p=0.2, scale=(0.02, 0.15)),\n",
    "    ])\n",
    "    \n",
    "    return T.Compose(transforms_list)\n",
    "\n",
    "def get_val_transforms(cfg):\n",
    "    return T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d8e93",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"Enhanced Dataset with Left/Right Split\"\"\"\n",
    "    def __init__(self, df, cfg, transform=None, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        img = Image.open(self.cfg.DATA_PATH / row['image_path']).convert('RGB')\n",
    "        width, height = img.size\n",
    "        mid_point = width // 2\n",
    "        \n",
    "        left_img = img.crop((0, 0, mid_point, height))\n",
    "        right_img = img.crop((mid_point, 0, width, height))\n",
    "        \n",
    "        if self.transform:\n",
    "            left_img = self.transform(left_img)\n",
    "            right_img = self.transform(right_img)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            targets = torch.tensor([\n",
    "                row['Dry_Green_g'],\n",
    "                row['Dry_Clover_g'],\n",
    "                row['Dry_Dead_g']\n",
    "            ], dtype=torch.float32)\n",
    "            \n",
    "            # Log1p transform\n",
    "            if self.cfg.use_log1p:\n",
    "                targets = torch.log1p(targets)\n",
    "            \n",
    "            return left_img, right_img, targets\n",
    "        else:\n",
    "            return left_img, right_img, row['image_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5e351",
   "metadata": {},
   "source": [
    "## C-MixUp for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13eec9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def c_mixup(left1, right1, targets1, left2, right2, targets2, sigma=0.5, alpha=0.4):\n",
    "    \"\"\"\n",
    "    C-MixUp: Continuous target-aware MixUp for regression\n",
    "    ÎπÑÏä∑Ìïú targetÎÅºÎ¶¨ Îçî Í∞ïÌïòÍ≤å mixing\n",
    "    \"\"\"\n",
    "    # Target Í±∞Î¶¨ Í≥ÑÏÇ∞ (CPUÎ°ú Î≥ÄÌôòÌïòÏó¨ numpy Ìò∏Ìôò)\n",
    "    target_dist = torch.abs(targets1 - targets2).mean().cpu().item()\n",
    "\n",
    "    # Í±∞Î¶¨ Í∏∞Î∞ò mixing probability\n",
    "    mix_weight = np.exp(-target_dist / sigma)\n",
    "\n",
    "    # Beta distributionÏúºÎ°ú lambda ÏÉòÌîåÎßÅ\n",
    "    if mix_weight > 0.1:  # Í±∞Î¶¨Í∞Ä Í∞ÄÍπåÏö∏ ÎïåÎßå mixing\n",
    "        lam = np.random.beta(alpha * mix_weight, alpha * mix_weight)\n",
    "    else:\n",
    "        lam = 1.0  # Í±∞Î¶¨Í∞Ä Î©ÄÎ©¥ mixing ÏïàÌï®\n",
    "\n",
    "    # Mix images and targets\n",
    "    mixed_left = lam * left1 + (1 - lam) * left2\n",
    "    mixed_right = lam * right1 + (1 - lam) * right2\n",
    "    mixed_targets = lam * targets1 + (1 - lam) * targets2\n",
    "\n",
    "    return mixed_left, mixed_right, mixed_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e58be",
   "metadata": {},
   "source": [
    "## Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b69ba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    \"\"\"Feature-wise Linear Modulation\"\"\"\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)\n",
    "        return gamma, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1103ba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ZeroInflatedHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Zero-Inflated Head for Clover\n",
    "    Îëê Îã®Í≥Ñ ÏòàÏ∏°: (1) is_positive? (2) amount if positive\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Binary classifier (is positive?)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # Amount regressor\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        prob = torch.sigmoid(self.classifier(x))\n",
    "        amount = self.regressor(x)\n",
    "        return prob * amount  # Expected value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fea22d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CSIROModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Optimized DINOv2 Model with:\n",
    "    - Deeper Head (512 ‚Üí 128 ‚Üí 1)\n",
    "    - LayerNorm + GELU\n",
    "    - Dropout regularization\n",
    "    - Zero-Inflated Clover Head\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, pretrained=True, weights_path=None, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # DINOv3 ViT-Large backbone\n",
    "        if pretrained and weights_path and Path(weights_path).exists():\n",
    "            print(f\"Loading backbone from: {weights_path}\")\n",
    "            self.backbone = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=False,\n",
    "                num_classes=0,\n",
    "                global_pool='avg'\n",
    "            )\n",
    "            state_dict = torch.load(weights_path / \"dinov3_vitl16_qkvb.pth\", map_location='cpu', weights_only=True)\n",
    "            self.backbone.load_state_dict(state_dict, strict=False)\n",
    "            print(\"‚úì Backbone loaded from local weights\")\n",
    "        else:\n",
    "            print(\"Loading backbone from timm (online)\")\n",
    "            self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool='avg')\n",
    "        \n",
    "        feat_dim = self.backbone.num_features\n",
    "        print(f\"Backbone feature dim: {feat_dim}\")\n",
    "        \n",
    "        # FiLM for cross-region modulation\n",
    "        self.film = FiLM(feat_dim)\n",
    "        \n",
    "        # Deeper head architecture\n",
    "        def make_head(in_dim, dropout):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_dim, 512),\n",
    "                nn.LayerNorm(512),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout * 0.5),\n",
    "                nn.Linear(128, 1),\n",
    "                nn.Softplus()\n",
    "            )\n",
    "        \n",
    "        combined_dim = feat_dim * 2\n",
    "        self.head_green = make_head(combined_dim, dropout)\n",
    "        self.head_dead = make_head(combined_dim, dropout)\n",
    "        \n",
    "        # Zero-inflated head for Clover (38% zeros)\n",
    "        self.head_clover = ZeroInflatedHead(combined_dim, dropout)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        # Extract features\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        # FiLM modulation\n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        # Concatenate\n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "        \n",
    "        # Predict\n",
    "        green = self.head_green(combined)\n",
    "        clover = self.head_clover(combined)\n",
    "        dead = self.head_dead(combined)\n",
    "        \n",
    "        # Physics constraints\n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        # Return: [Green, Dead, Clover, GDM, Total]\n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff4e30",
   "metadata": {},
   "source": [
    "## Training Functions with C-MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef53d42",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, scheduler, device, scaler, cfg):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for step, (left, right, targets) in enumerate(pbar):\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # C-MixUp\n",
    "        if cfg.use_cmixup and np.random.random() < 0.5:\n",
    "            indices = torch.randperm(len(left), device=device)  # Í∞ôÏùÄ deviceÏóê ÏÉùÏÑ±\n",
    "            left, right, targets = c_mixup(\n",
    "                left, right, targets,\n",
    "                left[indices], right[indices], targets[indices],\n",
    "                sigma=cfg.cmixup_sigma, alpha=cfg.cmixup_alpha\n",
    "            )\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(left, right)\n",
    "            # Loss on Green, Clover, Dead (indices 0, 2, 1 in output)\n",
    "            pred = outputs[:, [0, 2, 1]]\n",
    "            loss = F.mse_loss(pred, targets)\n",
    "            loss = loss / cfg.accumulation_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (step + 1) % cfg.accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item() * cfg.accumulation_steps\n",
    "        pbar.set_postfix({'loss': f'{loss.item() * cfg.accumulation_steps:.2f}'})\n",
    "\n",
    "    # ÎßàÏßÄÎßâ batch Ï≤òÎ¶¨ (accumulation_stepsÎ°ú ÎÇòÎàÑÏñ¥ Îñ®Ïñ¥ÏßÄÏßÄ ÏïäÏùÑ Îïå)\n",
    "    if (step + 1) % cfg.accumulation_steps != 0:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device, cfg):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for left, right, targets in tqdm(loader, desc=\"Validating\"):\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        \n",
    "        outputs = model(left, right)\n",
    "        \n",
    "        # Inverse log1p if used\n",
    "        if cfg.use_log1p:\n",
    "            outputs = torch.expm1(outputs)\n",
    "        \n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_targets.append(targets.numpy())\n",
    "    \n",
    "    preds = np.concatenate(all_preds)\n",
    "    targets = np.concatenate(all_targets)\n",
    "    \n",
    "    # Inverse log1p for targets\n",
    "    if cfg.use_log1p:\n",
    "        targets = np.expm1(targets)\n",
    "    \n",
    "    # Compute full targets for metric\n",
    "    full_targets = np.zeros((len(targets), 5))\n",
    "    full_targets[:, 0] = targets[:, 0]  # Green\n",
    "    full_targets[:, 1] = targets[:, 2]  # Dead\n",
    "    full_targets[:, 2] = targets[:, 1]  # Clover\n",
    "    full_targets[:, 3] = targets[:, 0] + targets[:, 1]  # GDM\n",
    "    full_targets[:, 4] = full_targets[:, 3] + targets[:, 2]  # Total\n",
    "    \n",
    "    score = competition_metric(full_targets, preds)\n",
    "    return score, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c0aa7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_fold(fold, train_df, cfg):\n",
    "    \"\"\"Train single fold with all optimizations\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "    \n",
    "    # Datasets & Loaders\n",
    "    train_ds = BiomassDataset(train_data, cfg, get_train_transforms(cfg), 'train')\n",
    "    val_ds = BiomassDataset(val_data, cfg, get_val_transforms(cfg), 'train')\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=cfg.batch_size,\n",
    "        shuffle=True, num_workers=cfg.num_workers, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=cfg.batch_size * 2,\n",
    "        shuffle=False, num_workers=cfg.num_workers, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    model = CSIROModelV2(\n",
    "        cfg.model_name,\n",
    "        pretrained=True,\n",
    "        weights_path=cfg.WEIGHTS_PATH,\n",
    "        dropout=cfg.dropout\n",
    "    )\n",
    "    model = model.to(cfg.device)\n",
    "    \n",
    "    # Optimizer with layer-wise LR\n",
    "    backbone_params = list(model.backbone.parameters())\n",
    "    head_params = (\n",
    "        list(model.head_green.parameters()) +\n",
    "        list(model.head_clover.parameters()) +\n",
    "        list(model.head_dead.parameters()) +\n",
    "        list(model.film.parameters())\n",
    "    )\n",
    "    \n",
    "    optimizer = AdamW([\n",
    "        {'params': backbone_params, 'lr': cfg.lr * cfg.backbone_lr_mult},\n",
    "        {'params': head_params, 'lr': cfg.lr}\n",
    "    ], weight_decay=cfg.weight_decay)\n",
    "    \n",
    "    total_steps = len(train_loader) * cfg.epochs // cfg.accumulation_steps\n",
    "    warmup_steps = len(train_loader) * cfg.warmup_epochs // cfg.accumulation_steps\n",
    "    \n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Training loop\n",
    "    best_score = -float('inf')\n",
    "    best_epoch = 0\n",
    "    patience = 5\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{cfg.epochs}\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, cfg.device, scaler, cfg)\n",
    "        val_score, _ = validate(model, val_loader, cfg.device, cfg)\n",
    "        \n",
    "        print(f\"Loss: {train_loss:.4f} | CV: {val_score:.4f}\")\n",
    "        \n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_epoch = epoch + 1\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), cfg.OUTPUT_DIR / f'model_fold{fold}.pth')\n",
    "            print(f\"  ‚úì New best! Saved.\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nFold {fold} Best: {best_score:.4f} (epoch {best_epoch})\")\n",
    "    \n",
    "    flush()\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d30f96",
   "metadata": {},
   "source": [
    "## Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold in range(cfg.n_folds):\n",
    "        score = train_fold(fold, train_wide, cfg)\n",
    "        fold_scores.append(score)\n",
    "\n",
    "        # Í∞Å fold ÏôÑÎ£å ÌõÑ Ï¶âÏãú Google DriveÏóê Î∞±ÏóÖ (Ï§ëÍ∞Ñ Ï†ÄÏû•)\n",
    "        if GDRIVE_SAVE_PATH is not None:\n",
    "            import shutil\n",
    "            model_file = cfg.OUTPUT_DIR / f'model_fold{fold}.pth'\n",
    "            if model_file.exists():\n",
    "                shutil.copy(model_file, GDRIVE_SAVE_PATH / f'model_fold{fold}.pth')\n",
    "                print(f\"  üìÅ Backed up to Google Drive: model_fold{fold}.pth\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ TRAINING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Fold scores: {fold_scores}\")\n",
    "    print(f\"Mean CV: {np.mean(fold_scores):.4f} ¬± {np.std(fold_scores):.4f}\")\n",
    "\n",
    "    # List saved models\n",
    "    print(\"\\nSaved models (local):\")\n",
    "    for f in sorted(cfg.OUTPUT_DIR.glob(\"model_fold*.pth\")):\n",
    "        print(f\"  {f.name}: {f.stat().st_size / 1e6:.1f} MB\")\n",
    "\n",
    "    # Google DriveÏóê ÏµúÏ¢Ö Ï†ÄÏû•\n",
    "    if GDRIVE_SAVE_PATH is not None:\n",
    "        import shutil\n",
    "        from datetime import datetime\n",
    "\n",
    "        # ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Ìè¥Îçî ÏÉùÏÑ±\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        final_save_path = GDRIVE_SAVE_PATH / f\"run_{timestamp}_cv{np.mean(fold_scores):.4f}\"\n",
    "        final_save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Î™®Îì† Î™®Îç∏ Î≥µÏÇ¨\n",
    "        for f in sorted(cfg.OUTPUT_DIR.glob(\"model_fold*.pth\")):\n",
    "            shutil.copy(f, final_save_path / f.name)\n",
    "\n",
    "        # ÌïôÏäµ Í≤∞Í≥º Ï†ÄÏû•\n",
    "        results = {\n",
    "            'fold_scores': fold_scores,\n",
    "            'mean_cv': float(np.mean(fold_scores)),\n",
    "            'std_cv': float(np.std(fold_scores)),\n",
    "            'config': {\n",
    "                'model_name': cfg.model_name,\n",
    "                'img_size': cfg.img_size,\n",
    "                'epochs': cfg.epochs,\n",
    "                'batch_size': cfg.batch_size,\n",
    "                'lr': cfg.lr,\n",
    "                'backbone_lr_mult': cfg.backbone_lr_mult,\n",
    "                'dropout': cfg.dropout,\n",
    "            }\n",
    "        }\n",
    "        import json\n",
    "        with open(final_save_path / 'results.json', 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "        print(f\"\\n‚úÖ All models saved to Google Drive:\")\n",
    "        print(f\"   {final_save_path}\")\n",
    "        for f in sorted(final_save_path.glob(\"*\")):\n",
    "            print(f\"   - {f.name}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
