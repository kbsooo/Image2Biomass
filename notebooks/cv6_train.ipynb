{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e249e20",
   "metadata": {},
   "source": [
    "# üöÄ CV6: Rect-Frame DINOv3 + SSF\n",
    "\n",
    "**Goal**: Single full-frame approach (no left/right split)\n",
    "\n",
    "**Key Ideas**:\n",
    "- **Full-frame rectangular input (560x240)**: preserve 70√ó30 aspect ratio\n",
    "- **CLS + Patch Mean pooling**: richer global + local aggregation\n",
    "- **SSF adapters**: lightweight backbone adaptation (scale/shift)\n",
    "- **Zero-Inflated Clover head** + physics constraints\n",
    "- **5-Fold CV** with OOF collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ea006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import timm\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd31f13",
   "metadata": {},
   "source": [
    "## üìä WandB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e09a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "WANDB_ENTITY = \"kbsoo0620-\"\n",
    "WANDB_PROJECT = \"csiro\"\n",
    "\n",
    "print(f\"‚úì WandB: {WANDB_ENTITY}/{WANDB_PROJECT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73a1aa",
   "metadata": {},
   "source": [
    "## üîê Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ca391",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDRIVE_SAVE_PATH = None\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    GDRIVE_SAVE_PATH = Path('/content/drive/MyDrive/kaggle_models/csiro_biomass_cv6')\n",
    "    GDRIVE_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úì Drive: {GDRIVE_SAVE_PATH}\")\n",
    "except ImportError:\n",
    "    print(\"Not in Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88830e39",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "IS_KAGGLE = Path(\"/kaggle/input/csiro-biomass\").exists()\n",
    "if not IS_KAGGLE:\n",
    "    kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70681e2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05c405f",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c36cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # Model settings\n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb.lvd1689m\"\n",
    "    # Full-frame: 70x30 aspect ‚Üí (H=240, W=560), H/W divisible by 16\n",
    "    img_size = (240, 560)\n",
    "    backbone_dim = 1024\n",
    "    freeze_backbone = True\n",
    "    use_ssf = True\n",
    "    ssf_per_block = True\n",
    "    \n",
    "    # Head\n",
    "    head_dim = 256\n",
    "    head_layers = 2\n",
    "    dropout = 0.2\n",
    "    \n",
    "    # Training\n",
    "    lr = 2e-4\n",
    "    weight_decay = 1e-4\n",
    "    warmup_ratio = 0.1\n",
    "    grad_clip = 1.0\n",
    "    \n",
    "    batch_size = 8\n",
    "    epochs = 25\n",
    "    patience = 7\n",
    "    \n",
    "    # Loss\n",
    "    zi_weight = 0.3\n",
    "    \n",
    "    # Augmentation\n",
    "    hue_jitter = 0.02\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "print(\"=== CV6 Configuration: Rect-Frame + SSF ===\")\n",
    "print(f\"Image size (H, W): {cfg.img_size}\")\n",
    "print(f\"SSF adapters: {cfg.use_ssf}, per_block: {cfg.ssf_per_block}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367fcf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_KAGGLE:\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    WEIGHTS_PATH = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large\")\n",
    "    OUTPUT_DIR = Path(\"/kaggle/working\")\n",
    "else:\n",
    "    csiro_path = kagglehub.competition_download('csiro-biomass')\n",
    "    weights_path = kagglehub.dataset_download('kbsooo/pretrained-weights-biomass')\n",
    "    DATA_PATH = Path(csiro_path)\n",
    "    WEIGHTS_PATH = Path(weights_path) / \"dinov3_large\" / \"dinov3_large\"\n",
    "    OUTPUT_DIR = Path(\"/content/output\")\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Data: {DATA_PATH}\")\n",
    "print(f\"Weights: {WEIGHTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54889318",
   "metadata": {},
   "source": [
    "## üìä Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a99d3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "TARGET_WEIGHTS = {'Dry_Green_g': 0.1, 'Dry_Dead_g': 0.1, 'Dry_Clover_g': 0.1, 'GDM_g': 0.2, 'Dry_Total_g': 0.5}\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "def competition_metric(y_true, y_pred):\n",
    "    weighted_r2 = 0.0\n",
    "    for i, target in enumerate(TARGET_ORDER):\n",
    "        weight = TARGET_WEIGHTS[target]\n",
    "        ss_res = np.sum((y_true[:, i] - y_pred[:, i]) ** 2)\n",
    "        ss_tot = np.sum((y_true[:, i] - np.mean(y_true[:, i])) ** 2)\n",
    "        r2 = 1 - ss_res / (ss_tot + 1e-8)\n",
    "        weighted_r2 += weight * r2\n",
    "    return weighted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf82f00",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    pivot = df.pivot_table(\n",
    "        index=['image_path', 'State', 'Species', 'Sampling_Date', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "        columns='target_name', values='target', aggfunc='first'\n",
    "    ).reset_index()\n",
    "    pivot.columns.name = None\n",
    "    return pivot\n",
    "\n",
    "train_df = pd.read_csv(DATA_PATH / \"train.csv\")\n",
    "train_wide = prepare_data(train_df)\n",
    "train_wide['image_id'] = train_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "train_wide['Month'] = pd.to_datetime(train_wide['Sampling_Date']).dt.month\n",
    "\n",
    "print(f\"Train samples: {len(train_wide)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd48d4d",
   "metadata": {},
   "source": [
    "## üéØ Sampling_Date Í∏∞Î∞ò CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c05bd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_proper_folds(df, n_splits=5):\n",
    "    \"\"\"Sampling_Date Í∏∞Î∞ò GroupKFold (data leakage Î∞©ÏßÄ)\"\"\"\n",
    "    df = df.copy()\n",
    "    df['date_group'] = pd.to_datetime(df['Sampling_Date']).dt.strftime('%Y-%m-%d')\n",
    "    df['strat_key'] = df['State'] + '_' + df['Month'].astype(str)\n",
    "    \n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    df['fold'] = -1\n",
    "    for fold, (_, val_idx) in enumerate(sgkf.split(\n",
    "        df, \n",
    "        df['strat_key'], \n",
    "        groups=df['date_group']\n",
    "    )):\n",
    "        df.loc[val_idx, 'fold'] = fold\n",
    "    \n",
    "    print(\"=== Fold Distribution ===\")\n",
    "    for fold in range(n_splits):\n",
    "        fold_data = df[df['fold'] == fold]\n",
    "        n_samples = len(fold_data)\n",
    "        n_dates = fold_data['date_group'].nunique()\n",
    "        print(f\"  Fold {fold}: {n_samples} samples, {n_dates} unique dates\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_wide = create_proper_folds(train_wide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df985c40",
   "metadata": {},
   "source": [
    "## üé® Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533cd28",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_train_transforms(cfg):\n",
    "    return T.Compose([\n",
    "        T.Resize(cfg.img_size, interpolation=T.InterpolationMode.BICUBIC),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.3),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=cfg.hue_jitter),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_transforms(cfg):\n",
    "    return T.Compose([\n",
    "        T.Resize(cfg.img_size, interpolation=T.InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271b3b6",
   "metadata": {},
   "source": [
    "## üì¶ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59f198",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassRectDataset(Dataset):\n",
    "    \"\"\"Full-frame dataset (no left/right split)\"\"\"\n",
    "    def __init__(self, df, data_path, transform=None, return_idx=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.return_idx = return_idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(self.data_path / row['image_path']).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # Independent targets: [Green, Clover, Dead]\n",
    "        main_targets = torch.tensor([\n",
    "            row['Dry_Green_g'],\n",
    "            row['Dry_Clover_g'],\n",
    "            row['Dry_Dead_g']\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        if self.return_idx:\n",
    "            return img, main_targets, idx\n",
    "        return img, main_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d0b1c",
   "metadata": {},
   "source": [
    "## üß† Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db9715",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SSFAdapter(nn.Module):\n",
    "    \"\"\"Feature-wise scale & shift (lightweight PEFT)\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(1, 1, dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(1, 1, dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * self.scale + self.shift\n",
    "\n",
    "\n",
    "class DINOv3Backbone(nn.Module):\n",
    "    def __init__(self, cfg, weights_path=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=False,\n",
    "            num_classes=0,\n",
    "            global_pool=\"\"  # keep tokens\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        if weights_path:\n",
    "            weights_file = weights_path / \"dinov3_vitl16_qkvb.pth\"\n",
    "            if weights_file.exists():\n",
    "                state = torch.load(weights_file, map_location='cpu', weights_only=True)\n",
    "                self.backbone.load_state_dict(state, strict=False)\n",
    "                print(f\"‚úì Loaded backbone weights from {weights_file}\")\n",
    "        \n",
    "        self.num_features = self.backbone.num_features\n",
    "        \n",
    "        # Freeze backbone\n",
    "        if cfg.freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "            print(\"‚úì Backbone frozen\")\n",
    "        \n",
    "        # SSF adapters\n",
    "        self.use_ssf = cfg.use_ssf\n",
    "        self.ssf_per_block = cfg.use_ssf and cfg.ssf_per_block\n",
    "        self.ssf_blocks = None\n",
    "        self._hooks = []\n",
    "        \n",
    "        if self.use_ssf:\n",
    "            if self.ssf_per_block:\n",
    "                self._init_ssf_per_block()\n",
    "            else:\n",
    "                self.ssf_out = SSFAdapter(self.num_features)\n",
    "    \n",
    "    def _init_ssf_per_block(self):\n",
    "        assert hasattr(self.backbone, 'blocks'), \"Backbone has no blocks attribute\"\n",
    "        self.ssf_blocks = nn.ModuleList([\n",
    "            SSFAdapter(self.num_features) for _ in range(len(self.backbone.blocks))\n",
    "        ])\n",
    "        \n",
    "        def make_hook(i):\n",
    "            def hook(_module, _input, output):\n",
    "                return self.ssf_blocks[i](output)\n",
    "            return hook\n",
    "        \n",
    "        for i, blk in enumerate(self.backbone.blocks):\n",
    "            self._hooks.append(blk.register_forward_hook(make_hook(i)))\n",
    "        \n",
    "        print(f\"‚úì SSF hooks attached: {len(self.ssf_blocks)} blocks\")\n",
    "    \n",
    "    def forward_tokens(self, x):\n",
    "        tokens = self.backbone.forward_features(x)\n",
    "        if isinstance(tokens, (tuple, list)):\n",
    "            tokens = tokens[0]\n",
    "        if tokens.ndim == 2:\n",
    "            tokens = tokens.unsqueeze(1)\n",
    "        \n",
    "        if self.use_ssf and not self.ssf_per_block:\n",
    "            tokens = self.ssf_out(tokens)\n",
    "        \n",
    "        return tokens\n",
    "\n",
    "\n",
    "class ZeroInflatedHead(nn.Module):\n",
    "    \"\"\"Two-stage head for zero-inflated targets (Clover)\n",
    "    \n",
    "    Note: classifier outputs logits (no sigmoid) for AMP compatibility\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim=128, dropout=0.2):\n",
    "        super().__init__()\n",
    "        # Classifier outputs logits (no sigmoid for AMP compatibility)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softplus(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.classifier(x)\n",
    "        p_pos = torch.sigmoid(logits)  # Convert to probability for prediction\n",
    "        amount = self.regressor(x)\n",
    "        pred = p_pos * amount\n",
    "        return logits, amount, pred  # Return logits for loss, not p_pos\n",
    "\n",
    "\n",
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        cur = in_dim\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.Linear(cur, hidden_dim))\n",
    "            if i < num_layers - 1:\n",
    "                layers.append(nn.ReLU(inplace=True))\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            cur = hidden_dim\n",
    "        layers.append(nn.Linear(hidden_dim, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class CV6Model(nn.Module):\n",
    "    \"\"\"Rect-Frame + CLS/Patch pooling + SSF\"\"\"\n",
    "    def __init__(self, cfg, weights_path=None):\n",
    "        super().__init__()\n",
    "        self.backbone = DINOv3Backbone(cfg, weights_path)\n",
    "        feat_dim = self.backbone.num_features\n",
    "        \n",
    "        # CLS + mean pooling ‚Üí 2x features\n",
    "        self.out_dim = feat_dim * 2\n",
    "        \n",
    "        self.green_head = MLPHead(self.out_dim, cfg.head_dim, cfg.head_layers, cfg.dropout)\n",
    "        self.dead_head = MLPHead(self.out_dim, cfg.head_dim, cfg.head_layers, cfg.dropout)\n",
    "        self.clover_head = ZeroInflatedHead(self.out_dim, hidden_dim=cfg.head_dim, dropout=cfg.dropout)\n",
    "        \n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        tokens = self.backbone.forward_tokens(x)  # [B, N, C]\n",
    "        B, N, C = tokens.shape\n",
    "        \n",
    "        cls = tokens[:, 0]\n",
    "        patch_mean = tokens[:, 1:].mean(dim=1) if N > 1 else cls\n",
    "        \n",
    "        feat = torch.cat([cls, patch_mean], dim=1)\n",
    "        \n",
    "        green = self.softplus(self.green_head(feat))\n",
    "        dead = self.softplus(self.dead_head(feat))\n",
    "        clover_prob, clover_amount, clover = self.clover_head(feat)\n",
    "        \n",
    "        # Physics constraints\n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        main_output = torch.cat([green, dead, clover, gdm, total], dim=1)\n",
    "        \n",
    "        return main_output, clover_prob, clover_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc321e32",
   "metadata": {},
   "source": [
    "## üîß Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fee5f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ZeroInflatedLoss(nn.Module):\n",
    "    \"\"\"Zero-inflated loss using BCEWithLogits for AMP compatibility\"\"\"\n",
    "    def __init__(self, cls_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.cls_weight = cls_weight\n",
    "    \n",
    "    def forward(self, logits, amount, targets):\n",
    "        # logits: classifier output (before sigmoid)\n",
    "        is_pos = (targets > 0).float()\n",
    "        # Use binary_cross_entropy_with_logits for AMP compatibility\n",
    "        cls_loss = F.binary_cross_entropy_with_logits(logits, is_pos)\n",
    "        \n",
    "        pos_mask = targets > 0\n",
    "        if pos_mask.sum() > 0:\n",
    "            reg_loss = F.mse_loss(amount[pos_mask], targets[pos_mask])\n",
    "        else:\n",
    "            reg_loss = torch.tensor(0.0, device=targets.device)\n",
    "        \n",
    "        return self.cls_weight * cls_loss + (1 - self.cls_weight) * reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599b53cd",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Training with OOF Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b212f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_fold(fold, train_df, cfg, device=\"cuda\"):\n",
    "    \"\"\"ÌïôÏäµ + OOF ÏòàÏ∏° Ï†ÄÏû•\"\"\"\n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n  Train: {len(train_data)} | Val: {len(val_data)}\")\n",
    "    print(f\"  Val dates: {val_data['date_group'].nunique()} unique\")\n",
    "    \n",
    "    # Dataset\n",
    "    train_ds = BiomassRectDataset(train_data, DATA_PATH, get_train_transforms(cfg))\n",
    "    val_ds = BiomassRectDataset(val_data, DATA_PATH, get_val_transforms(cfg), return_idx=True)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, \n",
    "                              num_workers=4, pin_memory=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size*2, shuffle=False, \n",
    "                            num_workers=4, pin_memory=True)\n",
    "    \n",
    "    # Model\n",
    "    model = CV6Model(cfg, WEIGHTS_PATH).to(device)\n",
    "    \n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    print(f\"  Trainable params: {sum(p.numel() for p in trainable_params) / 1e6:.2f}M\")\n",
    "    \n",
    "    optimizer = AdamW(trainable_params, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    \n",
    "    total_steps = len(train_loader) * cfg.epochs\n",
    "    warmup_steps = int(total_steps * cfg.warmup_ratio)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "    \n",
    "    zi_loss_fn = ZeroInflatedLoss()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_score = -float('inf')\n",
    "    no_improve = 0\n",
    "    best_oof = None\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for img, main_targets in train_loader:\n",
    "            img = img.to(device)\n",
    "            main_targets = main_targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                main_output, clover_prob, clover_amount = model(img)\n",
    "                pred = main_output[:, [0, 2, 1]]  # Green, Clover, Dead\n",
    "                main_loss = F.mse_loss(pred, main_targets)\n",
    "                \n",
    "                # Zero-inflated clover loss\n",
    "                clover_targets = main_targets[:, 1:2]\n",
    "                zi_loss = zi_loss_fn(clover_prob, clover_amount, clover_targets)\n",
    "                \n",
    "                loss = main_loss + cfg.zi_weight * zi_loss\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            if cfg.grad_clip > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(trainable_params, cfg.grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validate & Collect OOF\n",
    "        model.eval()\n",
    "        all_preds, all_targets, all_indices = [], [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for img, main_targets, indices in val_loader:\n",
    "                img = img.to(device)\n",
    "                main_output, _, _ = model(img)\n",
    "                all_preds.append(main_output.cpu().numpy())\n",
    "                all_targets.append(main_targets.numpy())\n",
    "                all_indices.extend(indices.numpy().tolist())\n",
    "        \n",
    "        preds = np.concatenate(all_preds)\n",
    "        targets = np.concatenate(all_targets)\n",
    "        \n",
    "        # 5Í∞ú ÌÉÄÍ≤üÏúºÎ°ú ÌôïÏû•\n",
    "        full_targets = np.zeros((len(targets), 5))\n",
    "        full_targets[:, 0] = targets[:, 0]  # Green\n",
    "        full_targets[:, 1] = targets[:, 2]  # Dead\n",
    "        full_targets[:, 2] = targets[:, 1]  # Clover\n",
    "        full_targets[:, 3] = targets[:, 0] + targets[:, 1]  # GDM\n",
    "        full_targets[:, 4] = full_targets[:, 3] + targets[:, 2]  # Total\n",
    "        \n",
    "        val_score = competition_metric(full_targets, preds)\n",
    "        \n",
    "        wandb.log({\n",
    "            f\"fold{fold}/train_loss\": train_loss,\n",
    "            f\"fold{fold}/val_score\": val_score,\n",
    "            f\"fold{fold}/epoch\": epoch + 1,\n",
    "        })\n",
    "        \n",
    "        print(f\"  Epoch {epoch+1}: loss={train_loss:.4f}, CV={val_score:.4f}\")\n",
    "        \n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), OUTPUT_DIR / f'model_fold{fold}.pth')\n",
    "            \n",
    "            best_oof = {\n",
    "                'predictions': preds.copy(),\n",
    "                'targets': full_targets.copy(),\n",
    "                'indices': np.array(all_indices),\n",
    "                'fold': fold,\n",
    "                'val_score': val_score\n",
    "            }\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= cfg.patience:\n",
    "                print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # OOF Ï†ÄÏû•\n",
    "    np.save(OUTPUT_DIR / f'oof_fold{fold}.npy', best_oof)\n",
    "    print(f\"  ‚úì OOF saved: {len(best_oof['predictions'])} samples, score={best_score:.4f}\")\n",
    "    \n",
    "    wandb.log({f\"fold{fold}/best_score\": best_score})\n",
    "    \n",
    "    flush()\n",
    "    return best_score, best_oof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd8ac86",
   "metadata": {},
   "source": [
    "## üöÄ Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0588ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    entity=WANDB_ENTITY,\n",
    "    project=WANDB_PROJECT,\n",
    "    name=f\"cv6_rectframe_ssf\",\n",
    "    config={\n",
    "        \"version\": \"cv6\",\n",
    "        \"strategy\": \"Rect-Frame + SSF\",\n",
    "        \"img_size\": cfg.img_size,\n",
    "        \"freeze_backbone\": cfg.freeze_backbone,\n",
    "        \"use_ssf\": cfg.use_ssf,\n",
    "        \"ssf_per_block\": cfg.ssf_per_block,\n",
    "        \"head_dim\": cfg.head_dim,\n",
    "        \"head_layers\": cfg.head_layers,\n",
    "        \"lr\": cfg.lr,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ CV6 Training: Rect-Frame + SSF Adapters\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Image size: {cfg.img_size} (H, W)\")\n",
    "print(f\"SSF: {cfg.use_ssf}, per_block: {cfg.ssf_per_block}\")\n",
    "print(f\"Backbone frozen: {cfg.freeze_backbone}\")\n",
    "\n",
    "fold_scores = []\n",
    "all_oof = []\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    score, oof = train_fold(fold, train_wide, cfg)\n",
    "    fold_scores.append(score)\n",
    "    all_oof.append(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19087da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cv = np.mean(fold_scores)\n",
    "std_cv = np.std(fold_scores)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ CV6 RESULTS: Rect-Frame + SSF\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Folds: {[f'{s:.4f}' for s in fold_scores]}\")\n",
    "print(f\"Mean CV: {mean_cv:.4f} ¬± {std_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21fe57b",
   "metadata": {},
   "source": [
    "## üìä OOF Score Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÑÏ≤¥ OOF score Í≥ÑÏÇ∞\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "for fold in range(5):\n",
    "    oof = np.load(OUTPUT_DIR / f'oof_fold{fold}.npy', allow_pickle=True).item()\n",
    "    all_predictions.append(oof['predictions'])\n",
    "    all_targets.append(oof['targets'])\n",
    "\n",
    "oof_predictions = np.concatenate(all_predictions)\n",
    "oof_targets = np.concatenate(all_targets)\n",
    "\n",
    "total_oof_score = competition_metric(oof_targets, oof_predictions)\n",
    "print(f\"\\n‚úì Total OOF Score: {total_oof_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google DriveÏóê Ï†ÄÏû•\n",
    "if GDRIVE_SAVE_PATH:\n",
    "    for f in OUTPUT_DIR.glob(\"model_fold*.pth\"):\n",
    "        shutil.copy(f, GDRIVE_SAVE_PATH / f.name)\n",
    "    for f in OUTPUT_DIR.glob(\"oof_fold*.npy\"):\n",
    "        shutil.copy(f, GDRIVE_SAVE_PATH / f.name)\n",
    "    \n",
    "    with open(GDRIVE_SAVE_PATH / 'results.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'version': 'cv6',\n",
    "            'strategy': 'Rect-Frame + SSF',\n",
    "            'fold_scores': fold_scores,\n",
    "            'mean_cv': float(mean_cv),\n",
    "            'std_cv': float(std_cv),\n",
    "            'total_oof_score': float(total_oof_score),\n",
    "        }, f, indent=2)\n",
    "    print(f\"\\n‚úì All saved to: {GDRIVE_SAVE_PATH}\")\n",
    "\n",
    "wandb.log({\n",
    "    \"final/mean_cv\": mean_cv,\n",
    "    \"final/std_cv\": std_cv,\n",
    "    \"final/oof_score\": total_oof_score,\n",
    "})\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ CV6 Complete!\")\n",
    "print(f\"   Strategy: Rect-Frame + SSF Adapters\")\n",
    "print(f\"   Mean CV: {mean_cv:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
