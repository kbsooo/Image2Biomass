{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "433ca8dd",
   "metadata": {},
   "source": [
    "# üöÄ DINOv3 ViT-Large Inference Pipeline\n",
    "\n",
    "**Ïö©ÎèÑ**: Kaggle Ï†úÏ∂úÏö© (ÌïôÏäµÎêú Í∞ÄÏ§ëÏπò Î°úÎìú ‚Üí ÏòàÏ∏° ‚Üí submission.csv)\n",
    "**Ïã§Ìñâ ÏãúÍ∞Ñ**: ~1Î∂Ñ (ÌïôÏäµ ÏóÜÏùå)\n",
    "\n",
    "**ÌïÑÏöî Datasets**:\n",
    "1. `csiro-biomass` (competition data)\n",
    "2. `pretrained-weights-biomass` (DINOv3 backbone)\n",
    "3. `csiro-dinov3-trained` (ÌïôÏäµÎêú fold Í∞ÄÏ§ëÏπò) ‚Üê ÌïôÏäµ ÌõÑ ÏÉùÏÑ± ÌïÑÏöî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e500c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Suppress all warnings BEFORE importing libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "import gc\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import timm\n",
    "\n",
    "# Suppress multiprocessing errors\n",
    "logging.getLogger('torch.multiprocessing').setLevel(logging.ERROR)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b946694",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c862d99f",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb718ca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === Paths ===\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    BACKBONE_WEIGHTS = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large/dinov3_vitl16_qkvb.pth\")\n",
    "    # ÌïôÏäµÎêú Î™®Îç∏ Í∞ÄÏ§ëÏπò (ÌïôÏäµ ÌõÑ DatasetÏúºÎ°ú ÏóÖÎ°úÎìú ÌïÑÏöî)\n",
    "    MODELS_DIR = Path(\"/kaggle/input/csiro-dinov3-trained\")\n",
    "    \n",
    "    # === Model ===\n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb\"\n",
    "    backbone_dim = 1024\n",
    "    img_size = (512, 512)\n",
    "    \n",
    "    # === Inference ===\n",
    "    batch_size = 32\n",
    "    num_workers = 0  # 0 to avoid multiprocessing cleanup errors\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()\n",
    "print(f\"Device: {cfg.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730f61a",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ee4ef",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \"\"\"Test dataset with Left/Right split\"\"\"\n",
    "    def __init__(self, df, cfg, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img = Image.open(self.cfg.DATA_PATH / row['image_path']).convert('RGB')\n",
    "        width, height = img.size\n",
    "        mid_point = width // 2\n",
    "        \n",
    "        # Split into left and right halves\n",
    "        left_img = img.crop((0, 0, mid_point, height))\n",
    "        right_img = img.crop((mid_point, 0, width, height))\n",
    "        \n",
    "        if self.transform:\n",
    "            left_img = self.transform(left_img)\n",
    "            right_img = self.transform(right_img)\n",
    "        \n",
    "        return left_img, right_img, row['sample_id_prefix']\n",
    "\n",
    "def get_tta_dataloaders(df, cfg):\n",
    "    \"\"\"3x TTA: Original, HFlip, VFlip\"\"\"\n",
    "    loaders = []\n",
    "    \n",
    "    transforms_list = [\n",
    "        # Original\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        # Horizontal Flip\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.RandomHorizontalFlip(p=1.0),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        # Vertical Flip\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.RandomVerticalFlip(p=1.0),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    for transform in transforms_list:\n",
    "        dataset = TestDataset(df, cfg, transform)\n",
    "        loader = DataLoader(dataset, batch_size=cfg.batch_size,\n",
    "                           shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\n",
    "        loaders.append(loader)\n",
    "    \n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec5f79",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e78348",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)\n",
    "        return gamma, beta\n",
    "\n",
    "\n",
    "class CSIROModel(nn.Module):\n",
    "    \"\"\"DINOv3 ViT-Large + FiLM + Physics-constrained Heads\"\"\"\n",
    "    def __init__(self, model_name, backbone_weights_path=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone - load from local weights\n",
    "        if backbone_weights_path and Path(backbone_weights_path).exists():\n",
    "            print(f\"Loading backbone from: {backbone_weights_path}\")\n",
    "            self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0, global_pool='avg')\n",
    "            backbone_state = torch.load(backbone_weights_path, map_location='cpu', weights_only=True)\n",
    "            self.backbone.load_state_dict(backbone_state, strict=False)\n",
    "            print(\"‚úì Backbone loaded from local weights\")\n",
    "        else:\n",
    "            # Fallback: try online (won't work on Kaggle)\n",
    "            self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool='avg')\n",
    "        \n",
    "        feat_dim = self.backbone.num_features  # 1024\n",
    "        \n",
    "        self.film = FiLM(feat_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(feat_dim * 2, 8),  # 070.pyÏôÄ ÎèôÏùº\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(8, 1)\n",
    "            )\n",
    "        \n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        \n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "        # 070.py: combinedÏóê dropout ÎØ∏Ï†ÅÏö©\n",
    "        \n",
    "        green = self.softplus(self.head_green(combined))\n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined))\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b091e01",
   "metadata": {},
   "source": [
    "## Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fef12c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_ids = []\n",
    "    \n",
    "    for left, right, ids in tqdm(loader, desc=\"Predicting\"):\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        \n",
    "        outputs = model(left, right)\n",
    "        all_outputs.append(outputs.cpu().numpy())\n",
    "        all_ids.extend(ids)\n",
    "    \n",
    "    return np.concatenate(all_outputs), all_ids\n",
    "\n",
    "\n",
    "def predict_with_tta(model, tta_loaders, device):\n",
    "    \"\"\"Predict with TTA (average across augmentations)\"\"\"\n",
    "    all_preds = []\n",
    "    final_ids = None\n",
    "    \n",
    "    for i, loader in enumerate(tta_loaders):\n",
    "        preds, ids = predict(model, loader, device)\n",
    "        all_preds.append(preds)\n",
    "        if final_ids is None:\n",
    "            final_ids = ids\n",
    "    \n",
    "    # Average across TTA\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds, final_ids\n",
    "\n",
    "\n",
    "def predict_ensemble(models_dir, tta_loaders, cfg):\n",
    "    \"\"\"Ensemble prediction: N folds √ó 3 TTA\"\"\"\n",
    "    all_fold_preds = []\n",
    "    final_ids = None\n",
    "    \n",
    "    model_files = sorted(Path(models_dir).glob(\"model_fold*.pth\"))\n",
    "    print(f\"Found {len(model_files)} model files\")\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        print(f\"\\nLoading {model_file.name}...\")\n",
    "        \n",
    "        # Create model with backbone weights\n",
    "        model = CSIROModel(\n",
    "            cfg.model_name, \n",
    "            backbone_weights_path=cfg.BACKBONE_WEIGHTS,\n",
    "            dropout=0.0\n",
    "        ).to(cfg.device)\n",
    "        \n",
    "        # Load trained fold weights\n",
    "        model.load_state_dict(torch.load(model_file, map_location=cfg.device))\n",
    "        \n",
    "        preds, ids = predict_with_tta(model, tta_loaders, cfg.device)\n",
    "        all_fold_preds.append(preds)\n",
    "        \n",
    "        if final_ids is None:\n",
    "            final_ids = ids\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Average across folds\n",
    "    final_preds = np.mean(all_fold_preds, axis=0)\n",
    "    return final_preds, final_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6c95d",
   "metadata": {},
   "source": [
    "## Main Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "\n",
    "# Prepare test data\n",
    "test_df['sample_id_prefix'] = test_df['sample_id'].str.split('__').str[0]\n",
    "test_wide = test_df.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Test samples: {len(test_wide)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefe74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TTA dataloaders\n",
    "tta_loaders = get_tta_dataloaders(test_wide, cfg)\n",
    "\n",
    "# Run ensemble prediction\n",
    "preds, sample_ids = predict_ensemble(cfg.MODELS_DIR, tta_loaders, cfg)\n",
    "\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "# Build prediction dataframe\n",
    "pred_df = pd.DataFrame(preds, columns=TARGET_ORDER)\n",
    "pred_df['sample_id_prefix'] = sample_ids\n",
    "\n",
    "# Melt to long format\n",
    "sub_df = pred_df.melt(\n",
    "    id_vars=['sample_id_prefix'],\n",
    "    value_vars=TARGET_ORDER,\n",
    "    var_name='target_name',\n",
    "    value_name='target'\n",
    ")\n",
    "\n",
    "# Create sample_id\n",
    "sub_df['sample_id'] = sub_df['sample_id_prefix'] + '__' + sub_df['target_name']\n",
    "\n",
    "# Final submission\n",
    "submission = sub_df[['sample_id', 'target']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved: {len(submission)} rows\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa23b289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify submission format\n",
    "sample_submission = pd.read_csv(cfg.DATA_PATH / \"sample_submission.csv\")\n",
    "print(f\"\\nExpected rows: {len(sample_submission)}\")\n",
    "print(f\"Actual rows: {len(submission)}\")\n",
    "assert len(submission) == len(sample_submission), \"Row count mismatch!\"\n",
    "print(\"‚úì Submission format verified!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
