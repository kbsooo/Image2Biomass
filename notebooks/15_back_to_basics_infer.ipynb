{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8137c0bc",
   "metadata": {},
   "source": [
    "# üîß DINOv3 Inference v15\n",
    "\n",
    "**Î™®Îç∏**: v15 (15_back_to_basics.pyÎ°ú ÌïôÏäµÎêú Î™®Îç∏)\n",
    "**ÌôòÍ≤Ω**: Kaggle (ÌïôÏäµÎêú Î™®Îç∏ÏùÑ DatasetÏúºÎ°ú ÏóÖÎ°úÎìú ÌõÑ ÏÇ¨Ïö©)\n",
    "\n",
    "**ÌïÑÏöî Datasets**:\n",
    "1. `csiro-biomass` (competition data)\n",
    "2. `pretrained-weights-biomass` (DINOv3 backbone weights)\n",
    "3. ÌïôÏäµÎêú Î™®Îç∏ Dataset (ÏßÅÏ†ë ÏóÖÎ°úÎìú)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e00e8d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import timm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab8c28",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca46cc",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1992a76",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === Í≤ΩÎ°ú (Kaggle) ===\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    \n",
    "    # DINOv3 backbone weights (timmÏù¥ Ïù¥ Ïù¥Î¶ÑÏùÑ Ïù∏ÏãùÌïòÎèÑÎ°ù Îì±Î°ù)\n",
    "    BACKBONE_WEIGHTS = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large/dinov3_vitl16_qkvb.pth\")\n",
    "    \n",
    "    # ‚ö†Ô∏è Ïù¥ Í≤ΩÎ°úÎ•º ÏóÖÎ°úÎìúÌïú Î™®Îç∏ Dataset Í≤ΩÎ°úÎ°ú Î≥ÄÍ≤ΩÌïòÏÑ∏Ïöî\n",
    "    MODELS_DIR = Path(\"/kaggle/input/csiro-v15-models\")\n",
    "    \n",
    "    # === Model ===\n",
    "    # hf_hub: prefixÎ°ú HuggingFaceÏóêÏÑú Î™®Îç∏ ÏïÑÌÇ§ÌÖçÏ≤ò Î°úÎìú\n",
    "    model_name = \"hf_hub:timm/vit_large_patch16_224.dinov2.lvd142m\"\n",
    "    img_size = (512, 512)\n",
    "    dropout = 0.1\n",
    "    \n",
    "    # === Inference ===\n",
    "    batch_size = 32\n",
    "    num_workers = 0  # KaggleÏóêÏÑú multiprocessing ÏóêÎü¨ Î∞©ÏßÄ\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"Models: {cfg.MODELS_DIR}\")\n",
    "print(f\"Backbone: {cfg.BACKBONE_WEIGHTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ea498",
   "metadata": {},
   "source": [
    "## üìä Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305fe9e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \"\"\"Test dataset with Left/Right split\"\"\"\n",
    "    def __init__(self, df, cfg, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        img = Image.open(self.cfg.DATA_PATH / row['image_path']).convert('RGB')\n",
    "        width, height = img.size\n",
    "        mid = width // 2\n",
    "        \n",
    "        left_img = img.crop((0, 0, mid, height))\n",
    "        right_img = img.crop((mid, 0, width, height))\n",
    "        \n",
    "        if self.transform:\n",
    "            left_img = self.transform(left_img)\n",
    "            right_img = self.transform(right_img)\n",
    "        \n",
    "        return left_img, right_img, row['sample_id_prefix']\n",
    "\n",
    "def get_tta_dataloaders(df, cfg):\n",
    "    \"\"\"3x TTA: Original, HFlip, VFlip\"\"\"\n",
    "    loaders = []\n",
    "    \n",
    "    transforms_list = [\n",
    "        # Original\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        # Horizontal Flip\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.RandomHorizontalFlip(p=1.0),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        # Vertical Flip\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.RandomVerticalFlip(p=1.0),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    for transform in transforms_list:\n",
    "        dataset = TestDataset(df, cfg, transform)\n",
    "        loader = DataLoader(dataset, batch_size=cfg.batch_size,\n",
    "                           shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\n",
    "        loaders.append(loader)\n",
    "    \n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f6c02e",
   "metadata": {},
   "source": [
    "## üß† Model Definition (v15ÏôÄ ÎèôÏùº)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa61c1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    \"\"\"Feature-wise Linear Modulation\"\"\"\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)\n",
    "        return gamma, beta\n",
    "\n",
    "\n",
    "class CSIROModel(nn.Module):\n",
    "    \"\"\"v15 Model - v12 Í∏∞Î∞ò\"\"\"\n",
    "    def __init__(self, model_name, backbone_weights_path=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone - hf_hub prefixÎ°ú HuggingFaceÏóêÏÑú architecture Î°úÎìú\n",
    "        # Í∑∏ ÌõÑ local backbone weightsÎ°ú ÎçÆÏñ¥ÏîÄ\n",
    "        print(f\"Creating backbone: {model_name}\")\n",
    "        self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0, global_pool='avg')\n",
    "        \n",
    "        if backbone_weights_path and Path(backbone_weights_path).exists():\n",
    "            print(f\"Loading backbone weights from: {backbone_weights_path}\")\n",
    "            backbone_state = torch.load(backbone_weights_path, map_location='cpu', weights_only=True)\n",
    "            self.backbone.load_state_dict(backbone_state, strict=False)\n",
    "            print(\"‚úì Backbone weights loaded\")\n",
    "        else:\n",
    "            print(f\"WARNING: Backbone weights not found, using random init\")\n",
    "        \n",
    "        feat_dim = self.backbone.num_features  # 1024\n",
    "        print(f\"Feature dim: {feat_dim}\")\n",
    "        \n",
    "        self.film = FiLM(feat_dim)\n",
    "        \n",
    "        # v12/v15ÏôÄ ÎèôÏùºÌïú head (256 hidden units)\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(feat_dim * 2, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(256, 1)\n",
    "            )\n",
    "        \n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        \n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "        \n",
    "        green = self.softplus(self.head_green(combined))\n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined))\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        # [Green, Dead, Clover, GDM, Total]\n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792837d",
   "metadata": {},
   "source": [
    "## üîÆ Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d97eb3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_ids = []\n",
    "    \n",
    "    for left, right, ids in tqdm(loader, desc=\"Predicting\"):\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        \n",
    "        outputs = model(left, right)\n",
    "        all_outputs.append(outputs.cpu().numpy())\n",
    "        all_ids.extend(ids)\n",
    "    \n",
    "    return np.concatenate(all_outputs), all_ids\n",
    "\n",
    "\n",
    "def predict_with_tta(model, tta_loaders, device):\n",
    "    \"\"\"Predict with TTA (average across augmentations)\"\"\"\n",
    "    all_preds = []\n",
    "    final_ids = None\n",
    "    \n",
    "    for i, loader in enumerate(tta_loaders):\n",
    "        preds, ids = predict(model, loader, device)\n",
    "        all_preds.append(preds)\n",
    "        if final_ids is None:\n",
    "            final_ids = ids\n",
    "    \n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds, final_ids\n",
    "\n",
    "\n",
    "def predict_ensemble(cfg, tta_loaders):\n",
    "    \"\"\"Ensemble prediction: N folds √ó 3 TTA\"\"\"\n",
    "    all_fold_preds = []\n",
    "    final_ids = None\n",
    "    \n",
    "    model_files = sorted(cfg.MODELS_DIR.glob(\"model_fold*.pth\"))\n",
    "    print(f\"Found {len(model_files)} model files\")\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        print(f\"\\nLoading {model_file.name}...\")\n",
    "        \n",
    "        # 1. Backbone architecture ÏÉùÏÑ± + backbone weights Î°úÎìú\n",
    "        model = CSIROModel(\n",
    "            cfg.model_name, \n",
    "            backbone_weights_path=cfg.BACKBONE_WEIGHTS,\n",
    "            dropout=cfg.dropout\n",
    "        ).to(cfg.device)\n",
    "        \n",
    "        # 2. ÌïôÏäµÎêú fold weightsÎ°ú Ï†ÑÏ≤¥ ÎçÆÏñ¥Ïì∞Í∏∞\n",
    "        state_dict = torch.load(model_file, map_location=cfg.device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(\"‚úì Fold weights loaded\")\n",
    "        \n",
    "        preds, ids = predict_with_tta(model, tta_loaders, cfg.device)\n",
    "        all_fold_preds.append(preds)\n",
    "        \n",
    "        if final_ids is None:\n",
    "            final_ids = ids\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Average across folds\n",
    "    final_preds = np.mean(all_fold_preds, axis=0)\n",
    "    return final_preds, final_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f542a8",
   "metadata": {},
   "source": [
    "## üìã Main Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "\n",
    "# Prepare test data\n",
    "test_df['sample_id_prefix'] = test_df['sample_id'].str.split('__').str[0]\n",
    "test_wide = test_df.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Test samples: {len(test_wide)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TTA dataloaders\n",
    "tta_loaders = get_tta_dataloaders(test_wide, cfg)\n",
    "\n",
    "# Run ensemble prediction\n",
    "preds, sample_ids = predict_ensemble(cfg, tta_loaders)\n",
    "\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "pred_df = pd.DataFrame(preds, columns=TARGET_ORDER)\n",
    "pred_df['sample_id_prefix'] = sample_ids\n",
    "\n",
    "sub_df = pred_df.melt(\n",
    "    id_vars=['sample_id_prefix'],\n",
    "    value_vars=TARGET_ORDER,\n",
    "    var_name='target_name',\n",
    "    value_name='target'\n",
    ")\n",
    "\n",
    "sub_df['sample_id'] = sub_df['sample_id_prefix'] + '__' + sub_df['target_name']\n",
    "\n",
    "submission = sub_df[['sample_id', 'target']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Submission saved: {len(submission)} rows\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090acee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify submission format\n",
    "sample_submission = pd.read_csv(cfg.DATA_PATH / \"sample_submission.csv\")\n",
    "print(f\"\\nExpected rows: {len(sample_submission)}\")\n",
    "print(f\"Actual rows: {len(submission)}\")\n",
    "assert len(submission) == len(sample_submission), \"Row count mismatch!\"\n",
    "print(\"‚úì Submission format verified!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
