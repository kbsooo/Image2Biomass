{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e6f994",
   "metadata": {},
   "source": [
    "# üîß DINOv3 Inference v15\n",
    "\n",
    "**Î™®Îç∏**: v15 (15_back_to_basics.pyÎ°ú ÌïôÏäµÎêú Î™®Îç∏)\n",
    "**ÌôòÍ≤Ω**: Kaggle (ÌïôÏäµÎêú Î™®Îç∏ÏùÑ DatasetÏúºÎ°ú ÏóÖÎ°úÎìú ÌõÑ ÏÇ¨Ïö©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebacb69f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88615e74",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5755212",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === Í≤ΩÎ°ú (Kaggle) ===\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    \n",
    "    # ‚ö†Ô∏è Ïù¥ Í≤ΩÎ°úÎ•º ÏóÖÎ°úÎìúÌïú Î™®Îç∏ Dataset Í≤ΩÎ°úÎ°ú Î≥ÄÍ≤ΩÌïòÏÑ∏Ïöî\n",
    "    MODELS_DIR = Path(\"/kaggle/input/csiro-v15-models\")  # ÏòàÏãú\n",
    "    \n",
    "    # === Model (v15ÏôÄ ÎèôÏùºÌï¥Ïïº Ìï®) ===\n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb.lvd1689m\"\n",
    "    img_size = (512, 512)\n",
    "    dropout = 0.1\n",
    "    \n",
    "    # === TTA ===\n",
    "    use_tta = True  # Test Time Augmentation\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"Models: {cfg.MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afee51",
   "metadata": {},
   "source": [
    "## üß† Model Definition (v15ÏôÄ ÎèôÏùº)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737de66f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    \"\"\"Feature-wise Linear Modulation\"\"\"\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)\n",
    "        return gamma, beta\n",
    "\n",
    "class CSIROModel(nn.Module):\n",
    "    \"\"\"v15 Model (v12 Í∏∞Î∞ò)\"\"\"\n",
    "    def __init__(self, model_name, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone (pretrained=FalseÎ°ú Î°úÎìú - Í∞ÄÏ§ëÏπòÎäî ÎÇòÏ§ëÏóê load_state_dict)\n",
    "        self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0, global_pool='avg')\n",
    "        \n",
    "        feat_dim = self.backbone.num_features\n",
    "        \n",
    "        # FiLM\n",
    "        self.film = FiLM(feat_dim)\n",
    "        \n",
    "        # Heads (v12ÏôÄ ÎèôÏùº: 256 hidden units)\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(feat_dim * 2, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(256, 1)\n",
    "            )\n",
    "        \n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        \n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "        \n",
    "        green = self.softplus(self.head_green(combined))\n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined))\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        # [Green, Dead, Clover, GDM, Total]\n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f02a33",
   "metadata": {},
   "source": [
    "## üé® Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd98bd4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_transforms(cfg):\n",
    "    return T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_tta_transforms(cfg):\n",
    "    \"\"\"TTA: original + hflip + vflip\"\"\"\n",
    "    base = get_transforms(cfg)\n",
    "    \n",
    "    hflip = T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.functional.hflip,\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    vflip = T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.functional.vflip,\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return [base, hflip, vflip]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e1c3c",
   "metadata": {},
   "source": [
    "## üîÆ Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c2013",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_single(model, img_path, transforms, cfg):\n",
    "    \"\"\"Single image prediction with optional TTA\"\"\"\n",
    "    img = Image.open(cfg.DATA_PATH / img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    mid = width // 2\n",
    "    \n",
    "    left_img = img.crop((0, 0, mid, height))\n",
    "    right_img = img.crop((mid, 0, width, height))\n",
    "    \n",
    "    if cfg.use_tta:\n",
    "        # TTA: average over transforms\n",
    "        all_preds = []\n",
    "        for transform in transforms:\n",
    "            left_t = transform(left_img).unsqueeze(0).to(cfg.device)\n",
    "            right_t = transform(right_img).unsqueeze(0).to(cfg.device)\n",
    "            outputs = model(left_t, right_t)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "        return np.mean(all_preds, axis=0)\n",
    "    else:\n",
    "        transform = transforms[0]\n",
    "        left_t = transform(left_img).unsqueeze(0).to(cfg.device)\n",
    "        right_t = transform(right_img).unsqueeze(0).to(cfg.device)\n",
    "        outputs = model(left_t, right_t)\n",
    "        return outputs.cpu().numpy()\n",
    "\n",
    "def predict_all_folds(test_df, cfg):\n",
    "    \"\"\"Ensemble prediction across all folds\"\"\"\n",
    "    transforms = get_tta_transforms(cfg) if cfg.use_tta else [get_transforms(cfg)]\n",
    "    \n",
    "    all_fold_preds = []\n",
    "    model_files = sorted(cfg.MODELS_DIR.glob(\"model_fold*.pth\"))\n",
    "    \n",
    "    print(f\"Found {len(model_files)} model files\")\n",
    "    \n",
    "    for model_path in model_files:\n",
    "        print(f\"Loading {model_path.name}...\")\n",
    "        \n",
    "        model = CSIROModel(cfg.model_name, cfg.dropout)\n",
    "        state_dict = torch.load(model_path, map_location=cfg.device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model = model.to(cfg.device)\n",
    "        model.eval()\n",
    "        \n",
    "        fold_preds = []\n",
    "        for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=f\"Fold\"):\n",
    "            pred = predict_single(model, row['image_path'], transforms, cfg)\n",
    "            fold_preds.append(pred)\n",
    "        \n",
    "        all_fold_preds.append(np.concatenate(fold_preds))\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Average across folds\n",
    "    return np.mean(all_fold_preds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19caff",
   "metadata": {},
   "source": [
    "## üìã Main Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27969f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "    test_df['target'] = 0.0\n",
    "    test_df[['sample_id_prefix', 'sample_id_suffix']] = test_df.sample_id.str.split('__', expand=True)\n",
    "    \n",
    "    # Get unique images\n",
    "    test_data = test_df.groupby(['sample_id_prefix', 'image_path']).apply(\n",
    "        lambda df: df.set_index('target_name').target\n",
    "    ).reset_index()\n",
    "    test_data.columns.name = None\n",
    "    \n",
    "    print(f\"Test images: {len(test_data)}\")\n",
    "    \n",
    "    # Predict\n",
    "    preds = predict_all_folds(test_data, cfg)\n",
    "    \n",
    "    # Assign predictions\n",
    "    # Output order: [Green, Dead, Clover, GDM, Total]\n",
    "    test_data['Dry_Green_g'] = preds[:, 0]\n",
    "    test_data['Dry_Dead_g'] = preds[:, 1]\n",
    "    test_data['Dry_Clover_g'] = preds[:, 2]\n",
    "    test_data['GDM_g'] = preds[:, 3]\n",
    "    test_data['Dry_Total_g'] = preds[:, 4]\n",
    "    \n",
    "    # Create submission\n",
    "    cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "    sub_df = test_data.set_index('sample_id_prefix')[cols].stack().reset_index()\n",
    "    sub_df.columns = ['sample_id_prefix', 'target_name', 'target']\n",
    "    sub_df['sample_id'] = sub_df.sample_id_prefix + '__' + sub_df.target_name\n",
    "    \n",
    "    # Save\n",
    "    sub_df[['sample_id', 'target']].to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(\"\\n‚úÖ submission.csv created!\")\n",
    "    print(sub_df[['sample_id', 'target']].head(10))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
