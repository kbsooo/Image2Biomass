{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2b99eb",
   "metadata": {},
   "source": [
    "# ğŸ”§ DINOv3 Inference v15\n",
    "\n",
    "**ëª¨ë¸**: v15 (15_back_to_basics.pyë¡œ í•™ìŠµëœ ëª¨ë¸)\n",
    "**í™˜ê²½**: Kaggle (í•™ìŠµëœ ëª¨ë¸ì„ Datasetìœ¼ë¡œ ì—…ë¡œë“œ í›„ ì‚¬ìš©)\n",
    "\n",
    "**í•„ìš” Datasets**:\n",
    "1. `csiro-biomass` (competition data)\n",
    "2. í•™ìŠµëœ ëª¨ë¸ Dataset (ì§ì ‘ ì—…ë¡œë“œ) - backbone weights í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cdbc40",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import timm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c243c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771037be",
   "metadata": {},
   "source": [
    "## âš™ï¸ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de072ef4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === ê²½ë¡œ (Kaggle) ===\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "\n",
    "    # âš ï¸ í•™ìŠµëœ ëª¨ë¸ Dataset ê²½ë¡œ (ì—…ë¡œë“œ í›„ ë³€ê²½)\n",
    "    MODELS_DIR = Path(\"/kaggle/input/csiro-v15-models\")\n",
    "\n",
    "    # === Model (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•´ì•¼ í•¨) ===\n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb.lvd1689m\"  # ì „ì²´ ëª¨ë¸ëª…\n",
    "    img_size = (512, 512)\n",
    "    dropout = 0.1  # ì¶”ë¡ ì‹œ ë¹„í™œì„±í™”ë˜ì§€ë§Œ architecture ì¼ì¹˜ í•„ìš”\n",
    "\n",
    "    # === Inference ===\n",
    "    batch_size = 32\n",
    "    num_workers = 0  # Kaggle multiprocessing ì—ëŸ¬ ë°©ì§€\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"Models: {cfg.MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1aed0d",
   "metadata": {},
   "source": [
    "## ğŸ“Š Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63b636",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \"\"\"Test dataset with Left/Right split\"\"\"\n",
    "    def __init__(self, df, cfg, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        img = Image.open(self.cfg.DATA_PATH / row['image_path']).convert('RGB')\n",
    "        width, height = img.size\n",
    "        mid = width // 2\n",
    "        \n",
    "        left_img = img.crop((0, 0, mid, height))\n",
    "        right_img = img.crop((mid, 0, width, height))\n",
    "        \n",
    "        if self.transform:\n",
    "            left_img = self.transform(left_img)\n",
    "            right_img = self.transform(right_img)\n",
    "        \n",
    "        return left_img, right_img, row['sample_id_prefix']\n",
    "\n",
    "def get_tta_dataloaders(df, cfg):\n",
    "    \"\"\"3x TTA: Original, HFlip, VFlip\"\"\"\n",
    "    loaders = []\n",
    "    \n",
    "    transforms_list = [\n",
    "        # Original\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        # Horizontal Flip\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.RandomHorizontalFlip(p=1.0),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        # Vertical Flip\n",
    "        T.Compose([\n",
    "            T.Resize(cfg.img_size),\n",
    "            T.RandomVerticalFlip(p=1.0),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    for transform in transforms_list:\n",
    "        dataset = TestDataset(df, cfg, transform)\n",
    "        loader = DataLoader(dataset, batch_size=cfg.batch_size,\n",
    "                           shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\n",
    "        loaders.append(loader)\n",
    "    \n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739ea161",
   "metadata": {},
   "source": [
    "## ğŸ§  Model Definition (v15ì™€ ë™ì¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04de84b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    \"\"\"Feature-wise Linear Modulation\"\"\"\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)\n",
    "        return gamma, beta\n",
    "\n",
    "\n",
    "class CSIROModel(nn.Module):\n",
    "    \"\"\"v15 Model - v12 ê¸°ë°˜ (fold weightsê°€ backbone í¬í•¨ ì „ì²´ ë®ì–´ì“°ë¯€ë¡œ pretrained ë¶ˆí•„ìš”)\"\"\"\n",
    "    def __init__(self, model_name, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Backbone architectureë§Œ ìƒì„± (weightsëŠ” fold checkpointì—ì„œ ë¡œë“œë¨)\n",
    "        self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0, global_pool='avg')\n",
    "        feat_dim = self.backbone.num_features  # 1024\n",
    "        \n",
    "        self.film = FiLM(feat_dim)\n",
    "        \n",
    "        # v12/v15ì™€ ë™ì¼í•œ head (256 hidden units)\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(feat_dim * 2, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(256, 1)\n",
    "            )\n",
    "        \n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        \n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        context = (left_feat + right_feat) / 2\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "        \n",
    "        green = self.softplus(self.head_green(combined))\n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined))\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        # [Green, Dead, Clover, GDM, Total]\n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca82dd9",
   "metadata": {},
   "source": [
    "## ğŸ”® Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67808f63",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_ids = []\n",
    "    \n",
    "    for left, right, ids in tqdm(loader, desc=\"Predicting\"):\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        \n",
    "        outputs = model(left, right)\n",
    "        all_outputs.append(outputs.cpu().numpy())\n",
    "        all_ids.extend(ids)\n",
    "    \n",
    "    return np.concatenate(all_outputs), all_ids\n",
    "\n",
    "\n",
    "def predict_with_tta(model, tta_loaders, device):\n",
    "    \"\"\"Predict with TTA (average across augmentations)\"\"\"\n",
    "    all_preds = []\n",
    "    final_ids = None\n",
    "    \n",
    "    for i, loader in enumerate(tta_loaders):\n",
    "        preds, ids = predict(model, loader, device)\n",
    "        all_preds.append(preds)\n",
    "        if final_ids is None:\n",
    "            final_ids = ids\n",
    "    \n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    return avg_preds, final_ids\n",
    "\n",
    "\n",
    "def predict_ensemble(cfg, tta_loaders):\n",
    "    \"\"\"Ensemble prediction: N folds Ã— 3 TTA\"\"\"\n",
    "    all_fold_preds = []\n",
    "    final_ids = None\n",
    "    \n",
    "    model_files = sorted(cfg.MODELS_DIR.glob(\"model_fold*.pth\"))\n",
    "    print(f\"Found {len(model_files)} model files\")\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        print(f\"\\nLoading {model_file.name}...\")\n",
    "\n",
    "        # Model architecture ìƒì„± í›„ fold checkpointë¡œ ì „ì²´ weights ë¡œë“œ\n",
    "        model = CSIROModel(cfg.model_name, dropout=cfg.dropout).to(cfg.device)\n",
    "        state_dict = torch.load(model_file, map_location=cfg.device, weights_only=True)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(\"âœ“ Weights loaded\")\n",
    "        \n",
    "        preds, ids = predict_with_tta(model, tta_loaders, cfg.device)\n",
    "        all_fold_preds.append(preds)\n",
    "        \n",
    "        if final_ids is None:\n",
    "            final_ids = ids\n",
    "        \n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Average across folds\n",
    "    final_preds = np.mean(all_fold_preds, axis=0)\n",
    "    return final_preds, final_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c6113",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Main Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94313801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "\n",
    "# Prepare test data\n",
    "test_df['sample_id_prefix'] = test_df['sample_id'].str.split('__').str[0]\n",
    "test_wide = test_df.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Test samples: {len(test_wide)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951da2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TTA dataloaders\n",
    "tta_loaders = get_tta_dataloaders(test_wide, cfg)\n",
    "\n",
    "# Run ensemble prediction\n",
    "preds, sample_ids = predict_ensemble(cfg, tta_loaders)\n",
    "\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "pred_df = pd.DataFrame(preds, columns=TARGET_ORDER)\n",
    "pred_df['sample_id_prefix'] = sample_ids\n",
    "\n",
    "sub_df = pred_df.melt(\n",
    "    id_vars=['sample_id_prefix'],\n",
    "    value_vars=TARGET_ORDER,\n",
    "    var_name='target_name',\n",
    "    value_name='target'\n",
    ")\n",
    "\n",
    "sub_df['sample_id'] = sub_df['sample_id_prefix'] + '__' + sub_df['target_name']\n",
    "\n",
    "submission = sub_df[['sample_id', 'target']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nâœ… Submission saved: {len(submission)} rows\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify submission format\n",
    "sample_submission = pd.read_csv(cfg.DATA_PATH / \"sample_submission.csv\")\n",
    "print(f\"\\nExpected rows: {len(sample_submission)}\")\n",
    "print(f\"Actual rows: {len(submission)}\")\n",
    "assert len(submission) == len(sample_submission), \"Row count mismatch!\"\n",
    "print(\"âœ“ Submission format verified!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
