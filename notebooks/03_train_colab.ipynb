{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f4e551",
   "metadata": {},
   "source": [
    "# CSIRO Image2Biomass - Improved Training Pipeline v2\n",
    "\n",
    "**Key Improvements over 0.69 baseline:**\n",
    "- DINOv2-Large backbone (1024d vs 768d)\n",
    "- Left/Right image split with Bidirectional Cross-Attention\n",
    "- 3 predictions → 2 derived (physics constraint)\n",
    "- Competition-weighted loss (Total=0.5, GDM=0.2)\n",
    "- Post-processing with constraint projection\n",
    "\n",
    "**Target**: 0.69 → 0.78+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6a608",
   "metadata": {},
   "source": [
    "## Section 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q timm albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512f67c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import KFold, GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c1941",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a423f05",
   "metadata": {},
   "source": [
    "## Section 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    # Paths (Colab Google Drive)\n",
    "    DATA_PATH: Path = Path(\"/content/drive/MyDrive/kaggle/csiro-biomass\")\n",
    "    OUTPUT_DIR: Path = Path(\"/content/drive/MyDrive/kaggle/outputs\")\n",
    "\n",
    "    # Model\n",
    "    backbone: str = \"vit_large_patch14_dinov2.lvd142m\"\n",
    "    input_size: int = 518\n",
    "    embed_dim: int = 1024  # DINOv2-large\n",
    "    num_heads: int = 16\n",
    "    dropout: float = 0.1\n",
    "\n",
    "    # Training\n",
    "    n_folds: int = 5\n",
    "    train_folds: List[int] = None  # [0] for quick test, None for all\n",
    "    epochs: int = 20\n",
    "    batch_size: int = 4\n",
    "    gradient_accumulation: int = 2\n",
    "    effective_batch_size: int = 8  # batch_size * gradient_accumulation\n",
    "\n",
    "    # Optimizer\n",
    "    lr: float = 1e-4\n",
    "    backbone_lr: float = 1e-5\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_epochs: int = 2\n",
    "\n",
    "    # Training phases\n",
    "    freeze_backbone_epochs: int = 3  # Freeze backbone for first N epochs\n",
    "\n",
    "    # Target\n",
    "    targets: List[str] = None\n",
    "    num_targets: int = 5\n",
    "\n",
    "    # Misc\n",
    "    seed: int = 42\n",
    "    num_workers: int = 2\n",
    "    mixed_precision: bool = True\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.targets is None:\n",
    "            self.targets = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "        if self.train_folds is None:\n",
    "            self.train_folds = list(range(self.n_folds))\n",
    "        self.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cfg = CFG()\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Data path: {cfg.DATA_PATH}\")\n",
    "print(f\"Output dir: {cfg.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c509958",
   "metadata": {},
   "source": [
    "## Section 2: Competition Metric & Target Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba928985",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Competition weights - Total이 50%로 가장 중요!\n",
    "TARGET_WEIGHTS = {\n",
    "    'Dry_Green_g': 0.1,\n",
    "    'Dry_Dead_g': 0.1,\n",
    "    'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2,\n",
    "    'Dry_Total_g': 0.5,\n",
    "}\n",
    "\n",
    "# Target order: Green, Dead, Clover, GDM, Total\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "# Max values for normalization (from train data)\n",
    "TARGET_MAX = {\n",
    "    'Dry_Green_g': 157.9836,\n",
    "    'Dry_Dead_g': 83.8407,\n",
    "    'Dry_Clover_g': 71.7865,\n",
    "    'GDM_g': 157.9836,\n",
    "    'Dry_Total_g': 185.70,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f25019f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def competition_metric(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate competition weighted R² score.\n",
    "\n",
    "    Args:\n",
    "        y_true: (N, 5) ground truth [Green, Dead, Clover, GDM, Total]\n",
    "        y_pred: (N, 5) predictions\n",
    "    \"\"\"\n",
    "    weights = np.array([TARGET_WEIGHTS[t] for t in TARGET_ORDER])\n",
    "\n",
    "    # Weighted mean for baseline\n",
    "    y_weighted_mean = sum(\n",
    "        y_true[:, i].mean() * weights[i]\n",
    "        for i in range(5)\n",
    "    )\n",
    "\n",
    "    # Weighted SS_res and SS_tot\n",
    "    ss_res = sum(\n",
    "        ((y_true[:, i] - y_pred[:, i]) ** 2).mean() * weights[i]\n",
    "        for i in range(5)\n",
    "    )\n",
    "    ss_tot = sum(\n",
    "        ((y_true[:, i] - y_weighted_mean) ** 2).mean() * weights[i]\n",
    "        for i in range(5)\n",
    "    )\n",
    "\n",
    "    return 1 - ss_res / (ss_tot + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d0cd0f",
   "metadata": {},
   "source": [
    "## Section 3: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df1644",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def pivot_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert long format to wide format.\"\"\"\n",
    "    if 'target' in df.columns:\n",
    "        df_pt = pd.pivot_table(\n",
    "            df,\n",
    "            values='target',\n",
    "            index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "            columns='target_name',\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        df['target'] = 0\n",
    "        df_pt = pd.pivot_table(\n",
    "            df,\n",
    "            values='target',\n",
    "            index='image_path',\n",
    "            columns='target_name',\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    return df_pt\n",
    "\n",
    "def melt_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert wide format to submission format.\"\"\"\n",
    "    melted = df.melt(\n",
    "        id_vars='image_path',\n",
    "        value_vars=TARGET_ORDER,\n",
    "        var_name='target_name',\n",
    "        value_name='target'\n",
    "    )\n",
    "    melted['sample_id'] = (\n",
    "        melted['image_path']\n",
    "        .str.replace(r'^.*/', '', regex=True)\n",
    "        .str.replace('.jpg', '', regex=False)\n",
    "        + '__' + melted['target_name']\n",
    "    )\n",
    "    return melted[['sample_id', 'image_path', 'target_name', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38cfc5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_data(cfg: CFG) -> pd.DataFrame:\n",
    "    \"\"\"Load and prepare training data.\"\"\"\n",
    "    train_df = pd.read_csv(cfg.DATA_PATH / \"train.csv\")\n",
    "    train_wide = pivot_table(train_df)\n",
    "\n",
    "    # Add image_id\n",
    "    train_wide['image_id'] = train_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "    # Create folds (KFold - random split)\n",
    "    # Insight: Random split이 State-based GroupKFold보다 CV 점수가 높음\n",
    "    kf = KFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "    train_wide['fold'] = -1\n",
    "    for fold, (_, val_idx) in enumerate(kf.split(train_wide)):\n",
    "        train_wide.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "    print(f\"Data shape: {train_wide.shape}\")\n",
    "    print(f\"Fold distribution:\\n{train_wide['fold'].value_counts().sort_index()}\")\n",
    "\n",
    "    return train_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb44673",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive (uncomment in Colab)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Load data\n",
    "train_df = prepare_data(cfg)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51978746",
   "metadata": {},
   "source": [
    "## Section 4: Dataset & Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51047f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_transforms(cfg: CFG, mode: str = 'train') -> A.Compose:\n",
    "    \"\"\"Get augmentation transforms.\"\"\"\n",
    "    if mode == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(cfg.input_size, cfg.input_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            # Insight: 색상 변환은 약하게 (녹색/갈색 구분이 중요)\n",
    "            A.ColorJitter(\n",
    "                brightness=0.1, contrast=0.1,\n",
    "                saturation=0.05, hue=0.02,\n",
    "                p=0.3\n",
    "            ),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.1, scale_limit=0.1, rotate_limit=15,\n",
    "                border_mode=cv2.BORDER_REFLECT, p=0.5\n",
    "            ),\n",
    "            # Regularization\n",
    "            A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(cfg.input_size, cfg.input_size),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a245fd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for biomass prediction.\n",
    "    Splits image into left/right halves for separate processing.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, cfg: CFG, transforms=None, mode: str = 'train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        img_path = self.cfg.DATA_PATH / row['image_path']\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Split into left/right halves (2000x1000 → 1000x1000 x2)\n",
    "        h, w = img.shape[:2]\n",
    "        mid = w // 2\n",
    "        left_img = img[:, :mid]\n",
    "        right_img = img[:, mid:]\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transforms:\n",
    "            left_aug = self.transforms(image=left_img)['image']\n",
    "            right_aug = self.transforms(image=right_img)['image']\n",
    "        else:\n",
    "            left_aug = torch.from_numpy(left_img).permute(2, 0, 1).float() / 255.0\n",
    "            right_aug = torch.from_numpy(right_img).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        # Targets: [Green, Dead, Clover, GDM, Total]\n",
    "        targets = torch.tensor([\n",
    "            row[t] for t in TARGET_ORDER\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            'left': left_aug,\n",
    "            'right': right_aug,\n",
    "            'targets': targets,\n",
    "            'image_id': row['image_id']\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee8727",
   "metadata": {},
   "source": [
    "## Section 5: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545861d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"FFN block with GELU activation.\"\"\"\n",
    "    def __init__(self, dim: int, mlp_ratio: float = 4.0, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        hidden = int(dim * mlp_ratio)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5792cc4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiDirectionalCrossAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional cross-attention for left/right image fusion.\n",
    "\n",
    "    ### [Architectural Insight]\n",
    "    Unlike simple concatenation, cross-attention allows:\n",
    "    1. Left features to query relevant context from right\n",
    "    2. Right features to query relevant context from left\n",
    "    3. Learnable [FUSE] tokens aggregate cross-view information\n",
    "\n",
    "    This captures spatial correspondence between left/right views.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int = 1024, num_heads: int = 16,\n",
    "                 num_fuse_tokens: int = 4, num_layers: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_fuse_tokens = num_fuse_tokens\n",
    "\n",
    "        # Learnable fusion tokens\n",
    "        self.fuse_tokens = nn.Parameter(torch.randn(1, num_fuse_tokens, dim) * 0.02)\n",
    "\n",
    "        # Cross-attention layers\n",
    "        self.cross_layers = nn.ModuleList([\n",
    "            nn.ModuleDict({\n",
    "                'l2r_attn': nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True),\n",
    "                'r2l_attn': nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True),\n",
    "                'l2r_norm': nn.LayerNorm(dim),\n",
    "                'r2l_norm': nn.LayerNorm(dim),\n",
    "                'ffn_l': FeedForward(dim, mlp_ratio=4.0, dropout=dropout),\n",
    "                'ffn_r': FeedForward(dim, mlp_ratio=4.0, dropout=dropout),\n",
    "                'ffn_norm_l': nn.LayerNorm(dim),\n",
    "                'ffn_norm_r': nn.LayerNorm(dim),\n",
    "            })\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Final fusion\n",
    "        fusion_input_dim = dim * 2 + dim * num_fuse_tokens\n",
    "        self.fusion_proj = nn.Sequential(\n",
    "            nn.LayerNorm(fusion_input_dim),\n",
    "            nn.Linear(fusion_input_dim, dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * 2, dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, feat_left: torch.Tensor, feat_right: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feat_left: (B, D) - left image CLS token\n",
    "            feat_right: (B, D) - right image CLS token\n",
    "\n",
    "        Returns:\n",
    "            (B, D*2) - fused features\n",
    "        \"\"\"\n",
    "        B = feat_left.shape[0]\n",
    "\n",
    "        # Expand to sequence (B, 1, D)\n",
    "        feat_left = feat_left.unsqueeze(1)\n",
    "        feat_right = feat_right.unsqueeze(1)\n",
    "\n",
    "        # Expand fuse tokens\n",
    "        fuse = self.fuse_tokens.expand(B, -1, -1)  # (B, num_fuse, D)\n",
    "\n",
    "        for layer in self.cross_layers:\n",
    "            # Left attends to Right (with fuse tokens)\n",
    "            l_query = torch.cat([feat_left, fuse], dim=1)  # (B, 1+num_fuse, D)\n",
    "            l2r_out, _ = layer['l2r_attn'](\n",
    "                layer['l2r_norm'](l_query),\n",
    "                feat_right, feat_right,\n",
    "                need_weights=False\n",
    "            )\n",
    "            feat_left = feat_left + l2r_out[:, :1]\n",
    "            fuse_l = l2r_out[:, 1:]\n",
    "\n",
    "            # Right attends to Left (with fuse tokens)\n",
    "            r_query = torch.cat([feat_right, fuse], dim=1)\n",
    "            r2l_out, _ = layer['r2l_attn'](\n",
    "                layer['r2l_norm'](r_query),\n",
    "                feat_left, feat_left,\n",
    "                need_weights=False\n",
    "            )\n",
    "            feat_right = feat_right + r2l_out[:, :1]\n",
    "            fuse_r = r2l_out[:, 1:]\n",
    "\n",
    "            # FFN\n",
    "            feat_left = feat_left + layer['ffn_l'](layer['ffn_norm_l'](feat_left))\n",
    "            feat_right = feat_right + layer['ffn_r'](layer['ffn_norm_r'](feat_right))\n",
    "\n",
    "            # Merge fuse tokens\n",
    "            fuse = (fuse_l + fuse_r) / 2\n",
    "\n",
    "        # Final fusion\n",
    "        left_pool = feat_left.squeeze(1)   # (B, D)\n",
    "        right_pool = feat_right.squeeze(1) # (B, D)\n",
    "        fuse_flat = fuse.flatten(1)        # (B, num_fuse * D)\n",
    "\n",
    "        combined = torch.cat([left_pool, right_pool, fuse_flat], dim=1)\n",
    "        return self.fusion_proj(combined)  # (B, D*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68616e02",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassModel(nn.Module):\n",
    "    \"\"\"\n",
    "    DINOv2-Large based model for biomass prediction.\n",
    "\n",
    "    Architecture:\n",
    "    1. DINOv2-Large backbone (shared for left/right)\n",
    "    2. Bidirectional cross-attention fusion\n",
    "    3. 3 prediction heads (Green, Dead, Clover)\n",
    "    4. Derived outputs (GDM = Green + Clover, Total = GDM + Dead)\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: CFG):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # DINOv2-Large backbone\n",
    "        # ### [SOTA Alert] Using DINOv2-large for richer representations\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.backbone,\n",
    "            pretrained=True,\n",
    "            num_classes=0,  # Remove classification head\n",
    "        )\n",
    "        self.embed_dim = self.backbone.embed_dim  # 1024 for large\n",
    "\n",
    "        # Enable gradient checkpointing for memory efficiency\n",
    "        if hasattr(self.backbone, 'set_grad_checkpointing'):\n",
    "            self.backbone.set_grad_checkpointing(True)\n",
    "\n",
    "        # Bidirectional cross-attention fusion\n",
    "        self.cross_attn = BiDirectionalCrossAttention(\n",
    "            dim=self.embed_dim,\n",
    "            num_heads=cfg.num_heads,\n",
    "            num_fuse_tokens=4,\n",
    "            num_layers=2,\n",
    "            dropout=cfg.dropout\n",
    "        )\n",
    "\n",
    "        # Prediction heads (3 only - Green, Dead, Clover)\n",
    "        # Insight: 3개만 예측하고 나머지는 물리 법칙으로 계산\n",
    "        head_dim = self.embed_dim * 2\n",
    "        hidden_dim = head_dim // 2\n",
    "\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(head_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(cfg.dropout),\n",
    "                nn.Linear(hidden_dim, 1)\n",
    "            )\n",
    "\n",
    "        self.head_green = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        self.head_clover = make_head()\n",
    "\n",
    "        # Softplus for non-negative outputs\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "\n",
    "    def forward(self, left: torch.Tensor, right: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            left: (B, 3, H, W) - left half image\n",
    "            right: (B, 3, H, W) - right half image\n",
    "\n",
    "        Returns:\n",
    "            dict with 'green', 'dead', 'clover', 'gdm', 'total', 'all' (B, 5)\n",
    "        \"\"\"\n",
    "        # Extract features (CLS token)\n",
    "        feat_left = self.backbone(left)   # (B, embed_dim)\n",
    "        feat_right = self.backbone(right) # (B, embed_dim)\n",
    "\n",
    "        # Cross-attention fusion\n",
    "        fused = self.cross_attn(feat_left, feat_right)  # (B, embed_dim*2)\n",
    "\n",
    "        # Predict 3 components\n",
    "        green = self.softplus(self.head_green(fused))   # (B, 1)\n",
    "        dead = self.softplus(self.head_dead(fused))     # (B, 1)\n",
    "        clover = self.softplus(self.head_clover(fused)) # (B, 1)\n",
    "\n",
    "        # Derive GDM and Total (physics constraint)\n",
    "        gdm = green + clover        # GDM = Green + Clover\n",
    "        total = gdm + dead          # Total = GDM + Dead\n",
    "\n",
    "        # Stack all: [Green, Dead, Clover, GDM, Total]\n",
    "        all_preds = torch.cat([green, dead, clover, gdm, total], dim=1)\n",
    "\n",
    "        return {\n",
    "            'green': green,\n",
    "            'dead': dead,\n",
    "            'clover': clover,\n",
    "            'gdm': gdm,\n",
    "            'total': total,\n",
    "            'all': all_preds  # (B, 5)\n",
    "        }\n",
    "\n",
    "    def freeze_backbone(self):\n",
    "        \"\"\"Freeze backbone parameters.\"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_backbone(self):\n",
    "        \"\"\"Unfreeze backbone parameters.\"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad70261",
   "metadata": {},
   "source": [
    "## Section 6: Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e4204f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class WeightedBiomassLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Competition-aligned weighted loss function.\n",
    "\n",
    "    ### [Insight]\n",
    "    Competition metric weights Total at 0.5, so we align training loss.\n",
    "    Also adds physics constraint to ensure GDM = Green + Clover.\n",
    "    \"\"\"\n",
    "    def __init__(self, physics_weight: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Weights: [Green, Dead, Clover, GDM, Total]\n",
    "        self.register_buffer('weights', torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]))\n",
    "        self.physics_weight = physics_weight\n",
    "        self.smooth_l1 = nn.SmoothL1Loss(reduction='none', beta=1.0)\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: (B, 5) - [Green, Dead, Clover, GDM, Total]\n",
    "            target: (B, 5)\n",
    "        \"\"\"\n",
    "        # Per-target SmoothL1 loss\n",
    "        loss_per_target = self.smooth_l1(pred, target)  # (B, 5)\n",
    "\n",
    "        # Weighted mean\n",
    "        weighted_loss = (loss_per_target * self.weights.unsqueeze(0)).sum(dim=1).mean()\n",
    "\n",
    "        # Physics constraint loss (should already be satisfied by architecture)\n",
    "        # But we add it for extra regularization\n",
    "        pred_gdm_check = pred[:, 0] + pred[:, 2]   # green + clover\n",
    "        pred_total_check = pred[:, 3] + pred[:, 1] # gdm + dead\n",
    "\n",
    "        physics_loss = (\n",
    "            F.smooth_l1_loss(pred_gdm_check, pred[:, 3]) +  # GDM consistency\n",
    "            F.smooth_l1_loss(pred_total_check, pred[:, 4])   # Total consistency\n",
    "        )\n",
    "\n",
    "        return weighted_loss + self.physics_weight * physics_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec4e1a0",
   "metadata": {},
   "source": [
    "## Section 7: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037a7d5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, scheduler, criterion, cfg, scaler=None, epoch=0):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch+1} Training')\n",
    "\n",
    "    for step, batch in enumerate(pbar):\n",
    "        left = batch['left'].to(cfg.device)\n",
    "        right = batch['right'].to(cfg.device)\n",
    "        targets = batch['targets'].to(cfg.device)\n",
    "\n",
    "        # Mixed precision forward\n",
    "        with torch.amp.autocast('cuda', enabled=cfg.mixed_precision):\n",
    "            outputs = model(left, right)\n",
    "            loss = criterion(outputs['all'], targets)\n",
    "            loss = loss / cfg.gradient_accumulation\n",
    "\n",
    "        # Backward\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        # Gradient accumulation\n",
    "        if (step + 1) % cfg.gradient_accumulation == 0:\n",
    "            if scaler is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        total_loss += loss.item() * cfg.gradient_accumulation\n",
    "        pbar.set_postfix({'loss': f'{loss.item() * cfg.gradient_accumulation:.4f}'})\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ef468",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, cfg):\n",
    "    \"\"\"Validate model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for batch in tqdm(loader, desc='Validation'):\n",
    "        left = batch['left'].to(cfg.device)\n",
    "        right = batch['right'].to(cfg.device)\n",
    "        targets = batch['targets'].to(cfg.device)\n",
    "\n",
    "        with torch.amp.autocast('cuda', enabled=cfg.mixed_precision):\n",
    "            outputs = model(left, right)\n",
    "            loss = criterion(outputs['all'], targets)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_preds.append(outputs['all'].cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_targets = torch.cat(all_targets, dim=0).numpy()\n",
    "\n",
    "    # Compute competition metric\n",
    "    cv_score = competition_metric(all_targets, all_preds)\n",
    "\n",
    "    # Per-target R²\n",
    "    r2_scores = {}\n",
    "    for i, name in enumerate(TARGET_ORDER):\n",
    "        ss_res = np.sum((all_targets[:, i] - all_preds[:, i]) ** 2)\n",
    "        ss_tot = np.sum((all_targets[:, i] - all_targets[:, i].mean()) ** 2)\n",
    "        r2_scores[name] = 1 - ss_res / (ss_tot + 1e-8)\n",
    "\n",
    "    return total_loss / len(loader), cv_score, r2_scores, all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66902c36",
   "metadata": {},
   "source": [
    "## Section 8: Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6604d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def post_process_biomass(preds: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Project predictions to satisfy physics constraints.\n",
    "\n",
    "    Constraints:\n",
    "    1) GDM = Green + Clover\n",
    "    2) Total = GDM + Dead\n",
    "\n",
    "    Uses linear algebra projection to find closest point satisfying constraints.\n",
    "    \"\"\"\n",
    "    # Order: Green, Dead, Clover, GDM, Total\n",
    "    # Constraints in matrix form: C @ Y = 0\n",
    "    # [1, 0, 1, -1, 0] @ [G, D, C, GDM, T]^T = G + C - GDM = 0\n",
    "    # [0, 1, 0, 1, -1] @ [G, D, C, GDM, T]^T = D + GDM - T = 0\n",
    "\n",
    "    C = np.array([\n",
    "        [1, 0, 1, -1,  0],   # Green + Clover - GDM = 0\n",
    "        [0, 1, 0,  1, -1]    # Dead + GDM - Total = 0\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "    # Projection matrix: P = I - C^T @ (C @ C^T)^{-1} @ C\n",
    "    C_T = C.T\n",
    "    inv_CCt = np.linalg.inv(C @ C_T)\n",
    "    P = np.eye(5) - C_T @ inv_CCt @ C\n",
    "\n",
    "    # Project each prediction\n",
    "    Y = preds.T  # (5, N)\n",
    "    Y_proj = P @ Y\n",
    "    Y_proj = Y_proj.T  # (N, 5)\n",
    "\n",
    "    # Clip to non-negative\n",
    "    Y_proj = np.clip(Y_proj, 0, None)\n",
    "\n",
    "    return Y_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53370dcd",
   "metadata": {},
   "source": [
    "## Section 9: Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8370e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_fold(fold: int, train_df: pd.DataFrame, cfg: CFG):\n",
    "    \"\"\"Train one fold.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Fold {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Split data\n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "\n",
    "    # Datasets\n",
    "    train_dataset = BiomassDataset(\n",
    "        train_data, cfg,\n",
    "        transforms=get_transforms(cfg, 'train'),\n",
    "        mode='train'\n",
    "    )\n",
    "    val_dataset = BiomassDataset(\n",
    "        val_data, cfg,\n",
    "        transforms=get_transforms(cfg, 'val'),\n",
    "        mode='val'\n",
    "    )\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.batch_size * 2,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = BiomassModel(cfg).to(cfg.device)\n",
    "\n",
    "    # Freeze backbone initially\n",
    "    if cfg.freeze_backbone_epochs > 0:\n",
    "        model.freeze_backbone()\n",
    "        print(f\"Backbone frozen for first {cfg.freeze_backbone_epochs} epochs\")\n",
    "\n",
    "    # Optimizer with differential learning rates\n",
    "    backbone_params = list(model.backbone.parameters())\n",
    "    other_params = [p for n, p in model.named_parameters() if 'backbone' not in n]\n",
    "\n",
    "    optimizer = AdamW([\n",
    "        {'params': backbone_params, 'lr': cfg.backbone_lr},\n",
    "        {'params': other_params, 'lr': cfg.lr}\n",
    "    ], weight_decay=cfg.weight_decay)\n",
    "\n",
    "    # Scheduler\n",
    "    num_training_steps = len(train_loader) * cfg.epochs // cfg.gradient_accumulation\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=[cfg.backbone_lr * 10, cfg.lr],\n",
    "        total_steps=num_training_steps,\n",
    "        pct_start=cfg.warmup_epochs / cfg.epochs,\n",
    "        anneal_strategy='cos'\n",
    "    )\n",
    "\n",
    "    # Loss & Scaler\n",
    "    criterion = WeightedBiomassLoss(physics_weight=0.1)\n",
    "    scaler = torch.amp.GradScaler('cuda') if cfg.mixed_precision else None\n",
    "\n",
    "    # Training history\n",
    "    best_score = -float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': [], 'cv_score': []}\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        # Unfreeze backbone after initial epochs\n",
    "        if epoch == cfg.freeze_backbone_epochs and cfg.freeze_backbone_epochs > 0:\n",
    "            model.unfreeze_backbone()\n",
    "            print(f\"\\nBackbone unfrozen at epoch {epoch + 1}\")\n",
    "\n",
    "        # Train\n",
    "        train_loss = train_one_epoch(\n",
    "            model, train_loader, optimizer, scheduler, criterion, cfg, scaler, epoch\n",
    "        )\n",
    "\n",
    "        # Validate\n",
    "        val_loss, cv_score, r2_scores, val_preds = validate(\n",
    "            model, val_loader, criterion, cfg\n",
    "        )\n",
    "\n",
    "        # Apply post-processing and re-evaluate\n",
    "        val_preds_pp = post_process_biomass(val_preds)\n",
    "        val_targets = np.array([\n",
    "            val_dataset[i]['targets'].numpy() for i in range(len(val_dataset))\n",
    "        ])\n",
    "        cv_score_pp = competition_metric(val_targets, val_preds_pp)\n",
    "\n",
    "        # Log\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['cv_score'].append(cv_score_pp)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}/{cfg.epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"CV Score (raw): {cv_score:.4f}\")\n",
    "        print(f\"CV Score (post-processed): {cv_score_pp:.4f}\")\n",
    "        print(\"Per-target R²:\")\n",
    "        for name, r2 in r2_scores.items():\n",
    "            weight = TARGET_WEIGHTS[name]\n",
    "            print(f\"  {name} (w={weight}): {r2:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if cv_score_pp > best_score:\n",
    "            best_score = cv_score_pp\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_score': best_score,\n",
    "                'r2_scores': r2_scores,\n",
    "                'config': {\n",
    "                    'backbone': cfg.backbone,\n",
    "                    'embed_dim': cfg.embed_dim,\n",
    "                    'num_heads': cfg.num_heads,\n",
    "                    'dropout': cfg.dropout,\n",
    "                }\n",
    "            }, cfg.OUTPUT_DIR / f'best_model_fold{fold}.pt')\n",
    "            print(f\"✓ Saved best model (CV: {best_score:.4f})\")\n",
    "\n",
    "    # Plot training history\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title('Loss Curve')\n",
    "\n",
    "    axes[1].plot(history['cv_score'], label='CV Score', color='green')\n",
    "    axes[1].axhline(y=best_score, color='r', linestyle='--', label=f'Best: {best_score:.4f}')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Competition Metric')\n",
    "    axes[1].legend()\n",
    "    axes[1].set_title('CV Score (Post-processed)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cfg.OUTPUT_DIR / f'training_history_fold{fold}.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    flush()\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513a496",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Train all folds\n",
    "all_scores = []\n",
    "for fold in cfg.train_folds:\n",
    "    best_score = train_fold(fold, train_df, cfg)\n",
    "    all_scores.append(best_score)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Mean CV Score: {np.mean(all_scores):.4f} ± {np.std(all_scores):.4f}\")\n",
    "print(f\"Scores per fold: {all_scores}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af020ff",
   "metadata": {},
   "source": [
    "## Section 10: Inference & Submission (Local Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee134c46",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference_with_tta(model, loader, cfg, n_tta: int = 4) -> np.ndarray:\n",
    "    \"\"\"Inference with Test-Time Augmentation.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "\n",
    "    tta_transforms = [\n",
    "        lambda x: x,                                    # Original\n",
    "        lambda x: torch.flip(x, dims=[3]),             # HFlip\n",
    "        lambda x: torch.flip(x, dims=[2]),             # VFlip\n",
    "        lambda x: torch.flip(x, dims=[2, 3]),          # HFlip + VFlip\n",
    "    ][:n_tta]\n",
    "\n",
    "    for batch in tqdm(loader, desc='Inference'):\n",
    "        left = batch['left'].to(cfg.device)\n",
    "        right = batch['right'].to(cfg.device)\n",
    "\n",
    "        batch_preds = []\n",
    "\n",
    "        for tta in tta_transforms:\n",
    "            left_aug = tta(left)\n",
    "            right_aug = tta(right)\n",
    "\n",
    "            with torch.amp.autocast('cuda', enabled=cfg.mixed_precision):\n",
    "                outputs = model(left_aug, right_aug)\n",
    "                batch_preds.append(outputs['all'].cpu())\n",
    "\n",
    "        # Average TTA predictions\n",
    "        batch_pred = torch.stack(batch_preds).mean(dim=0)\n",
    "        all_preds.append(batch_pred.numpy())\n",
    "\n",
    "    return np.concatenate(all_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae4ffb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_submission(model, test_df: pd.DataFrame, cfg: CFG, fold: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"Create submission from test data.\"\"\"\n",
    "\n",
    "    # Test dataset\n",
    "    test_wide = test_df.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "    test_wide['image_id'] = test_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "    # Add dummy targets for dataset\n",
    "    for t in TARGET_ORDER:\n",
    "        if t not in test_wide.columns:\n",
    "            test_wide[t] = 0.0\n",
    "\n",
    "    test_dataset = BiomassDataset(\n",
    "        test_wide, cfg,\n",
    "        transforms=get_transforms(cfg, 'val'),\n",
    "        mode='test'\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Inference\n",
    "    preds = inference_with_tta(model, test_loader, cfg, n_tta=4)\n",
    "\n",
    "    # Post-process\n",
    "    preds = post_process_biomass(preds)\n",
    "\n",
    "    # Create submission\n",
    "    test_wide[TARGET_ORDER] = preds\n",
    "    submission = melt_table(test_wide)\n",
    "\n",
    "    return submission[['sample_id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46beee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission using best fold 0 model\n",
    "if (cfg.OUTPUT_DIR / 'best_model_fold0.pt').exists():\n",
    "    # Load model\n",
    "    checkpoint = torch.load(cfg.OUTPUT_DIR / 'best_model_fold0.pt', weights_only=False)\n",
    "    model = BiomassModel(cfg).to(cfg.device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded model with CV score: {checkpoint['best_score']:.4f}\")\n",
    "\n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(cfg.DATA_PATH / 'test.csv')\n",
    "\n",
    "    # Create submission\n",
    "    submission = create_submission(model, test_df, cfg, fold=0)\n",
    "    submission.to_csv(cfg.OUTPUT_DIR / 'submission.csv', index=False)\n",
    "    print(f\"Submission saved: {len(submission)} rows\")\n",
    "    print(submission.head(10))\n",
    "else:\n",
    "    print(\"No trained model found. Run training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1ef9a",
   "metadata": {},
   "source": [
    "## Section 11: Save for Kaggle Upload\n",
    "\n",
    "After training, upload the following to Kaggle Datasets:\n",
    "- `best_model_fold0.pt` (and other folds if trained)\n",
    "\n",
    "Then use `04_inference_kaggle.py` for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c339e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "{'='*60}\n",
    "Training Pipeline Complete!\n",
    "{'='*60}\n",
    "\n",
    "Files saved in {cfg.OUTPUT_DIR}:\n",
    "- best_model_fold*.pt (model weights)\n",
    "- training_history_fold*.png (loss curves)\n",
    "- submission.csv (local test submission)\n",
    "\n",
    "Next steps:\n",
    "1. Upload model weights to Kaggle Datasets\n",
    "2. Use 04_inference_kaggle.py for final submission\n",
    "{'='*60}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
