{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4756479",
   "metadata": {},
   "source": [
    "# ğŸ”¬ Exp A: Auxiliary Task Learning\n",
    "\n",
    "**ì•„ì´ë””ì–´**: ì´ë¯¸ì§€ì—ì„œ NDVI/Heightë„ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµ\n",
    "â†’ ëª¨ë¸ì´ \"í‘¸ë¦„\", \"ë†’ì´\" ê°œë…ì„ ì´í•´í•˜ê²Œ ë¨\n",
    "\n",
    "**ê²°ê³¼**: Testì—ì„œëŠ” ì´ë¯¸ì§€ë§Œ ë„£ì–´ë„ ì´ ì§€ì‹ì´ ë°˜ì˜ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c9027",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa9ce6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd24d06c",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdbeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === Kaggle Paths ===\n",
    "    DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    OUTPUT_DIR = Path(\"/kaggle/working\")\n",
    "    WEIGHTS_PATH = Path(\"/kaggle/input/pretrained-weights-biomass\")\n",
    "    \n",
    "    # === Model ===\n",
    "    backbone = \"efficientnet_b4\"\n",
    "    input_size = 384\n",
    "    \n",
    "    # === Training ===\n",
    "    n_folds = 5\n",
    "    train_folds = 1  # ì‹¹ìˆ˜ í™•ì¸ìš©: 1-foldë§Œ í•™ìŠµ\n",
    "    epochs = 10       # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸\n",
    "    batch_size = 16   # GPU 2ê°œ ê¸°ì¤€\n",
    "    lr = 2e-4\n",
    "    weight_decay = 1e-4\n",
    "    \n",
    "    # === Auxiliary Task ===\n",
    "    aux_weight = 0.3  # aux_loss ê°€ì¤‘ì¹˜\n",
    "    tabular_cols = ['Pre_GSHH_NDVI', 'Height_Ave_cm']\n",
    "    \n",
    "    # === Misc ===\n",
    "    seed = 42\n",
    "    num_workers = 0\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # === Targets ===\n",
    "    independent_targets = ['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g']\n",
    "    all_targets = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "cfg = CFG()\n",
    "cfg.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"Training {cfg.train_folds} fold(s) for quick test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c2dce",
   "metadata": {},
   "source": [
    "## Competition Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8151a0a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "TARGET_WEIGHTS = {\n",
    "    'Dry_Green_g': 0.1,\n",
    "    'Dry_Dead_g': 0.1,\n",
    "    'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2,\n",
    "    'Dry_Total_g': 0.5,\n",
    "}\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "def competition_metric(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    weights = np.array([TARGET_WEIGHTS[t] for t in TARGET_ORDER])\n",
    "    y_weighted_mean = sum(y_true[:, i].mean() * weights[i] for i in range(5))\n",
    "    ss_res = sum(((y_true[:, i] - y_pred[:, i]) ** 2).mean() * weights[i] for i in range(5))\n",
    "    ss_tot = sum(((y_true[:, i] - y_weighted_mean) ** 2).mean() * weights[i] for i in range(5))\n",
    "    return 1 - ss_res / (ss_tot + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf437d2f",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9fc80",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame, is_train: bool = True) -> pd.DataFrame:\n",
    "    if 'target' in df.columns:\n",
    "        df_wide = pd.pivot_table(\n",
    "            df, values='target',\n",
    "            index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "            columns='target_name', aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        df['target'] = 0\n",
    "        cols = ['image_path']\n",
    "        for col in ['Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm']:\n",
    "            if col in df.columns:\n",
    "                cols.append(col)\n",
    "        df_wide = df.drop_duplicates(subset=['image_path'])[cols].reset_index(drop=True)\n",
    "        for t in TARGET_ORDER:\n",
    "            df_wide[t] = 0.0\n",
    "    return df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf94fa3f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(cfg.DATA_PATH / \"train.csv\")\n",
    "train_wide = prepare_data(train_df, is_train=True)\n",
    "train_wide['image_id'] = train_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "kf = KFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "train_wide['fold'] = -1\n",
    "for fold, (_, val_idx) in enumerate(kf.split(train_wide)):\n",
    "    train_wide.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "print(f\"Train data shape: {train_wide.shape}\")\n",
    "\n",
    "# Tabular í†µê³„\n",
    "for col in cfg.tabular_cols:\n",
    "    print(f\"  {col}: min={train_wide[col].min():.2f}, max={train_wide[col].max():.2f}, mean={train_wide[col].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc3d0f",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd29448",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_transforms(mode: str = 'train', size: int = 384) -> A.Compose:\n",
    "    if mode == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(size, size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.3, hue=0.05, p=0.7),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(size, size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89037725",
   "metadata": {},
   "source": [
    "## Dataset (Auxiliary Target í¬í•¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b852a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassDatasetWithAux(Dataset):\n",
    "    \"\"\"Biomass + Auxiliary targets (NDVI, Height)\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        cfg, \n",
    "        transforms=None, \n",
    "        mode: str = 'train',\n",
    "        tabular_scaler: Optional[StandardScaler] = None\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Auxiliary targets (NDVI, Height) - í•™ìŠµì—ë§Œ ì‚¬ìš©\n",
    "        if mode in ['train', 'val'] and all(col in df.columns for col in cfg.tabular_cols):\n",
    "            aux_data = df[cfg.tabular_cols].values.astype(np.float32)\n",
    "            if tabular_scaler is not None:\n",
    "                if mode == 'train':\n",
    "                    self.aux_targets = tabular_scaler.fit_transform(aux_data)\n",
    "                else:\n",
    "                    self.aux_targets = tabular_scaler.transform(aux_data)\n",
    "            else:\n",
    "                self.aux_targets = aux_data\n",
    "            self.has_aux = True\n",
    "        else:\n",
    "            self.aux_targets = None\n",
    "            self.has_aux = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Image\n",
    "        img_path = self.cfg.DATA_PATH / row['image_path']\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        # Main targets (Green, Clover, Dead)\n",
    "        main_targets = torch.tensor([\n",
    "            row['Dry_Green_g'],\n",
    "            row['Dry_Clover_g'],\n",
    "            row['Dry_Dead_g']\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        # Auxiliary targets (NDVI, Height)\n",
    "        if self.has_aux:\n",
    "            aux_targets = torch.tensor(self.aux_targets[idx], dtype=torch.float32)\n",
    "            return img, main_targets, aux_targets\n",
    "        else:\n",
    "            return img, main_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc55dc",
   "metadata": {},
   "source": [
    "## ğŸ”‘ Model with Auxiliary Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09b4bb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class PhysicsConstrainedHead(nn.Module):\n",
    "    \"\"\"ë¬¼ë¦¬ì  ì œì•½ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì˜ˆì¸¡ í—¤ë“œ\"\"\"\n",
    "    def __init__(self, in_features: int, hidden_dim: int = 256, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 3)\n",
    "        )\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        raw = self.head(x)\n",
    "        independent = self.softplus(raw)\n",
    "        \n",
    "        green = independent[:, 0:1]\n",
    "        clover = independent[:, 1:2]\n",
    "        dead = independent[:, 2:3]\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        full = torch.cat([green, dead, clover, gdm, total], dim=1)\n",
    "        return independent, full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef1bbb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassModelWithAux(nn.Module):\n",
    "    \"\"\"\n",
    "    Auxiliary Task Learning ëª¨ë¸\n",
    "    \n",
    "    - Main Head: ë°”ì´ì˜¤ë§¤ìŠ¤ ì˜ˆì¸¡\n",
    "    - Aux Head: NDVI/Height ì˜ˆì¸¡ (í•™ìŠµ ì‹œì—ë§Œ ì‚¬ìš©)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        backbone_name: str = \"efficientnet_b4\",\n",
    "        n_aux: int = 2,  # NDVI, Height\n",
    "        dropout: float = 0.3,\n",
    "        pretrained: bool = True,\n",
    "        weights_path: Optional[str] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone\n",
    "        if pretrained and weights_path and Path(weights_path).exists():\n",
    "            self.backbone = timm.create_model(backbone_name, pretrained=False, num_classes=0)\n",
    "            weights = torch.load(weights_path, weights_only=True)\n",
    "            weights = {k: v for k, v in weights.items() if not k.startswith('classifier')}\n",
    "            self.backbone.load_state_dict(weights, strict=False)\n",
    "            print(f\"âœ“ Loaded pretrained weights from {weights_path}\")\n",
    "        else:\n",
    "            self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)\n",
    "        \n",
    "        self.feat_dim = self.backbone.num_features\n",
    "        \n",
    "        # Main Head (ë°”ì´ì˜¤ë§¤ìŠ¤)\n",
    "        self.main_head = PhysicsConstrainedHead(\n",
    "            in_features=self.feat_dim, \n",
    "            hidden_dim=256, \n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Auxiliary Head (NDVI, Height)\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Linear(self.feat_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, n_aux)\n",
    "        )\n",
    "    \n",
    "    def forward(self, image: torch.Tensor, return_aux: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image: [B, C, H, W]\n",
    "            return_aux: Trueë©´ aux ì˜ˆì¸¡ë„ ë°˜í™˜\n",
    "        \n",
    "        Returns:\n",
    "            independent: [B, 3] - Green, Clover, Dead\n",
    "            full: [B, 5] - All 5 targets\n",
    "            aux: [B, 2] - NDVI, Height (optional)\n",
    "        \"\"\"\n",
    "        feat = self.backbone(image)\n",
    "        independent, full = self.main_head(feat)\n",
    "        \n",
    "        if return_aux:\n",
    "            aux = self.aux_head(feat)\n",
    "            return independent, full, aux\n",
    "        return independent, full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e8339",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad182b4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_with_aux(\n",
    "    model: nn.Module, \n",
    "    loader: DataLoader, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    device: str,\n",
    "    aux_weight: float = 0.3\n",
    ") -> Tuple[float, float, float]:\n",
    "    model.train()\n",
    "    total_main_loss = 0\n",
    "    total_aux_loss = 0\n",
    "    \n",
    "    for batch in tqdm(loader, desc='Train', leave=False):\n",
    "        imgs, main_targets, aux_targets = batch\n",
    "        imgs = imgs.to(device)\n",
    "        main_targets = main_targets.to(device)\n",
    "        aux_targets = aux_targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        independent, _, aux_pred = model(imgs, return_aux=True)\n",
    "        \n",
    "        # Main loss (ë°”ì´ì˜¤ë§¤ìŠ¤)\n",
    "        main_loss = F.mse_loss(independent, main_targets)\n",
    "        \n",
    "        # Aux loss (NDVI, Height)\n",
    "        aux_loss = F.mse_loss(aux_pred, aux_targets)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = main_loss + aux_weight * aux_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_main_loss += main_loss.item()\n",
    "        total_aux_loss += aux_loss.item()\n",
    "    \n",
    "    n = len(loader)\n",
    "    return total_main_loss / n, total_aux_loss / n, (total_main_loss + aux_weight * total_aux_loss) / n\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_with_aux(\n",
    "    model: nn.Module, \n",
    "    loader: DataLoader, \n",
    "    device: str\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    \n",
    "    for batch in tqdm(loader, desc='Valid', leave=False):\n",
    "        imgs, main_targets, _ = batch  # aux_targetsëŠ” ì—¬ê¸°ì„  ë¬´ì‹œ\n",
    "        imgs = imgs.to(device)\n",
    "        \n",
    "        _, full_pred = model(imgs, return_aux=False)\n",
    "        all_preds.append(full_pred.cpu().numpy())\n",
    "        \n",
    "        # Full targets ì¬êµ¬ì„±\n",
    "        green = main_targets[:, 0:1]\n",
    "        clover = main_targets[:, 1:2]\n",
    "        dead = main_targets[:, 2:3]\n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        full_targets = torch.cat([green, dead, clover, gdm, total], dim=1)\n",
    "        all_targets.append(full_targets.numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    \n",
    "    cv_score = competition_metric(all_targets, all_preds)\n",
    "    mse = np.mean((all_preds - all_targets) ** 2)\n",
    "    \n",
    "    return mse, cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e5433",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_fold_with_aux(fold: int, train_df: pd.DataFrame, cfg) -> float:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ”¬ Exp A: Auxiliary Task - Fold {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "    \n",
    "    # Tabular scaler (aux targetsìš©)\n",
    "    tabular_scaler = StandardScaler()\n",
    "    \n",
    "    train_dataset = BiomassDatasetWithAux(\n",
    "        train_data, cfg, get_transforms('train', cfg.input_size), 'train', tabular_scaler\n",
    "    )\n",
    "    val_dataset = BiomassDatasetWithAux(\n",
    "        val_data, cfg, get_transforms('val', cfg.input_size), 'val', tabular_scaler\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=cfg.batch_size, shuffle=True,\n",
    "        num_workers=cfg.num_workers, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=cfg.batch_size * 2, shuffle=False,\n",
    "        num_workers=cfg.num_workers, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    weights_path = None\n",
    "    if cfg.WEIGHTS_PATH.exists():\n",
    "        weights_path = str(cfg.WEIGHTS_PATH / cfg.backbone / f\"{cfg.backbone}.pth\")\n",
    "    \n",
    "    model = BiomassModelWithAux(\n",
    "        backbone_name=cfg.backbone,\n",
    "        n_aux=len(cfg.tabular_cols),\n",
    "        dropout=0.3,\n",
    "        pretrained=True,\n",
    "        weights_path=weights_path\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"ğŸš€ Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(cfg.device)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=cfg.epochs)\n",
    "    \n",
    "    best_score = -float('inf')\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        main_loss, aux_loss, total_loss = train_one_epoch_with_aux(\n",
    "            model, train_loader, optimizer, cfg.device, cfg.aux_weight\n",
    "        )\n",
    "        val_mse, cv_score = validate_with_aux(model, val_loader, cfg.device)\n",
    "        scheduler.step()\n",
    "        \n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{cfg.epochs} | LR: {lr:.6f} | \"\n",
    "              f\"Main: {main_loss:.2f} | Aux: {aux_loss:.4f} | \"\n",
    "              f\"Val MSE: {val_mse:.2f} | CV: {cv_score:.4f}\")\n",
    "        \n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            torch.save({\n",
    "                'model_state_dict': model_to_save.state_dict(),\n",
    "                'fold': fold,\n",
    "                'score': best_score,\n",
    "                'tabular_scaler': tabular_scaler,\n",
    "            }, cfg.OUTPUT_DIR / f'exp_a_fold{fold}.pt')\n",
    "            print(f\"  âœ“ New best!\")\n",
    "    \n",
    "    flush()\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f6e73",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Train (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: 1-foldë§Œ)\n",
    "fold_scores = []\n",
    "for fold in range(cfg.train_folds):\n",
    "    score = train_fold_with_aux(fold, train_wide, cfg)\n",
    "    fold_scores.append(score)\n",
    "    print(f\"Fold {fold} Best CV: {score:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ“Š Exp A Results: CV = {np.mean(fold_scores):.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c283b",
   "metadata": {},
   "source": [
    "## Inference (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe78d39",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference_exp_a(models: list, loader: DataLoader, device: str) -> np.ndarray:\n",
    "    all_preds = []\n",
    "    \n",
    "    for batch in tqdm(loader, desc='Inference'):\n",
    "        if len(batch) == 3:\n",
    "            imgs, _, _ = batch\n",
    "        else:\n",
    "            imgs, _ = batch\n",
    "        imgs = imgs.to(device)\n",
    "        \n",
    "        batch_preds = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            _, full_pred = model(imgs, return_aux=False)\n",
    "            batch_preds.append(full_pred.cpu().numpy())\n",
    "        \n",
    "        avg_pred = np.mean(batch_preds, axis=0)\n",
    "        all_preds.append(avg_pred)\n",
    "    \n",
    "    return np.concatenate(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "test_wide = prepare_data(test_df, is_train=False)\n",
    "print(f\"Test data: {len(test_wide)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36343f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models = []\n",
    "for fold in range(cfg.train_folds):\n",
    "    ckpt_path = cfg.OUTPUT_DIR / f'exp_a_fold{fold}.pt'\n",
    "    if ckpt_path.exists():\n",
    "        ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "        \n",
    "        model = BiomassModelWithAux(\n",
    "            backbone_name=cfg.backbone,\n",
    "            n_aux=len(cfg.tabular_cols),\n",
    "            pretrained=False\n",
    "        ).to(cfg.device)\n",
    "        model.load_state_dict(ckpt['model_state_dict'])\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "        print(f\"âœ“ Loaded fold {fold} (CV: {ckpt['score']:.4f})\")\n",
    "\n",
    "print(f\"\\nLoaded {len(models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3777487",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Test dataset (aux ì—†ì´)\n",
    "test_dataset = BiomassDatasetWithAux(\n",
    "    test_wide, cfg, get_transforms('val', cfg.input_size), 'test', None\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=cfg.batch_size, shuffle=False,\n",
    "    num_workers=cfg.num_workers, pin_memory=True\n",
    ")\n",
    "\n",
    "# Inference\n",
    "preds = inference_exp_a(models, test_loader, cfg.device)\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb42342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "def melt_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    melted = df.melt(\n",
    "        id_vars='image_path', value_vars=TARGET_ORDER,\n",
    "        var_name='target_name', value_name='target'\n",
    "    )\n",
    "    melted['sample_id'] = (\n",
    "        melted['image_path']\n",
    "        .str.replace(r'^.*/', '', regex=True)\n",
    "        .str.replace('.jpg', '', regex=False)\n",
    "        + '__' + melted['target_name']\n",
    "    )\n",
    "    return melted[['sample_id', 'image_path', 'target_name', 'target']]\n",
    "\n",
    "test_wide[TARGET_ORDER] = preds\n",
    "test_wide[TARGET_ORDER] = test_wide[TARGET_ORDER].clip(lower=0)\n",
    "\n",
    "submission = melt_table(test_wide)\n",
    "submission = submission[['sample_id', 'target']]\n",
    "submission.to_csv(cfg.OUTPUT_DIR / 'submission_exp_a.csv', index=False)\n",
    "\n",
    "print(f\"\\nğŸ“„ Submission saved: {len(submission)} rows\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd30726",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "{'='*60}\n",
    "ğŸ”¬ Exp A: Auxiliary Task ì™„ë£Œ\n",
    "{'='*60}\n",
    "\n",
    "CV Score: {np.mean(fold_scores):.4f} (1-fold quick test)\n",
    "\n",
    "í•µì‹¬ í™•ì¸ ì‚¬í•­:\n",
    "1. Aux lossê°€ ê°ì†Œí•˜ëŠ”ê°€? (ëª¨ë¸ì´ NDVI/Heightë¥¼ í•™ìŠµí•˜ê³  ìˆëŠ”ê°€?)\n",
    "2. Main CVê°€ baselineë³´ë‹¤ ì¢‹ì€ê°€?\n",
    "\n",
    "Output: {cfg.OUTPUT_DIR / 'submission_exp_a.csv'}\n",
    "{'='*60}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
