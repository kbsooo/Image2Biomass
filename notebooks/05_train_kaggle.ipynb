{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca58be6a",
   "metadata": {},
   "source": [
    "# CSIRO Image2Biomass - Kaggle Training Pipeline\n",
    "\n",
    "**Kaggle-only version** optimized for:\n",
    "- T4 x2 GPU with DataParallel\n",
    "- 9-hour session with checkpoint resume\n",
    "- Direct submission generation\n",
    "\n",
    "### [SOTA Alert]\n",
    "DINOv2-Large backbone with bidirectional cross-attention fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b8617d",
   "metadata": {},
   "source": [
    "## Section 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q timm albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d3732",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc3b90",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6d3fc",
   "metadata": {},
   "source": [
    "## Section 1: Kaggle Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d245e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    # === Kaggle Paths (Fixed) ===\n",
    "    # Change 'csiro-pasture-biomass' to actual competition dataset name\n",
    "    DATA_PATH: Path = Path(\"/kaggle/input/csiro-pasture-biomass\")\n",
    "    OUTPUT_DIR: Path = Path(\"/kaggle/working\")\n",
    "\n",
    "    # === Model ===\n",
    "    backbone: str = \"vit_large_patch14_dinov2.lvd142m\"\n",
    "    input_size: int = 518\n",
    "    embed_dim: int = 1024  # DINOv2-large\n",
    "    num_heads: int = 16\n",
    "    dropout: float = 0.1\n",
    "\n",
    "    # === Training ===\n",
    "    n_folds: int = 5\n",
    "    train_folds: List[int] = field(default_factory=lambda: [0])  # Train single fold for speed\n",
    "    epochs: int = 15\n",
    "    batch_size: int = 4  # Per GPU, effective = 8 with 2 GPUs\n",
    "    gradient_accumulation: int = 2\n",
    "\n",
    "    # === Optimizer ===\n",
    "    lr: float = 1e-4\n",
    "    backbone_lr: float = 1e-5\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_epochs: int = 2\n",
    "\n",
    "    # === Training phases ===\n",
    "    freeze_backbone_epochs: int = 2\n",
    "\n",
    "    # === Targets ===\n",
    "    targets: List[str] = field(default_factory=lambda: [\n",
    "        'Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g'\n",
    "    ])\n",
    "    num_targets: int = 5\n",
    "\n",
    "    # === Hardware ===\n",
    "    seed: int = 42\n",
    "    num_workers: int = 4  # Kaggle has good CPU\n",
    "    mixed_precision: bool = True\n",
    "    use_multi_gpu: bool = True  # Enable DataParallel for T4x2\n",
    "\n",
    "    # === Resume ===\n",
    "    resume_from: Optional[str] = None  # Path to checkpoint for resume\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.n_gpus = torch.cuda.device_count()\n",
    "\n",
    "        # Adjust batch size for multi-GPU\n",
    "        if self.use_multi_gpu and self.n_gpus > 1:\n",
    "            self.effective_batch_size = self.batch_size * self.n_gpus * self.gradient_accumulation\n",
    "        else:\n",
    "            self.effective_batch_size = self.batch_size * self.gradient_accumulation\n",
    "\n",
    "cfg = CFG()\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"GPUs available: {cfg.n_gpus}\")\n",
    "print(f\"Effective batch size: {cfg.effective_batch_size}\")\n",
    "print(f\"Data path: {cfg.DATA_PATH}\")\n",
    "print(f\"Output dir: {cfg.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e3350",
   "metadata": {},
   "source": [
    "## Section 2: Constants & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8932be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "TARGET_WEIGHTS = {\n",
    "    'Dry_Green_g': 0.1,\n",
    "    'Dry_Dead_g': 0.1,\n",
    "    'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2,\n",
    "    'Dry_Total_g': 0.5,\n",
    "}\n",
    "\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38ef4e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def competition_metric(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Globally weighted R² score.\"\"\"\n",
    "    weights = np.array([TARGET_WEIGHTS[t] for t in TARGET_ORDER])\n",
    "\n",
    "    y_weighted_mean = sum(\n",
    "        y_true[:, i].mean() * weights[i] for i in range(5)\n",
    "    )\n",
    "\n",
    "    ss_res = sum(\n",
    "        ((y_true[:, i] - y_pred[:, i]) ** 2).mean() * weights[i]\n",
    "        for i in range(5)\n",
    "    )\n",
    "    ss_tot = sum(\n",
    "        ((y_true[:, i] - y_weighted_mean) ** 2).mean() * weights[i]\n",
    "        for i in range(5)\n",
    "    )\n",
    "\n",
    "    return 1 - ss_res / (ss_tot + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1569bf",
   "metadata": {},
   "source": [
    "## Section 3: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a2aa6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def pivot_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert long format to wide format.\"\"\"\n",
    "    if 'target' in df.columns:\n",
    "        df_pt = pd.pivot_table(\n",
    "            df,\n",
    "            values='target',\n",
    "            index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "            columns='target_name',\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        df['target'] = 0\n",
    "        df_pt = pd.pivot_table(\n",
    "            df, values='target', index='image_path',\n",
    "            columns='target_name', aggfunc='mean'\n",
    "        ).reset_index()\n",
    "    return df_pt\n",
    "\n",
    "def melt_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert wide format to submission format.\"\"\"\n",
    "    melted = df.melt(\n",
    "        id_vars='image_path',\n",
    "        value_vars=TARGET_ORDER,\n",
    "        var_name='target_name',\n",
    "        value_name='target'\n",
    "    )\n",
    "    melted['sample_id'] = (\n",
    "        melted['image_path']\n",
    "        .str.replace(r'^.*/', '', regex=True)\n",
    "        .str.replace('.jpg', '', regex=False)\n",
    "        + '__' + melted['target_name']\n",
    "    )\n",
    "    return melted[['sample_id', 'image_path', 'target_name', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b8cfb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_data(cfg: CFG) -> pd.DataFrame:\n",
    "    \"\"\"Load and prepare training data with KFold.\"\"\"\n",
    "    train_df = pd.read_csv(cfg.DATA_PATH / \"train.csv\")\n",
    "    train_wide = pivot_table(train_df)\n",
    "    train_wide['image_id'] = train_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "    kf = KFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "    train_wide['fold'] = -1\n",
    "    for fold, (_, val_idx) in enumerate(kf.split(train_wide)):\n",
    "        train_wide.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "    print(f\"Data shape: {train_wide.shape}\")\n",
    "    print(f\"Fold distribution:\\n{train_wide['fold'].value_counts().sort_index()}\")\n",
    "    return train_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a478c48",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "train_df = prepare_data(cfg)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63bf57",
   "metadata": {},
   "source": [
    "## Section 4: Dataset & Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b46c5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_transforms(cfg: CFG, mode: str = 'train') -> A.Compose:\n",
    "    if mode == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(cfg.input_size, cfg.input_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            # Insight: 색상 변환은 약하게 (녹색/갈색 구분 중요)\n",
    "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.02, p=0.3),\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15,\n",
    "                               border_mode=cv2.BORDER_REFLECT, p=0.5),\n",
    "            A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(cfg.input_size, cfg.input_size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee523a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"Dataset with left/right image split.\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, cfg: CFG, transforms=None, mode: str = 'train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_path = self.cfg.DATA_PATH / row['image_path']\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Split left/right (2000x1000 -> 1000x1000 x2)\n",
    "        h, w = img.shape[:2]\n",
    "        mid = w // 2\n",
    "        left_img = img[:, :mid]\n",
    "        right_img = img[:, mid:]\n",
    "\n",
    "        if self.transforms:\n",
    "            left_aug = self.transforms(image=left_img)['image']\n",
    "            right_aug = self.transforms(image=right_img)['image']\n",
    "        else:\n",
    "            left_aug = torch.from_numpy(left_img).permute(2, 0, 1).float() / 255.0\n",
    "            right_aug = torch.from_numpy(right_img).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        targets = torch.tensor([row[t] for t in TARGET_ORDER], dtype=torch.float32)\n",
    "\n",
    "        return {'left': left_aug, 'right': right_aug, 'targets': targets, 'image_id': row['image_id']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a8a2d2",
   "metadata": {},
   "source": [
    "## Section 5: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8958d3a6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim: int, mlp_ratio: float = 4.0, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        hidden = int(dim * mlp_ratio)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, dim), nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002b63e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiDirectionalCrossAttention(nn.Module):\n",
    "    \"\"\"Bidirectional cross-attention for left/right image fusion.\"\"\"\n",
    "    def __init__(self, dim: int = 1024, num_heads: int = 16,\n",
    "                 num_fuse_tokens: int = 4, num_layers: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_fuse_tokens = num_fuse_tokens\n",
    "\n",
    "        self.fuse_tokens = nn.Parameter(torch.randn(1, num_fuse_tokens, dim) * 0.02)\n",
    "\n",
    "        self.cross_layers = nn.ModuleList([\n",
    "            nn.ModuleDict({\n",
    "                'l2r_attn': nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True),\n",
    "                'r2l_attn': nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True),\n",
    "                'l2r_norm': nn.LayerNorm(dim),\n",
    "                'r2l_norm': nn.LayerNorm(dim),\n",
    "                'ffn_l': FeedForward(dim, mlp_ratio=4.0, dropout=dropout),\n",
    "                'ffn_r': FeedForward(dim, mlp_ratio=4.0, dropout=dropout),\n",
    "                'ffn_norm_l': nn.LayerNorm(dim),\n",
    "                'ffn_norm_r': nn.LayerNorm(dim),\n",
    "            })\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        fusion_input_dim = dim * 2 + dim * num_fuse_tokens\n",
    "        self.fusion_proj = nn.Sequential(\n",
    "            nn.LayerNorm(fusion_input_dim),\n",
    "            nn.Linear(fusion_input_dim, dim * 2), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(dim * 2, dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, feat_left: torch.Tensor, feat_right: torch.Tensor) -> torch.Tensor:\n",
    "        B = feat_left.shape[0]\n",
    "\n",
    "        feat_left = feat_left.unsqueeze(1)\n",
    "        feat_right = feat_right.unsqueeze(1)\n",
    "        fuse = self.fuse_tokens.expand(B, -1, -1)\n",
    "\n",
    "        for layer in self.cross_layers:\n",
    "            l_query = torch.cat([feat_left, fuse], dim=1)\n",
    "            l2r_out, _ = layer['l2r_attn'](layer['l2r_norm'](l_query), feat_right, feat_right, need_weights=False)\n",
    "            feat_left = feat_left + l2r_out[:, :1]\n",
    "            fuse_l = l2r_out[:, 1:]\n",
    "\n",
    "            r_query = torch.cat([feat_right, fuse], dim=1)\n",
    "            r2l_out, _ = layer['r2l_attn'](layer['r2l_norm'](r_query), feat_left, feat_left, need_weights=False)\n",
    "            feat_right = feat_right + r2l_out[:, :1]\n",
    "            fuse_r = r2l_out[:, 1:]\n",
    "\n",
    "            feat_left = feat_left + layer['ffn_l'](layer['ffn_norm_l'](feat_left))\n",
    "            feat_right = feat_right + layer['ffn_r'](layer['ffn_norm_r'](feat_right))\n",
    "            fuse = (fuse_l + fuse_r) / 2\n",
    "\n",
    "        left_pool = feat_left.squeeze(1)\n",
    "        right_pool = feat_right.squeeze(1)\n",
    "        fuse_flat = fuse.flatten(1)\n",
    "\n",
    "        combined = torch.cat([left_pool, right_pool, fuse_flat], dim=1)\n",
    "        return self.fusion_proj(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12932a10",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassModel(nn.Module):\n",
    "    \"\"\"DINOv2-Large + Bidirectional Cross-Attention + Physics-constrained outputs.\"\"\"\n",
    "    def __init__(self, cfg: CFG):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # ### [SOTA Alert] DINOv2-large for rich visual representations\n",
    "        self.backbone = timm.create_model(cfg.backbone, pretrained=True, num_classes=0)\n",
    "        self.embed_dim = self.backbone.embed_dim\n",
    "\n",
    "        if hasattr(self.backbone, 'set_grad_checkpointing'):\n",
    "            self.backbone.set_grad_checkpointing(True)\n",
    "\n",
    "        self.cross_attn = BiDirectionalCrossAttention(\n",
    "            dim=self.embed_dim, num_heads=cfg.num_heads,\n",
    "            num_fuse_tokens=4, num_layers=2, dropout=cfg.dropout\n",
    "        )\n",
    "\n",
    "        head_dim = self.embed_dim * 2\n",
    "        hidden_dim = head_dim // 2\n",
    "\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(head_dim, hidden_dim), nn.LayerNorm(hidden_dim),\n",
    "                nn.GELU(), nn.Dropout(cfg.dropout), nn.Linear(hidden_dim, 1)\n",
    "            )\n",
    "\n",
    "        self.head_green = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "\n",
    "    def forward(self, left: torch.Tensor, right: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        feat_left = self.backbone(left)\n",
    "        feat_right = self.backbone(right)\n",
    "        fused = self.cross_attn(feat_left, feat_right)\n",
    "\n",
    "        green = self.softplus(self.head_green(fused))\n",
    "        dead = self.softplus(self.head_dead(fused))\n",
    "        clover = self.softplus(self.head_clover(fused))\n",
    "\n",
    "        # Physics constraints: GDM = Green + Clover, Total = GDM + Dead\n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "\n",
    "        all_preds = torch.cat([green, dead, clover, gdm, total], dim=1)\n",
    "        return {'green': green, 'dead': dead, 'clover': clover, 'gdm': gdm, 'total': total, 'all': all_preds}\n",
    "\n",
    "    def freeze_backbone(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_backbone(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ce025",
   "metadata": {},
   "source": [
    "## Section 6: Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69f29e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class WeightedBiomassLoss(nn.Module):\n",
    "    \"\"\"Competition-aligned weighted loss with physics regularization.\"\"\"\n",
    "    def __init__(self, physics_weight: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.register_buffer('weights', torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5]))\n",
    "        self.physics_weight = physics_weight\n",
    "        self.smooth_l1 = nn.SmoothL1Loss(reduction='none', beta=1.0)\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        loss_per_target = self.smooth_l1(pred, target)\n",
    "        weighted_loss = (loss_per_target * self.weights.unsqueeze(0)).sum(dim=1).mean()\n",
    "\n",
    "        # Physics constraint regularization\n",
    "        pred_gdm_check = pred[:, 0] + pred[:, 2]\n",
    "        pred_total_check = pred[:, 3] + pred[:, 1]\n",
    "        physics_loss = (\n",
    "            F.smooth_l1_loss(pred_gdm_check, pred[:, 3]) +\n",
    "            F.smooth_l1_loss(pred_total_check, pred[:, 4])\n",
    "        )\n",
    "\n",
    "        return weighted_loss + self.physics_weight * physics_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d5672",
   "metadata": {},
   "source": [
    "## Section 7: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a3067e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, scheduler, criterion, cfg, scaler=None, epoch=0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch+1} Train')\n",
    "\n",
    "    for step, batch in enumerate(pbar):\n",
    "        left = batch['left'].to(cfg.device, non_blocking=True)\n",
    "        right = batch['right'].to(cfg.device, non_blocking=True)\n",
    "        targets = batch['targets'].to(cfg.device, non_blocking=True)\n",
    "\n",
    "        with torch.amp.autocast('cuda', enabled=cfg.mixed_precision):\n",
    "            outputs = model(left, right)\n",
    "            loss = criterion(outputs['all'], targets)\n",
    "            loss = loss / cfg.gradient_accumulation\n",
    "\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        if (step + 1) % cfg.gradient_accumulation == 0:\n",
    "            if scaler is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        total_loss += loss.item() * cfg.gradient_accumulation\n",
    "        pbar.set_postfix({'loss': f'{loss.item() * cfg.gradient_accumulation:.4f}'})\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3982c6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, cfg):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    for batch in tqdm(loader, desc='Validation'):\n",
    "        left = batch['left'].to(cfg.device, non_blocking=True)\n",
    "        right = batch['right'].to(cfg.device, non_blocking=True)\n",
    "        targets = batch['targets'].to(cfg.device, non_blocking=True)\n",
    "\n",
    "        with torch.amp.autocast('cuda', enabled=cfg.mixed_precision):\n",
    "            outputs = model(left, right)\n",
    "            loss = criterion(outputs['all'], targets)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_preds.append(outputs['all'].cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_targets = torch.cat(all_targets, dim=0).numpy()\n",
    "\n",
    "    cv_score = competition_metric(all_targets, all_preds)\n",
    "\n",
    "    r2_scores = {}\n",
    "    for i, name in enumerate(TARGET_ORDER):\n",
    "        ss_res = np.sum((all_targets[:, i] - all_preds[:, i]) ** 2)\n",
    "        ss_tot = np.sum((all_targets[:, i] - all_targets[:, i].mean()) ** 2)\n",
    "        r2_scores[name] = 1 - ss_res / (ss_tot + 1e-8)\n",
    "\n",
    "    return total_loss / len(loader), cv_score, r2_scores, all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eca94f",
   "metadata": {},
   "source": [
    "## Section 8: Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8833e53",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def post_process_biomass(preds: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Project predictions to satisfy physics constraints.\"\"\"\n",
    "    C = np.array([\n",
    "        [1, 0, 1, -1,  0],   # Green + Clover - GDM = 0\n",
    "        [0, 1, 0,  1, -1]    # Dead + GDM - Total = 0\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "    C_T = C.T\n",
    "    inv_CCt = np.linalg.inv(C @ C_T)\n",
    "    P = np.eye(5) - C_T @ inv_CCt @ C\n",
    "\n",
    "    Y = preds.T\n",
    "    Y_proj = P @ Y\n",
    "    Y_proj = Y_proj.T\n",
    "    Y_proj = np.clip(Y_proj, 0, None)\n",
    "\n",
    "    return Y_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4260ab",
   "metadata": {},
   "source": [
    "## Section 9: Main Training Loop with Resume Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a898c9cf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, scheduler, scaler, epoch, best_score, fold, cfg):\n",
    "    \"\"\"Save checkpoint for resume.\"\"\"\n",
    "    # Handle DataParallel\n",
    "    model_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_state,\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "        'best_score': best_score,\n",
    "        'fold': fold,\n",
    "        'config': {\n",
    "            'backbone': cfg.backbone,\n",
    "            'embed_dim': cfg.embed_dim,\n",
    "            'num_heads': cfg.num_heads,\n",
    "            'dropout': cfg.dropout,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    torch.save(checkpoint, cfg.OUTPUT_DIR / f'checkpoint_fold{fold}.pt')\n",
    "    print(f\"Checkpoint saved: epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7451c1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_fold(fold: int, train_df: pd.DataFrame, cfg: CFG):\n",
    "    \"\"\"Train one fold with resume support.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Fold {fold} | GPUs: {cfg.n_gpus}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Split\n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "\n",
    "    # Datasets\n",
    "    train_dataset = BiomassDataset(train_data, cfg, transforms=get_transforms(cfg, 'train'), mode='train')\n",
    "    val_dataset = BiomassDataset(val_data, cfg, transforms=get_transforms(cfg, 'val'), mode='val')\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=cfg.batch_size * max(1, cfg.n_gpus),\n",
    "        shuffle=True, num_workers=cfg.num_workers, pin_memory=True, drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=cfg.batch_size * max(1, cfg.n_gpus) * 2,\n",
    "        shuffle=False, num_workers=cfg.num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = BiomassModel(cfg).to(cfg.device)\n",
    "\n",
    "    # Multi-GPU with DataParallel\n",
    "    if cfg.use_multi_gpu and cfg.n_gpus > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        print(f\"Using DataParallel with {cfg.n_gpus} GPUs\")\n",
    "\n",
    "    # Get base model for freeze/unfreeze\n",
    "    base_model = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "    # Freeze backbone initially\n",
    "    if cfg.freeze_backbone_epochs > 0:\n",
    "        base_model.freeze_backbone()\n",
    "        print(f\"Backbone frozen for first {cfg.freeze_backbone_epochs} epochs\")\n",
    "\n",
    "    # Optimizer\n",
    "    backbone_params = list(base_model.backbone.parameters())\n",
    "    other_params = [p for n, p in base_model.named_parameters() if 'backbone' not in n]\n",
    "\n",
    "    optimizer = AdamW([\n",
    "        {'params': backbone_params, 'lr': cfg.backbone_lr},\n",
    "        {'params': other_params, 'lr': cfg.lr}\n",
    "    ], weight_decay=cfg.weight_decay)\n",
    "\n",
    "    # Scheduler\n",
    "    num_training_steps = len(train_loader) * cfg.epochs // cfg.gradient_accumulation\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer, max_lr=[cfg.backbone_lr * 10, cfg.lr],\n",
    "        total_steps=num_training_steps, pct_start=cfg.warmup_epochs / cfg.epochs, anneal_strategy='cos'\n",
    "    )\n",
    "\n",
    "    # Loss & Scaler\n",
    "    criterion = WeightedBiomassLoss(physics_weight=0.1).to(cfg.device)\n",
    "    scaler = torch.amp.GradScaler('cuda') if cfg.mixed_precision else None\n",
    "\n",
    "    # Resume from checkpoint\n",
    "    start_epoch = 0\n",
    "    best_score = -float('inf')\n",
    "\n",
    "    checkpoint_path = cfg.OUTPUT_DIR / f'checkpoint_fold{fold}.pt'\n",
    "    if cfg.resume_from or checkpoint_path.exists():\n",
    "        ckpt_path = cfg.resume_from or checkpoint_path\n",
    "        if Path(ckpt_path).exists():\n",
    "            print(f\"Resuming from {ckpt_path}\")\n",
    "            checkpoint = torch.load(ckpt_path, weights_only=False)\n",
    "            base_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            if checkpoint['scheduler_state_dict']:\n",
    "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            if checkpoint['scaler_state_dict'] and scaler:\n",
    "                scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            best_score = checkpoint['best_score']\n",
    "            print(f\"Resumed from epoch {start_epoch}, best_score: {best_score:.4f}\")\n",
    "\n",
    "    # Training history\n",
    "    history = {'train_loss': [], 'val_loss': [], 'cv_score': []}\n",
    "\n",
    "    for epoch in range(start_epoch, cfg.epochs):\n",
    "        # Unfreeze backbone\n",
    "        if epoch == cfg.freeze_backbone_epochs and cfg.freeze_backbone_epochs > 0:\n",
    "            base_model.unfreeze_backbone()\n",
    "            print(f\"\\nBackbone unfrozen at epoch {epoch + 1}\")\n",
    "\n",
    "        # Train\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, cfg, scaler, epoch)\n",
    "\n",
    "        # Validate\n",
    "        val_loss, cv_score, r2_scores, val_preds = validate(model, val_loader, criterion, cfg)\n",
    "\n",
    "        # Post-process\n",
    "        val_preds_pp = post_process_biomass(val_preds)\n",
    "        val_targets = np.array([val_dataset[i]['targets'].numpy() for i in range(len(val_dataset))])\n",
    "        cv_score_pp = competition_metric(val_targets, val_preds_pp)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['cv_score'].append(cv_score_pp)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}/{cfg.epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"CV Score (raw): {cv_score:.4f} | CV Score (PP): {cv_score_pp:.4f}\")\n",
    "        for name, r2 in r2_scores.items():\n",
    "            print(f\"  {name} (w={TARGET_WEIGHTS[name]}): {r2:.4f}\")\n",
    "\n",
    "        # Save checkpoint every epoch (for 9h session limit)\n",
    "        save_checkpoint(model, optimizer, scheduler, scaler, epoch, best_score, fold, cfg)\n",
    "\n",
    "        # Save best model\n",
    "        if cv_score_pp > best_score:\n",
    "            best_score = cv_score_pp\n",
    "            model_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model_state,\n",
    "                'best_score': best_score,\n",
    "                'r2_scores': r2_scores,\n",
    "                'config': {\n",
    "                    'backbone': cfg.backbone,\n",
    "                    'embed_dim': cfg.embed_dim,\n",
    "                    'num_heads': cfg.num_heads,\n",
    "                    'dropout': cfg.dropout,\n",
    "                }\n",
    "            }, cfg.OUTPUT_DIR / f'best_model_fold{fold}.pt')\n",
    "            print(f\"*** New best model saved (CV: {best_score:.4f}) ***\")\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title('Loss Curve')\n",
    "\n",
    "    axes[1].plot(history['cv_score'], label='CV Score', color='green')\n",
    "    axes[1].axhline(y=best_score, color='r', linestyle='--', label=f'Best: {best_score:.4f}')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Competition Metric')\n",
    "    axes[1].legend()\n",
    "    axes[1].set_title('CV Score (Post-processed)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cfg.OUTPUT_DIR / f'training_history_fold{fold}.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    flush()\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4de08",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# === Train ===\n",
    "all_scores = []\n",
    "for fold in cfg.train_folds:\n",
    "    best_score = train_fold(fold, train_df, cfg)\n",
    "    all_scores.append(best_score)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Mean CV Score: {np.mean(all_scores):.4f} +/- {np.std(all_scores):.4f}\")\n",
    "print(f\"Scores per fold: {all_scores}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a6b60",
   "metadata": {},
   "source": [
    "## Section 10: Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83056688",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference_with_tta(model, loader, cfg, n_tta: int = 4) -> np.ndarray:\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "\n",
    "    tta_transforms = [\n",
    "        lambda x: x,\n",
    "        lambda x: torch.flip(x, dims=[3]),\n",
    "        lambda x: torch.flip(x, dims=[2]),\n",
    "        lambda x: torch.flip(x, dims=[2, 3]),\n",
    "    ][:n_tta]\n",
    "\n",
    "    for batch in tqdm(loader, desc='Inference'):\n",
    "        left = batch['left'].to(cfg.device)\n",
    "        right = batch['right'].to(cfg.device)\n",
    "\n",
    "        batch_preds = []\n",
    "        for tta in tta_transforms:\n",
    "            left_aug = tta(left)\n",
    "            right_aug = tta(right)\n",
    "            with torch.amp.autocast('cuda', enabled=cfg.mixed_precision):\n",
    "                outputs = model(left_aug, right_aug)\n",
    "                batch_preds.append(outputs['all'].cpu())\n",
    "\n",
    "        batch_pred = torch.stack(batch_preds).mean(dim=0)\n",
    "        all_preds.append(batch_pred.numpy())\n",
    "\n",
    "    return np.concatenate(all_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e86c0e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_submission(cfg: CFG, fold: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"Create submission from test data.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    checkpoint = torch.load(cfg.OUTPUT_DIR / f'best_model_fold{fold}.pt', weights_only=False)\n",
    "    model = BiomassModel(cfg).to(cfg.device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded model with CV score: {checkpoint['best_score']:.4f}\")\n",
    "\n",
    "    if cfg.use_multi_gpu and cfg.n_gpus > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    # Test data\n",
    "    test_df = pd.read_csv(cfg.DATA_PATH / 'test.csv')\n",
    "    test_wide = test_df.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "    test_wide['image_id'] = test_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "    for t in TARGET_ORDER:\n",
    "        if t not in test_wide.columns:\n",
    "            test_wide[t] = 0.0\n",
    "\n",
    "    test_dataset = BiomassDataset(test_wide, cfg, transforms=get_transforms(cfg, 'val'), mode='test')\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=cfg.batch_size, shuffle=False,\n",
    "        num_workers=cfg.num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Inference with TTA\n",
    "    preds = inference_with_tta(model, test_loader, cfg, n_tta=4)\n",
    "    preds = post_process_biomass(preds)\n",
    "\n",
    "    # Create submission\n",
    "    test_wide[TARGET_ORDER] = preds\n",
    "    submission = melt_table(test_wide)\n",
    "\n",
    "    return submission[['sample_id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission if model exists\n",
    "if (cfg.OUTPUT_DIR / f'best_model_fold{cfg.train_folds[0]}.pt').exists():\n",
    "    submission = create_submission(cfg, fold=cfg.train_folds[0])\n",
    "    submission.to_csv(cfg.OUTPUT_DIR / 'submission.csv', index=False)\n",
    "    print(f\"Submission saved: {len(submission)} rows\")\n",
    "    print(submission.head(10))\n",
    "else:\n",
    "    print(\"No trained model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bf5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "{'='*60}\n",
    "Kaggle Training Complete!\n",
    "{'='*60}\n",
    "\n",
    "Output files in {cfg.OUTPUT_DIR}:\n",
    "- best_model_fold*.pt     (best weights)\n",
    "- checkpoint_fold*.pt     (resume checkpoint)\n",
    "- training_history_*.png  (loss curves)\n",
    "- submission.csv          (final submission)\n",
    "\n",
    "To resume interrupted training:\n",
    "  Set cfg.resume_from = '/kaggle/working/checkpoint_fold0.pt'\n",
    "{'='*60}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
