{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1ce0eb",
   "metadata": {},
   "source": [
    "# üîß DINOv3 Training v15 - Back to Basics\n",
    "\n",
    "**Ï†ÑÎûµ**: v12 baseline (CV 0.67)ÏùÑ Í∏∞Î∞òÏúºÎ°ú Ï†êÏßÑÏ†Å Í∞úÏÑ†\n",
    "\n",
    "**v12 ‚Üí v15 Î≥ÄÍ≤ΩÏÇ¨Ìï≠** (ÏµúÏÜåÌïúÎßå):\n",
    "1. Dropout 0.0 ‚Üí 0.1 (ÏïΩÌïú regularization)\n",
    "2. More epochs: 15 ‚Üí 20\n",
    "3. Early stopping\n",
    "4. Îçî Í∞ïÌïú augmentation (TrivialAugment Ï†úÍ±∞, ÏïàÏ†ÑÌïú Í≤ÉÎßå)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a747d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import timm\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f542935c",
   "metadata": {},
   "source": [
    "## üîê Step 1: Google Drive Mount (Colab Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDRIVE_SAVE_PATH = None\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    GDRIVE_SAVE_PATH = Path('/content/drive/MyDrive/kaggle_models/csiro_biomass_v15')\n",
    "    GDRIVE_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úì Google Drive mounted: {GDRIVE_SAVE_PATH}\")\n",
    "except ImportError:\n",
    "    print(\"Not in Colab - Google Drive skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf0603",
   "metadata": {},
   "source": [
    "## üîë Step 2: Kaggle Login (Colab Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcdd0e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "IS_KAGGLE = Path(\"/kaggle/input/csiro-biomass\").exists()\n",
    "\n",
    "if not IS_KAGGLE:\n",
    "    print(\"üü¢ Colab ÌôòÍ≤Ω - Kaggle Î°úÍ∑∏Ïù∏ ÌïÑÏöî\")\n",
    "    kagglehub.login()\n",
    "else:\n",
    "    print(\"üîµ Kaggle ÌôòÍ≤Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5ee06",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a3181",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration (v12 Í∏∞Î∞ò, ÏµúÏÜå Î≥ÄÍ≤Ω)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae40bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # === Paths ===\n",
    "    DATA_PATH = None\n",
    "    OUTPUT_DIR = None\n",
    "    WEIGHTS_PATH = None\n",
    "    \n",
    "    # === Model (v12ÏôÄ ÎèôÏùº) ===\n",
    "    model_name = \"vit_large_patch16_dinov3_qkvb.lvd1689m\"\n",
    "    backbone_dim = 1024\n",
    "    img_size = (512, 512)\n",
    "    \n",
    "    # === Training (v12 Í∏∞Î∞ò + ÏïΩÍ∞Ñ Í∞úÏÑ†) ===\n",
    "    n_folds = 5\n",
    "    epochs = 20  # 15 ‚Üí 20\n",
    "    batch_size = 16\n",
    "    lr = 1e-4  # v12ÏôÄ ÎèôÏùº\n",
    "    backbone_lr_mult = 0.1  # v12ÏôÄ ÎèôÏùº\n",
    "    weight_decay = 1e-4  # v12ÏôÄ ÎèôÏùº\n",
    "    dropout = 0.1  # 0.0 ‚Üí 0.1 (ÏïΩÌïú regularization)\n",
    "    \n",
    "    # === Other ===\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a6640",
   "metadata": {},
   "source": [
    "## üì• Step 3: Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ce67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_KAGGLE:\n",
    "    cfg.DATA_PATH = Path(\"/kaggle/input/csiro-biomass\")\n",
    "    cfg.WEIGHTS_PATH = Path(\"/kaggle/input/pretrained-weights-biomass/dinov3_large/dinov3_large\")\n",
    "    cfg.OUTPUT_DIR = Path(\"/kaggle/working\")\n",
    "else:\n",
    "    print(\"Downloading data via kagglehub...\")\n",
    "    csiro_path = kagglehub.competition_download('csiro-biomass')\n",
    "    weights_path = kagglehub.dataset_download('kbsooo/pretrained-weights-biomass')\n",
    "    \n",
    "    cfg.DATA_PATH = Path(csiro_path)\n",
    "    cfg.WEIGHTS_PATH = Path(weights_path) / \"dinov3_large\" / \"dinov3_large\"\n",
    "    cfg.OUTPUT_DIR = Path(\"/content/output\")\n",
    "\n",
    "cfg.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Data: {cfg.DATA_PATH}\")\n",
    "print(f\"Weights: {cfg.WEIGHTS_PATH}\")\n",
    "print(f\"Output: {cfg.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014fc965",
   "metadata": {},
   "source": [
    "## üìä Competition Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274257f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "TARGET_WEIGHTS = {\n",
    "    'Dry_Green_g': 0.1, 'Dry_Dead_g': 0.1, 'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2, 'Dry_Total_g': 0.5,\n",
    "}\n",
    "TARGET_ORDER = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "def competition_metric(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Weighted R¬≤ score.\"\"\"\n",
    "    weighted_r2 = 0.0\n",
    "    for i, target in enumerate(TARGET_ORDER):\n",
    "        weight = TARGET_WEIGHTS[target]\n",
    "        ss_res = np.sum((y_true[:, i] - y_pred[:, i]) ** 2)\n",
    "        ss_tot = np.sum((y_true[:, i] - np.mean(y_true[:, i])) ** 2)\n",
    "        r2 = 1 - ss_res / (ss_tot + 1e-8)\n",
    "        weighted_r2 += weight * r2\n",
    "    return weighted_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41002a07",
   "metadata": {},
   "source": [
    "## üìÅ Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadf204",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    pivot = df.pivot_table(\n",
    "        index=['image_path', 'State', 'Species', 'Sampling_Date', 'Pre_GSHH_NDVI', 'Height_Ave_cm'],\n",
    "        columns='target_name',\n",
    "        values='target',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    pivot.columns.name = None\n",
    "    return pivot\n",
    "\n",
    "train_df = pd.read_csv(cfg.DATA_PATH / \"train.csv\")\n",
    "train_wide = prepare_data(train_df)\n",
    "train_wide['image_id'] = train_wide['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "# Stratified Group KFold\n",
    "sgkf = StratifiedGroupKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "train_wide['fold'] = -1\n",
    "for fold, (_, val_idx) in enumerate(sgkf.split(\n",
    "    train_wide, \n",
    "    train_wide['State'],\n",
    "    groups=train_wide['image_id']\n",
    ")):\n",
    "    train_wide.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "print(f\"Train samples: {len(train_wide)}\")\n",
    "print(f\"Folds: {train_wide['fold'].value_counts().sort_index().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c64993",
   "metadata": {},
   "source": [
    "## üé® Dataset & Augmentation (v12ÏôÄ ÎèôÏùº + ÏïΩÍ∞Ñ Í∞ïÌôî)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b324348",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"v12ÏôÄ ÎèôÏùºÌïú Left/Right Split Dataset\"\"\"\n",
    "    def __init__(self, df, cfg, transform=None, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        img = Image.open(self.cfg.DATA_PATH / row['image_path']).convert('RGB')\n",
    "        width, height = img.size\n",
    "        mid_point = width // 2\n",
    "        \n",
    "        left_img = img.crop((0, 0, mid_point, height))\n",
    "        right_img = img.crop((mid_point, 0, width, height))\n",
    "        \n",
    "        if self.transform:\n",
    "            left_img = self.transform(left_img)\n",
    "            right_img = self.transform(right_img)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            # ÎèÖÎ¶Ω ÌÉÄÍ≤ü 3Í∞úÎßå (GDM, TotalÏùÄ Î™®Îç∏ÏóêÏÑú Í≥ÑÏÇ∞)\n",
    "            targets = torch.tensor([\n",
    "                row['Dry_Green_g'],\n",
    "                row['Dry_Clover_g'],\n",
    "                row['Dry_Dead_g']\n",
    "            ], dtype=torch.float32)\n",
    "            return left_img, right_img, targets\n",
    "        else:\n",
    "            return left_img, right_img, row['image_id']\n",
    "\n",
    "def get_train_transforms(cfg):\n",
    "    \"\"\"v12 augmentation + ÏïΩÍ∞Ñ Í∞ïÌôî\"\"\"\n",
    "    return T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.RandomRotation(degrees=10),  # Ï∂îÍ∞Ä\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_transforms(cfg):\n",
    "    return T.Compose([\n",
    "        T.Resize(cfg.img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a3943",
   "metadata": {},
   "source": [
    "## üß† Model (v12ÏôÄ ÎèôÏùº Íµ¨Ï°∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732926c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    \"\"\"Feature-wise Linear Modulation (v12ÏôÄ ÎèôÏùº)\"\"\"\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)\n",
    "        return gamma, beta\n",
    "\n",
    "class CSIROModel(nn.Module):\n",
    "    \"\"\"\n",
    "    v12ÏôÄ ÎèôÏùºÌïú Íµ¨Ï°∞ (Í≤ÄÏ¶ùÎê®: CV 0.67)\n",
    "    Î≥ÄÍ≤Ω: dropoutÎßå Ï∂îÍ∞Ä\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, pretrained=True, weights_path=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # DINOv3 ViT-Large backbone\n",
    "        if pretrained and weights_path and Path(weights_path).exists():\n",
    "            print(f\"Loading backbone from: {weights_path}\")\n",
    "            self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0, global_pool='avg')\n",
    "            state_dict = torch.load(weights_path, map_location='cpu', weights_only=True)\n",
    "            self.backbone.load_state_dict(state_dict, strict=False)\n",
    "            print(\"‚úì Backbone loaded from local weights\")\n",
    "        else:\n",
    "            print(\"Loading backbone from timm (online)\")\n",
    "            self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool='avg')\n",
    "        \n",
    "        feat_dim = self.backbone.num_features\n",
    "        print(f\"Backbone feature dim: {feat_dim}\")\n",
    "        \n",
    "        # FiLM for cross-region modulation\n",
    "        self.film = FiLM(feat_dim)\n",
    "        \n",
    "        # v12ÏôÄ ÎèôÏùºÌïú head structure (256 hidden units)\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(feat_dim * 2, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),  # dropout Ï∂îÍ∞Ä\n",
    "                nn.Linear(256, 1)\n",
    "            )\n",
    "        \n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        \n",
    "        # Softplus for non-negative outputs\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "    \n",
    "    def forward(self, left_img, right_img):\n",
    "        # Extract features from both halves\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        # Compute context as average\n",
    "        context = (left_feat + right_feat) / 2\n",
    "        \n",
    "        # Generate modulation parameters\n",
    "        gamma, beta = self.film(context)\n",
    "        \n",
    "        # Modulate features\n",
    "        left_mod = left_feat * (1 + gamma) + beta\n",
    "        right_mod = right_feat * (1 + gamma) + beta\n",
    "        \n",
    "        # Concatenate\n",
    "        combined = torch.cat([left_mod, right_mod], dim=1)\n",
    "        \n",
    "        # Predict independent targets\n",
    "        green = self.softplus(self.head_green(combined))\n",
    "        clover = self.softplus(self.head_clover(combined))\n",
    "        dead = self.softplus(self.head_dead(combined))\n",
    "        \n",
    "        # Physics constraints\n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        # Return: [Green, Dead, Clover, GDM, Total] (competition order)\n",
    "        return torch.cat([green, dead, clover, gdm, total], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2797b",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Training Functions (v12ÏôÄ ÎèôÏùº)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27df721",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, scheduler, device, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for left, right, targets in pbar:\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(left, right)\n",
    "            # Loss on Green, Clover, Dead (indices 0, 2, 1 in output)\n",
    "            pred = outputs[:, [0, 2, 1]]  # Reorder to [Green, Clover, Dead]\n",
    "            loss = F.mse_loss(pred, targets)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.2f}'})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for left, right, targets in tqdm(loader, desc=\"Validating\"):\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        \n",
    "        outputs = model(left, right)\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_targets.append(targets.numpy())\n",
    "    \n",
    "    preds = np.concatenate(all_preds)\n",
    "    targets = np.concatenate(all_targets)\n",
    "    \n",
    "    # Compute full targets for metric\n",
    "    full_targets = np.zeros((len(targets), 5))\n",
    "    full_targets[:, 0] = targets[:, 0]  # Green\n",
    "    full_targets[:, 1] = targets[:, 2]  # Dead\n",
    "    full_targets[:, 2] = targets[:, 1]  # Clover\n",
    "    full_targets[:, 3] = targets[:, 0] + targets[:, 1]  # GDM = Green + Clover\n",
    "    full_targets[:, 4] = full_targets[:, 3] + targets[:, 2]  # Total = GDM + Dead\n",
    "    \n",
    "    score = competition_metric(full_targets, preds)\n",
    "    return score, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc94605",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_fold(fold, train_df, cfg):\n",
    "    \"\"\"Train single fold\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    val_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "    \n",
    "    # Datasets & Loaders\n",
    "    train_ds = BiomassDataset(train_data, cfg, get_train_transforms(cfg), 'train')\n",
    "    val_ds = BiomassDataset(val_data, cfg, get_val_transforms(cfg), 'train')\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, \n",
    "                              shuffle=True, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size * 2,\n",
    "                            shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    \n",
    "    # Model\n",
    "    weights_path = cfg.WEIGHTS_PATH / \"dinov3_vitl16_qkvb.pth\"\n",
    "    model = CSIROModel(\n",
    "        cfg.model_name, \n",
    "        pretrained=True, \n",
    "        weights_path=weights_path,\n",
    "        dropout=cfg.dropout\n",
    "    )\n",
    "    model = model.to(cfg.device)\n",
    "    \n",
    "    # Optimizer with layer-wise learning rate decay\n",
    "    backbone_params = list(model.backbone.parameters())\n",
    "    head_params = (list(model.head_green.parameters()) + \n",
    "                   list(model.head_clover.parameters()) + \n",
    "                   list(model.head_dead.parameters()) + \n",
    "                   list(model.film.parameters()))\n",
    "    \n",
    "    optimizer = AdamW([\n",
    "        {'params': backbone_params, 'lr': cfg.lr * cfg.backbone_lr_mult},\n",
    "        {'params': head_params, 'lr': cfg.lr}\n",
    "    ], weight_decay=cfg.weight_decay)\n",
    "    \n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=len(train_loader),\n",
    "        num_training_steps=len(train_loader) * cfg.epochs\n",
    "    )\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Training loop with early stopping\n",
    "    best_score = -float('inf')\n",
    "    best_epoch = 0\n",
    "    patience = 5\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(cfg.epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{cfg.epochs}\")\n",
    "        \n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, cfg.device, scaler)\n",
    "        val_score, _ = validate(model, val_loader, cfg.device)\n",
    "        \n",
    "        print(f\"Loss: {train_loss:.4f} | CV: {val_score:.4f}\")\n",
    "        \n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_epoch = epoch + 1\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), cfg.OUTPUT_DIR / f'model_fold{fold}.pth')\n",
    "            print(f\"  ‚úì New best! Saved.\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nFold {fold} Best: {best_score:.4f} (epoch {best_epoch})\")\n",
    "    \n",
    "    # Backup to Google Drive\n",
    "    if GDRIVE_SAVE_PATH is not None:\n",
    "        import shutil\n",
    "        src = cfg.OUTPUT_DIR / f'model_fold{fold}.pth'\n",
    "        if src.exists():\n",
    "            shutil.copy(src, GDRIVE_SAVE_PATH / f'model_fold{fold}.pth')\n",
    "            print(f\"  üìÅ Backed up to Drive\")\n",
    "    \n",
    "    flush()\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd322e8d",
   "metadata": {},
   "source": [
    "## üöÄ Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üöÄ TRAINING START (v15 - Back to Basics)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Config: dropout={cfg.dropout}, epochs={cfg.epochs}, lr={cfg.lr}\")\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold in range(cfg.n_folds):\n",
    "        score = train_fold(fold, train_wide, cfg)\n",
    "        fold_scores.append(score)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ TRAINING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Fold scores: {[f'{s:.4f}' for s in fold_scores]}\")\n",
    "    print(f\"Mean CV: {np.mean(fold_scores):.4f} ¬± {np.std(fold_scores):.4f}\")\n",
    "    \n",
    "    # Save to Google Drive\n",
    "    if GDRIVE_SAVE_PATH is not None:\n",
    "        import shutil\n",
    "        import json\n",
    "        from datetime import datetime\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        final_path = GDRIVE_SAVE_PATH / f\"run_{timestamp}_cv{np.mean(fold_scores):.4f}\"\n",
    "        final_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for f in cfg.OUTPUT_DIR.glob(\"model_fold*.pth\"):\n",
    "            shutil.copy(f, final_path / f.name)\n",
    "        \n",
    "        results = {\n",
    "            'fold_scores': fold_scores,\n",
    "            'mean_cv': float(np.mean(fold_scores)),\n",
    "            'std_cv': float(np.std(fold_scores)),\n",
    "            'config': {\n",
    "                'model_name': cfg.model_name,\n",
    "                'dropout': cfg.dropout,\n",
    "                'lr': cfg.lr,\n",
    "                'epochs': cfg.epochs,\n",
    "            }\n",
    "        }\n",
    "        with open(final_path / 'results.json', 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Saved to: {final_path}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
